{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/blainerothrock/nlp-group-2/blob/master/nlp_assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h5suI3fCFjhO"
   },
   "source": [
    "# NLP Assignment 2 (Bengio and other Neural Language Models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XD4GX_ezyPag"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/b/anaconda3/envs/nlp/lib/python3.7/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# %tensorflow_version 2.x\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "print(tf.__version__)\n",
    "\n",
    "# from google.colab import drive, files \n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "import os, pickle\n",
    "import numpy as np\n",
    "import math\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VnA8lII6Al51"
   },
   "outputs": [],
   "source": [
    "blaine_ubuntu_data_path = '../data'\n",
    "blaine_data_path = '/Users/blaine/Google Drive File Stream/My Drive/Winter20/nlp/nlp_group2/data'\n",
    "data_path = 'drive/My Drive/Winter20/nlp/nlp_group2/data'\n",
    "grant_data_path = 'drive/My Drive/nlp_group2/data'\n",
    "sundar_data_path = 'drive/My Drive/nlp_group2/data'\n",
    "z_data_path = 'drive/My Drive/nlp_group2/data'\n",
    "sundar_local_path = '~/Workspaces/Q2/NLP/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hux8jIA0OWWU"
   },
   "outputs": [],
   "source": [
    "data_path = blaine_ubuntu_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5X8tKzUSzAlu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['._brown_tokenized.txt', '._group2.test.txt', '._group2.tagged_valid.txt', 'group2.raw.txt', 'group2.int_test.p', 'brown_test_cost_history.p', 'group2.int_valid.p', 'group2.valid.txt', '._group2.test.p', 'group2.int_train.p', '._group2.int_tagged_valid.p', 'brown_val_perplexity_history.p', 'brown_perplexity_history.p', '._group2.tagged_train.p', 'group2.int_tagged_test.p', '._group2.train.txt', 'group2.tagged_vocab.p', 'group2.valid.p', 'group2.tagged_test.p', 'group2.tagged_test.txt', 'brown_cost_history.p', '._group2.int_valid.p', '._group2.valid.p', '._group2.int_tagged_train.p', '._group2.int_train.p', 'group2.tagged_train.txt', '._group2.tagged_train.txt', 'group2.test.txt', 'group2.test.p', 'group2.tagged_valid.txt', '._group2.vocab_dict.p', '._group2.tagged_test.txt', '._group2.tagged_vocab_dict.p', '._group2.tagged_vocab.p', '._Icon\\uf00d', '._group2.valid.txt', 'group2.vocab.p', '._group2.tagged_valid.p', 'brown_tokenized.txt', 'group2.int_tagged_valid.p', '._group2.int_test.p', 'group2.vocab_dict.p', 'group2.train.txt', '._group2.raw.txt', '._group2.int_tagged_test.p', '._group2.tagged_test.p', 'group2.tagged_vocab_dict.p', 'brown_val_cost_history.p', 'group2.int_tagged_train.p', 'brown_test_perplexity_history.p', 'group2.tagged_valid.p', '._group2.train.p', 'group2.tagged_train.p', '._group2.vocab.p', 'group2.train.p', 'Icon\\uf00d']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(data_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CWiLJQNrE72M"
   },
   "source": [
    "## Task 1\n",
    "Split train corpus with `batch_size=30` and `window=5` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V6iLwqmo_Do1"
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "int_train = pickle.load(open(os.path.join(data_path, 'group2.int_train.p'), 'rb'))\n",
    "int_validation = pickle.load(open(os.path.join(data_path, 'group2.int_valid.p'), 'rb'))\n",
    "int_test = pickle.load(open(os.path.join(data_path, 'group2.int_test.p'), 'rb'))\n",
    "train = pickle.load(open(os.path.join(data_path, 'group2.train.p'), 'rb'))\n",
    "vocab_dict = pickle.load(open(os.path.join(data_path, 'group2.vocab_dict.p'), 'rb'))\n",
    "# int_train = [vocab_dict[w] for w in train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0pw_br8mAJ58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18050, 9033, 16614, 35216, 3311, 34744, 19712, 39720, 38681, 5003] \n",
      " ['<s>', 'the', 'battle', 'of', 'fort', 'donelson', 'was', 'fought', 'from', 'february']\n",
      "vocab len: 42314\n",
      "int rep: 4628458\n",
      "train token: 4628458\n"
     ]
    }
   ],
   "source": [
    "print(int_train[:10], '\\n', train[:10])\n",
    "\n",
    "print(\"vocab len: %i\" % len(vocab_dict))\n",
    "print(\"int rep: %s\" % len(int_train))\n",
    "print(\"train token: %s\" % len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mFbxb_nIAQHn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "# batch the train integer representations\n",
    "def gen_batches(context_size, num_batches, data):\n",
    "  num_data = len(data)\n",
    "\n",
    "  # removing remainder tokens\n",
    "  remainder = num_data % math.floor(num_data/num_batches)\n",
    "  print(remainder)\n",
    "  data = data[:num_data - remainder]\n",
    "  num_data = len(data)\n",
    "\n",
    "  # batches = np.array_split(data, math.floor(num_data)/batch_size)\n",
    "  batches = np.split(np.array(data),num_batches,axis=0)\n",
    "  return batches\n",
    "\n",
    "batches_words = gen_batches(5, 30, train)\n",
    "batches_int = gen_batches(5, 30, int_train)\n",
    "# batches_embeddings = gen_batches(5, 30, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mg3b1XELNCYk"
   },
   "outputs": [],
   "source": [
    "def print_seq(batch, window, seq_idx):\n",
    "  input_tokens = batch[seq_idx:seq_idx+window]\n",
    "  target_token = batch[seq_idx+window]\n",
    "\n",
    "  print(\"input : \", input_tokens)\n",
    "  print(\"target: [\", target_token, \"]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dkBM381LNChw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- batch 01 ---\n",
      "input :  ['<s>' 'the' 'battle' 'of' 'fort']\n",
      "target: [ donelson ]\n",
      "\n",
      "input :  ['the' 'battle' 'of' 'fort' 'donelson']\n",
      "target: [ was ]\n",
      "\n",
      "input :  ['battle' 'of' 'fort' 'donelson' 'was']\n",
      "target: [ fought ]\n",
      "\n",
      "-- batch 02 --\n",
      "input :  ['the' 'battle' 'was' 'over' '</s>']\n",
      "target: [ <s> ]\n",
      "\n",
      "input :  ['battle' 'was' 'over' '</s>' '<s>']\n",
      "target: [ 72 ]\n",
      "\n",
      "input :  ['was' 'over' '</s>' '<s>' '72']\n",
      "target: [ </s> ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('--- batch 01 ---')\n",
    "print_seq(batches_words[0], 5, 0)\n",
    "print_seq(batches_words[0], 5, 1)\n",
    "print_seq(batches_words[0], 5, 2)\n",
    "\n",
    "print('-- batch 02 --')\n",
    "print_seq(batches_words[1], 5, 0)\n",
    "print_seq(batches_words[1], 5, 1)\n",
    "print_seq(batches_words[1], 5, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l6gNu8xBSizG"
   },
   "source": [
    "## Task 2: Bengio Style Feedforward network language model\n",
    "- TensorFlow version: `2.1.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RWCFC4p1RMPg"
   },
   "outputs": [],
   "source": [
    "class BengioParams():\n",
    "\n",
    "  def __init__(self, name, vocab_dict):\n",
    "    self.name = name\n",
    "    \n",
    "    self.context_window = 5\n",
    "    self.num_batches = 30\n",
    "\n",
    "    self.vocab_len = len(vocab_dict)\n",
    "    \n",
    "    self.hidden_units = 50\n",
    "    self.embeddings_dim = 60\n",
    "    self.num_epochs = 20\n",
    "\n",
    "    self.learning_rate = 0.5\n",
    "\n",
    "    self.gpu_mem = 0.25\n",
    "    \n",
    "    self.tf_precision = tf.float32\n",
    "    self.np_precision = np.float32\n",
    "\n",
    "    self.init_scale = 0.5\n",
    "    self.max_grad = 10.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cj6d3vk0U0lz"
   },
   "outputs": [],
   "source": [
    "class BengioModel():\n",
    "  \"\"\"\n",
    "  Class implements Bengio NN model with Tensorflow accoring to the function:\n",
    "    y = b + Wx + Utanh(d + Hx)\n",
    "  \n",
    "  and \n",
    "    cost = softmax_cross_entropy?\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, params):\n",
    "\n",
    "    self.Y = tf.placeholder(\n",
    "        dtype=params.tf_precision,\n",
    "        shape=(params.num_batches, params.vocab_len),\n",
    "        name=\"Y\"\n",
    "    )\n",
    "    \n",
    "    self.X = tf.placeholder(\n",
    "        tf.int32, \n",
    "        shape=(params.num_batches, params.context_window),\n",
    "        name=\"X\"\n",
    "    )\n",
    "\n",
    "    # embeddings\n",
    "    self.C = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            shape=(params.vocab_len, params.embeddings_dim),\n",
    "            mean=-1,\n",
    "            stddev=-1\n",
    "        ),\n",
    "        dtype=params.tf_precision,\n",
    "        name=\"C\"\n",
    "    )\n",
    "\n",
    "    self.W = tf.Variable(\n",
    "        tf.random_normal(\n",
    "            shape=(params.vocab_len, params.context_window * params.embeddings_dim)\n",
    "        ),\n",
    "        name=\"W\",\n",
    "        dtype=params.tf_precision\n",
    "    )\n",
    "    \n",
    "    self.H = tf.Variable(\n",
    "        tf.random_normal(\n",
    "            shape=(params.hidden_units, params.context_window * params.embeddings_dim)\n",
    "        ),\n",
    "        name=\"H\",\n",
    "        dtype=params.tf_precision\n",
    "    )\n",
    "\n",
    "    self.d = tf.Variable(\n",
    "        tf.random_normal(\n",
    "            shape=(params.hidden_units,)\n",
    "        ),\n",
    "        name=\"d\",\n",
    "        dtype=params.tf_precision\n",
    "    )\n",
    "\n",
    "    self.U = tf.Variable(\n",
    "        tf.random_normal(\n",
    "            (params.vocab_len, params.hidden_units)\n",
    "        ),\n",
    "        name=\"U\",\n",
    "        dtype=params.tf_precision\n",
    "    )\n",
    "\n",
    "    self.b = tf.Variable(\n",
    "        tf.random_normal(\n",
    "            shape=(params.vocab_len, )\n",
    "        ),\n",
    "        name=\"b\",\n",
    "        dtype=params.tf_precision\n",
    "    )\n",
    "\n",
    "    with tf.name_scope(\"Projection_Layer\"):\n",
    "      x = tf.nn.embedding_lookup(self.C, self.X)\n",
    "      x = tf.reshape(\n",
    "          x,\n",
    "          shape=(params.num_batches, params.context_window * params.embeddings_dim)\n",
    "      )\n",
    "\n",
    "    with tf.name_scope(\"Hidden_Layer\"):\n",
    "      Hx = tf.matmul(x, tf.transpose(self.H))\n",
    "      a = tf.nn.tanh(tf.add(Hx, self.d))\n",
    "\n",
    "    with tf.name_scope(\"Output_Layer\"):\n",
    "      Ua = tf.matmul(a, tf.transpose(self.U))\n",
    "      Wx = tf.matmul(x, tf.transpose(self.W))\n",
    "      Y_hat = tf.add(self.b, tf.add(Wx, Ua)) \n",
    "\n",
    "    with tf.name_scope(\"Cost\"):\n",
    "     self.cost = tf.reduce_mean( \n",
    "        tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            labels=self.Y,\n",
    "            logits=Y_hat\n",
    "        )\n",
    "      )\n",
    "     self.perplexity = tf.exp(self.cost)\n",
    "\n",
    "    self.optimizer = tf.train.GradientDescentOptimizer(params.learning_rate).minimize(self.cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "is2xf4mESMVv"
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "\n",
    "def spiltInputTarget(batch, win_idx, params):\n",
    "  _x = batch[win_idx:win_idx + params.context_window]\n",
    "  _y = np.zeros(params.vocab_len)\n",
    "  _y[batch[win_idx + params.context_window]] = 1\n",
    "  return _x, _y\n",
    "\n",
    "\n",
    "def run(model, params, batches_train_int, batches_validation_int, batches_test_int):\n",
    "\n",
    "  perplexity_history = []\n",
    "  cost_history = []\n",
    "\n",
    "  val_perplexity_history = []\n",
    "  val_cost_history = []\n",
    "\n",
    "  test_perplexity_history = []\n",
    "  test_cost_history = []\n",
    "  \n",
    "\n",
    "  gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.25)\n",
    "  with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=True)) as sess:\n",
    "    initializer = tf.global_variables_initializer()\n",
    "    initializer.run()\n",
    "    step = 0\n",
    "    for epoch in range(params.num_epochs):\n",
    "      # run model with 30 batches for a window size\n",
    "      # for idx in total number of window sizes\n",
    "        # for batch in batch_int\n",
    "      win_idx = 0\n",
    "      while win_idx < (len(batches_train_int[0]) - params.context_window - 1):\n",
    "        batch_x = []\n",
    "        batch_y = []\n",
    "        for batch in batches_train_int:\n",
    "          _x, _y = spiltInputTarget(batch, win_idx, params)\n",
    "          batch_x.append(_x)\n",
    "          batch_y.append(_y)\n",
    "        \n",
    "        cost, perplexity, _ = sess.run(\n",
    "            [model.cost, model.perplexity, model.optimizer], \n",
    "            feed_dict={ model.X:batch_x, model.Y:batch_y }\n",
    "        )\n",
    "\n",
    "        # calculate validation & test preplexity after each epoch\n",
    "\n",
    "        if step % 1000 == 0:\n",
    "          print(\"train: step {}, cost: {}, perplexity: {}\".format(step, cost, perplexity))\n",
    "          perplexity_history.append(perplexity)\n",
    "          cost_history.append(cost)\n",
    "        \n",
    "        step+=1\n",
    "        win_idx+=1\n",
    "        \n",
    "      # save model after each epoch\n",
    "      save_path = saver.save(sess, os.path.join(data_path, \"/tmp/\" + params.name +\"_\" + str(epoch+1) + \".ckpt\"))\n",
    "      print(\"Model saved in path: %s\" % save_path)\n",
    "\n",
    "      # validation\n",
    "      win_idx = 0\n",
    "      val_perplexity = 0\n",
    "      val_cost = 0\n",
    "      while win_idx < (len(batches_validation_int[0]) - params.context_window - 1):\n",
    "        val_batch_x = []\n",
    "        val_batch_y = []\n",
    "        for batch in batches_validation_int:\n",
    "          _x, _y = spiltInputTarget(batch, win_idx, params)\n",
    "          val_batch_x.append(_x)\n",
    "          val_batch_y.append(_y)\n",
    "\n",
    "        cost, perplexity = sess.run(\n",
    "            [model.cost, model.perplexity], \n",
    "            feed_dict={ model.X:val_batch_x, model.Y:val_batch_y }\n",
    "        )\n",
    "        val_perplexity = perplexity\n",
    "        val_cost = cost\n",
    "        \n",
    "        win_idx+=1\n",
    "      \n",
    "      val_perplexity_history.append(val_perplexity)\n",
    "      val_cost_history.append(val_cost)\n",
    "      print(\"validation: epoch {}, cost: {}, perplexity: {}\".format(epoch+1, val_cost, val_perplexity))\n",
    "\n",
    "      # test\n",
    "      win_idx = 0\n",
    "      test_perplexity = 0\n",
    "      test_cost = 0\n",
    "      while win_idx < (len(batches_test_int[0]) - params.context_window - 1):\n",
    "        test_batch_x = []\n",
    "        test_batch_y = []\n",
    "        for batch in batches_test_int:\n",
    "          _x, _y = spiltInputTarget(batch, win_idx, params)\n",
    "          test_batch_x.append(_x)\n",
    "          test_batch_y.append(_y)\n",
    "\n",
    "        cost, perplexity = sess.run(\n",
    "            [model.cost, model.perplexity], \n",
    "            feed_dict={ model.X:test_batch_x, model.Y:test_batch_y }\n",
    "        )\n",
    "        test_perplexity = perplexity\n",
    "        test_cost = cost\n",
    "        \n",
    "        win_idx+=1\n",
    "      \n",
    "      test_perplexity_history.append(test_perplexity)\n",
    "      test_cost_history.append(test_cost)\n",
    "      print(\"test: epoch {}, cost: {}, perplexity: {}\".format(epoch+1, test_cost, test_perplexity_history))\n",
    "\n",
    "  return perplexity_history, cost_history, val_perplexity_history, val_cost_history, test_perplexity_history, test_cost_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rWBxECjWWXn4"
   },
   "outputs": [],
   "source": [
    "# brown\n",
    "\n",
    "# read the brown corpus text file\n",
    "with open(os.path.join(data_path, 'brown_tokenized.txt'), 'r') as f:\n",
    "  brown_tokens_all = f.readline().split(\" \")\n",
    "\n",
    "# remove tokens with less than 3 freq\n",
    "brown_tok_freq = {}\n",
    "for idx, tok in enumerate(brown_tokens_all):\n",
    "  brown_tok_freq[tok] = brown_tok_freq.get(tok, 0) + 1\n",
    "\n",
    "brown_tokens_all = [tok for tok in filter(lambda x: brown_tok_freq[x] >= 3, brown_tokens_all)]  \n",
    "\n",
    "# create vocab\n",
    "brown_vocab = set([tok for tok in brown_tokens_all])\n",
    "\n",
    "# create train, validation, test\n",
    "brown_train = brown_tokens_all[:800000]\n",
    "brown_validation = brown_tokens_all[800000:1000000]\n",
    "brown_test = brown_tokens_all[1000000:]\n",
    "\n",
    "print(\"size of brown vocab: %i\" % len(brown_vocab))\n",
    "\n",
    "# integer representation\n",
    "brown_vocab_dict = {}\n",
    "for i, v in enumerate(brown_vocab):\n",
    "    brown_vocab_dict[v] = i\n",
    "\n",
    "brown_train_int = [brown_vocab_dict[tok] for tok in brown_train]\n",
    "brown_validation_int = [brown_vocab_dict[tok] for tok in brown_validation]\n",
    "brown_test_int = [brown_vocab_dict[tok] for tok in brown_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7owo5_W9Wb7E"
   },
   "outputs": [],
   "source": [
    "# train on brown\n",
    "# brown_train_int\n",
    "\n",
    "brown_params = BengioParams(brown_vocab_dict)\n",
    "brown_model = BengioModel(name=\"p2_brown\", params=brown_params)\n",
    "\n",
    "brown_train_batches_int = gen_batches(5, 30, brown_train_int)\n",
    "brown_val_batches_int = gen_batches(5, 30, brown_validation_int)\n",
    "brown_test_batches_int = gen_batches(5, 30, brown_test_int)\n",
    "\n",
    "brown_perplexity_history,  brown_cost_history, brown_val_perplexity_history, brown_val_cost_history, brown_test_perplexity_history, brown_test_cost_history = run(brown_model, brown_params, brown_train_batches_int, brown_val_batches_int, brown_test_batches_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1z2jH1dsIE_"
   },
   "outputs": [],
   "source": [
    "# save brown files\n",
    "import pickle\n",
    "\n",
    "pickle.dump(brown_perplexity_history, open(os.path.join(data_path, 'brown_perplexity_history.p'), 'wb'))\n",
    "pickle.dump(brown_cost_history, open(os.path.join(data_path, 'brown_cost_history.p'), 'wb'))\n",
    "pickle.dump(brown_val_perplexity_history, open(os.path.join(data_path, 'brown_val_perplexity_history.p'), 'wb'))\n",
    "pickle.dump(brown_val_cost_history, open(os.path.join(data_path, 'brown_val_cost_history.p'), 'wb'))\n",
    "pickle.dump(brown_test_perplexity_history, open(os.path.join(data_path, 'brown_test_perplexity_history.p'), 'wb'))\n",
    "pickle.dump(brown_test_cost_history, open(os.path.join(data_path, 'brown_test_cost_history.p'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QPOb8kVXAzRa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "6\n",
      "7\n",
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:XLA_CPU:0 -> device: XLA_CPU device\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "/job:localhost/replica:0/task:0/device:XLA_GPU:0 -> device: XLA_GPU device\n",
      "\n",
      "train: step 0, cost: 45.23798751831055, perplexity: 4.432087830904596e+19\n",
      "train: step 1000, cost: 9.845108985900879, perplexity: 18865.85546875\n",
      "train: step 2000, cost: 10.878351211547852, perplexity: 53016.1171875\n",
      "train: step 3000, cost: 9.460535049438477, perplexity: 12842.75390625\n",
      "train: step 4000, cost: 9.95299243927002, perplexity: 21015.013671875\n",
      "train: step 5000, cost: 9.27669906616211, perplexity: 10686.099609375\n",
      "train: step 6000, cost: 8.430233001708984, perplexity: 4583.56787109375\n",
      "train: step 7000, cost: 7.677794456481934, perplexity: 2159.850830078125\n",
      "train: step 8000, cost: 8.279935836791992, perplexity: 3943.941162109375\n",
      "train: step 9000, cost: 11.067889213562012, perplexity: 64080.1015625\n",
      "train: step 10000, cost: 9.772547721862793, perplexity: 17545.41015625\n",
      "train: step 11000, cost: 10.593363761901855, perplexity: 39869.375\n",
      "train: step 12000, cost: 9.292019844055176, perplexity: 10851.080078125\n",
      "train: step 13000, cost: 9.524839401245117, perplexity: 13695.7294921875\n",
      "train: step 14000, cost: 9.45517349243164, perplexity: 12774.0810546875\n",
      "train: step 15000, cost: 9.572992324829102, perplexity: 14371.35546875\n",
      "train: step 16000, cost: 12.97875690460205, perplexity: 433114.3125\n",
      "train: step 17000, cost: 9.127795219421387, perplexity: 9207.69921875\n",
      "train: step 18000, cost: 7.323071002960205, perplexity: 1514.8489990234375\n",
      "train: step 19000, cost: 11.879759788513184, perplexity: 144315.875\n",
      "train: step 20000, cost: 10.970259666442871, perplexity: 58119.68359375\n",
      "train: step 21000, cost: 8.138474464416504, perplexity: 3423.69091796875\n",
      "train: step 22000, cost: 11.062776565551758, perplexity: 63753.3203125\n",
      "train: step 23000, cost: 6.153314113616943, perplexity: 470.2733459472656\n",
      "train: step 24000, cost: 11.77725887298584, perplexity: 130256.25\n",
      "train: step 25000, cost: 8.383451461791992, perplexity: 4374.07958984375\n",
      "train: step 26000, cost: 7.745747089385986, perplexity: 2311.7197265625\n",
      "train: step 27000, cost: 9.593880653381348, perplexity: 14674.7060546875\n",
      "train: step 28000, cost: 8.229568481445312, perplexity: 3750.215087890625\n",
      "train: step 29000, cost: 7.906038284301758, perplexity: 2713.618408203125\n",
      "train: step 30000, cost: 6.847535133361816, perplexity: 941.5571899414062\n",
      "train: step 31000, cost: 8.759310722351074, perplexity: 6369.7197265625\n",
      "train: step 32000, cost: 8.387490272521973, perplexity: 4391.78173828125\n",
      "train: step 33000, cost: 8.578393936157227, perplexity: 5315.5615234375\n",
      "train: step 34000, cost: 11.083870887756348, perplexity: 65112.4375\n",
      "train: step 35000, cost: 7.838420391082764, perplexity: 2536.195556640625\n",
      "train: step 36000, cost: 7.009685039520264, perplexity: 1107.3056640625\n",
      "train: step 37000, cost: 8.115364074707031, perplexity: 3345.475341796875\n",
      "train: step 38000, cost: 8.401103019714355, perplexity: 4451.974609375\n",
      "train: step 39000, cost: 8.546039581298828, perplexity: 5146.33251953125\n",
      "train: step 40000, cost: 8.081546783447266, perplexity: 3234.232177734375\n",
      "train: step 41000, cost: 9.217987060546875, perplexity: 10076.759765625\n",
      "train: step 42000, cost: 10.220719337463379, perplexity: 27466.416015625\n",
      "train: step 43000, cost: 7.285769462585449, perplexity: 1459.3836669921875\n",
      "train: step 44000, cost: 8.720322608947754, perplexity: 6126.1552734375\n",
      "train: step 45000, cost: 8.344730377197266, perplexity: 4207.94775390625\n",
      "train: step 46000, cost: 9.146676063537598, perplexity: 9383.2001953125\n",
      "train: step 47000, cost: 10.108159065246582, perplexity: 24542.4375\n",
      "train: step 48000, cost: 7.16486120223999, perplexity: 1293.1820068359375\n",
      "train: step 49000, cost: 7.013984203338623, perplexity: 1112.076416015625\n",
      "train: step 50000, cost: 10.31328296661377, perplexity: 30130.189453125\n",
      "train: step 51000, cost: 8.901577949523926, perplexity: 7343.5517578125\n",
      "train: step 52000, cost: 9.969635963439941, perplexity: 21367.705078125\n",
      "train: step 53000, cost: 11.752717971801758, perplexity: 127098.546875\n",
      "train: step 54000, cost: 7.88950252532959, perplexity: 2669.11572265625\n",
      "train: step 55000, cost: 8.319649696350098, perplexity: 4103.72216796875\n",
      "train: step 56000, cost: 9.122461318969727, perplexity: 9158.716796875\n",
      "train: step 57000, cost: 8.912210464477539, perplexity: 7422.048828125\n",
      "train: step 58000, cost: 7.845545291900635, perplexity: 2554.330078125\n",
      "train: step 59000, cost: 7.359113693237305, perplexity: 1570.444091796875\n",
      "train: step 60000, cost: 8.216443061828613, perplexity: 3701.313720703125\n",
      "train: step 61000, cost: 7.598351001739502, perplexity: 1994.903564453125\n",
      "train: step 62000, cost: 8.847472190856934, perplexity: 6956.78125\n",
      "train: step 63000, cost: 6.4089508056640625, perplexity: 607.2562255859375\n",
      "train: step 64000, cost: 9.074861526489258, perplexity: 8732.9765625\n",
      "train: step 65000, cost: 8.391247749328613, perplexity: 4408.31494140625\n",
      "train: step 66000, cost: 8.569125175476074, perplexity: 5266.5205078125\n",
      "train: step 67000, cost: 8.76485538482666, perplexity: 6405.13525390625\n",
      "train: step 68000, cost: 8.24364948272705, perplexity: 3803.395263671875\n",
      "train: step 69000, cost: 9.814143180847168, perplexity: 18290.611328125\n",
      "train: step 70000, cost: 8.838994979858398, perplexity: 6898.05615234375\n",
      "train: step 71000, cost: 9.98931884765625, perplexity: 21792.44921875\n",
      "train: step 72000, cost: 8.334442138671875, perplexity: 4164.87744140625\n",
      "train: step 73000, cost: 9.946455001831055, perplexity: 20878.078125\n",
      "train: step 74000, cost: 7.0939531326293945, perplexity: 1204.66064453125\n",
      "train: step 75000, cost: 8.79317569732666, perplexity: 6589.1240234375\n",
      "train: step 76000, cost: 7.81199836730957, perplexity: 2470.0615234375\n",
      "train: step 77000, cost: 7.633884906768799, perplexity: 2067.06494140625\n",
      "train: step 78000, cost: 8.109124183654785, perplexity: 3324.6650390625\n",
      "train: step 79000, cost: 9.35422134399414, perplexity: 11547.466796875\n",
      "train: step 80000, cost: 10.13182544708252, perplexity: 25130.197265625\n",
      "train: step 81000, cost: 7.620032787322998, perplexity: 2038.62890625\n",
      "train: step 82000, cost: 7.825251579284668, perplexity: 2503.015869140625\n",
      "train: step 83000, cost: 9.301342964172363, perplexity: 10952.71875\n",
      "train: step 84000, cost: 9.618249893188477, perplexity: 15036.7109375\n",
      "train: step 85000, cost: 6.62294864654541, perplexity: 752.1597290039062\n",
      "train: step 86000, cost: 9.759393692016602, perplexity: 17316.130859375\n",
      "train: step 87000, cost: 8.310779571533203, perplexity: 4067.482421875\n",
      "train: step 88000, cost: 10.027044296264648, perplexity: 22630.28515625\n",
      "train: step 89000, cost: 10.839577674865723, perplexity: 50999.8359375\n",
      "train: step 90000, cost: 8.478849411010742, perplexity: 4811.91015625\n",
      "train: step 91000, cost: 8.780791282653809, perplexity: 6508.02490234375\n",
      "train: step 92000, cost: 7.227842330932617, perplexity: 1377.2476806640625\n",
      "train: step 93000, cost: 8.019317626953125, perplexity: 3039.102783203125\n",
      "train: step 94000, cost: 7.584493160247803, perplexity: 1967.44921875\n",
      "train: step 95000, cost: 7.761410713195801, perplexity: 2348.215087890625\n",
      "train: step 96000, cost: 7.887624263763428, perplexity: 2664.107177734375\n",
      "train: step 97000, cost: 7.499124050140381, perplexity: 1806.459228515625\n",
      "train: step 98000, cost: 8.416900634765625, perplexity: 4522.86376953125\n",
      "train: step 99000, cost: 10.974184036254883, perplexity: 58348.21484375\n",
      "train: step 100000, cost: 10.024087905883789, perplexity: 22563.478515625\n",
      "train: step 101000, cost: 11.363932609558105, perplexity: 86157.53125\n",
      "train: step 102000, cost: 9.27560043334961, perplexity: 10674.3662109375\n",
      "train: step 103000, cost: 7.5033111572265625, perplexity: 1814.0389404296875\n",
      "train: step 104000, cost: 8.76456069946289, perplexity: 6403.248046875\n",
      "train: step 105000, cost: 8.620677947998047, perplexity: 5545.14453125\n",
      "train: step 106000, cost: 7.712331295013428, perplexity: 2235.74853515625\n",
      "train: step 107000, cost: 9.187085151672363, perplexity: 9770.130859375\n",
      "train: step 108000, cost: 7.358818054199219, perplexity: 1569.9798583984375\n",
      "train: step 109000, cost: 8.042159080505371, perplexity: 3109.3193359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 110000, cost: 7.141575336456299, perplexity: 1263.4171142578125\n",
      "train: step 111000, cost: 6.967850208282471, perplexity: 1061.937255859375\n",
      "train: step 112000, cost: 9.32162094116211, perplexity: 11177.0849609375\n",
      "train: step 113000, cost: 8.383399963378906, perplexity: 4373.8544921875\n",
      "train: step 114000, cost: 7.622907638549805, perplexity: 2044.498046875\n",
      "train: step 115000, cost: 10.156434059143066, perplexity: 25756.287109375\n",
      "train: step 116000, cost: 7.6013336181640625, perplexity: 2000.8624267578125\n",
      "train: step 117000, cost: 6.535459518432617, perplexity: 689.1504516601562\n",
      "train: step 118000, cost: 8.75282096862793, perplexity: 6328.51513671875\n",
      "train: step 119000, cost: 12.518902778625488, perplexity: 273457.84375\n",
      "train: step 120000, cost: 7.076120853424072, perplexity: 1183.369140625\n",
      "train: step 121000, cost: 11.365167617797852, perplexity: 86264.0\n",
      "train: step 122000, cost: 8.725149154663086, perplexity: 6155.79443359375\n",
      "train: step 123000, cost: 7.898001194000244, perplexity: 2691.896484375\n",
      "train: step 124000, cost: 9.081048965454102, perplexity: 8787.1787109375\n",
      "train: step 125000, cost: 7.326828956604004, perplexity: 1520.5523681640625\n",
      "train: step 126000, cost: 7.713168144226074, perplexity: 2237.6201171875\n",
      "train: step 127000, cost: 8.636007308959961, perplexity: 5630.802734375\n",
      "train: step 128000, cost: 8.113306999206543, perplexity: 3338.600341796875\n",
      "train: step 129000, cost: 8.722859382629395, perplexity: 6141.71533203125\n",
      "train: step 130000, cost: 8.433575630187988, perplexity: 4598.91455078125\n",
      "train: step 131000, cost: 8.084453582763672, perplexity: 3243.64697265625\n",
      "train: step 132000, cost: 7.099046230316162, perplexity: 1210.8116455078125\n",
      "train: step 133000, cost: 8.291556358337402, perplexity: 3990.0390625\n",
      "train: step 134000, cost: 8.106842994689941, perplexity: 3317.089599609375\n",
      "train: step 135000, cost: 7.392241954803467, perplexity: 1623.341552734375\n",
      "train: step 136000, cost: 8.997206687927246, perplexity: 8080.48095703125\n",
      "train: step 137000, cost: 7.67677116394043, perplexity: 2157.641845703125\n",
      "train: step 138000, cost: 11.840337753295898, perplexity: 138737.34375\n",
      "train: step 139000, cost: 9.449227333068848, perplexity: 12698.3505859375\n",
      "train: step 140000, cost: 8.315770149230957, perplexity: 4087.832275390625\n",
      "train: step 141000, cost: 8.52348804473877, perplexity: 5031.57373046875\n",
      "train: step 142000, cost: 9.855813026428223, perplexity: 19068.880859375\n",
      "train: step 143000, cost: 8.283778190612793, perplexity: 3959.12451171875\n",
      "train: step 144000, cost: 9.295135498046875, perplexity: 10884.9404296875\n",
      "train: step 145000, cost: 7.734592914581299, perplexity: 2286.07763671875\n",
      "train: step 146000, cost: 10.508864402770996, perplexity: 36638.84765625\n",
      "train: step 147000, cost: 7.243481636047363, perplexity: 1398.9561767578125\n",
      "train: step 148000, cost: 8.813862800598145, perplexity: 6726.85400390625\n",
      "train: step 149000, cost: 8.038290977478027, perplexity: 3097.315185546875\n",
      "train: step 150000, cost: 7.806731224060059, perplexity: 2457.085693359375\n",
      "train: step 151000, cost: 9.019088745117188, perplexity: 8259.248046875\n",
      "train: step 152000, cost: 7.188706398010254, perplexity: 1324.388916015625\n",
      "train: step 153000, cost: 7.824797630310059, perplexity: 2501.879638671875\n",
      "train: step 154000, cost: 8.118413925170898, perplexity: 3355.694091796875\n",
      "Model saved in path: /tmp/p2_run02_1.ckpt\n",
      "validation: epoch 1, cost: 8.973691940307617, perplexity: 7892.68701171875\n",
      "test: epoch 1, cost: 9.861285209655762, perplexity: [19173.516]\n",
      "train: step 155000, cost: 7.441542625427246, perplexity: 1705.37890625\n",
      "train: step 156000, cost: 8.303069114685059, perplexity: 4036.240966796875\n",
      "train: step 157000, cost: 8.969822883605957, perplexity: 7862.20849609375\n",
      "train: step 158000, cost: 11.072054862976074, perplexity: 64347.59375\n",
      "train: step 159000, cost: 8.772217750549316, perplexity: 6452.466796875\n",
      "train: step 160000, cost: 7.568845748901367, perplexity: 1936.9031982421875\n",
      "train: step 161000, cost: 6.794772148132324, perplexity: 893.1657104492188\n",
      "train: step 162000, cost: 8.05622673034668, perplexity: 3153.369140625\n",
      "train: step 163000, cost: 10.561989784240723, perplexity: 38637.93359375\n",
      "train: step 164000, cost: 7.822648525238037, perplexity: 2496.508544921875\n",
      "train: step 165000, cost: 6.238892078399658, perplexity: 512.2906494140625\n",
      "train: step 166000, cost: 8.037921905517578, perplexity: 3096.17236328125\n",
      "train: step 167000, cost: 8.917641639709473, perplexity: 7462.46923828125\n",
      "train: step 168000, cost: 9.142253875732422, perplexity: 9341.796875\n",
      "train: step 169000, cost: 10.389196395874023, perplexity: 32506.533203125\n",
      "train: step 170000, cost: 9.768980026245117, perplexity: 17482.927734375\n",
      "train: step 171000, cost: 11.032291412353516, perplexity: 61839.11328125\n",
      "train: step 172000, cost: 7.429511070251465, perplexity: 1684.9835205078125\n",
      "train: step 173000, cost: 8.483244895935059, perplexity: 4833.107421875\n",
      "train: step 174000, cost: 7.839269161224365, perplexity: 2538.34912109375\n",
      "train: step 175000, cost: 9.006053924560547, perplexity: 8152.2880859375\n",
      "train: step 176000, cost: 8.66408634185791, perplexity: 5791.15087890625\n",
      "train: step 177000, cost: 6.587583541870117, perplexity: 726.0243530273438\n",
      "train: step 178000, cost: 8.334723472595215, perplexity: 4166.04931640625\n",
      "train: step 179000, cost: 8.60814094543457, perplexity: 5476.05859375\n",
      "train: step 180000, cost: 10.477011680603027, perplexity: 35490.19140625\n",
      "train: step 181000, cost: 6.803569316864014, perplexity: 901.0577392578125\n",
      "train: step 182000, cost: 10.132329940795898, perplexity: 25142.87890625\n",
      "train: step 183000, cost: 7.518542289733887, perplexity: 1841.88037109375\n",
      "train: step 184000, cost: 6.80058479309082, perplexity: 898.3724975585938\n",
      "train: step 185000, cost: 6.500665187835693, perplexity: 665.584228515625\n",
      "train: step 186000, cost: 8.633054733276367, perplexity: 5614.2021484375\n",
      "train: step 187000, cost: 10.29312515258789, perplexity: 29528.912109375\n",
      "train: step 188000, cost: 7.8444905281066895, perplexity: 2551.637451171875\n",
      "train: step 189000, cost: 7.602345943450928, perplexity: 2002.8890380859375\n",
      "train: step 190000, cost: 7.929604530334473, perplexity: 2778.327880859375\n",
      "train: step 191000, cost: 8.406229019165039, perplexity: 4474.85400390625\n",
      "train: step 192000, cost: 9.670186996459961, perplexity: 15838.310546875\n",
      "train: step 193000, cost: 8.289752006530762, perplexity: 3982.845947265625\n",
      "train: step 194000, cost: 9.628725051879883, perplexity: 15195.05078125\n",
      "train: step 195000, cost: 8.684983253479004, perplexity: 5913.44189453125\n",
      "train: step 196000, cost: 10.102702140808105, perplexity: 24408.876953125\n",
      "train: step 197000, cost: 11.051715850830078, perplexity: 63052.05078125\n",
      "train: step 198000, cost: 11.317774772644043, perplexity: 82271.0703125\n",
      "train: step 199000, cost: 9.79904556274414, perplexity: 18016.541015625\n",
      "train: step 200000, cost: 9.414923667907715, perplexity: 12270.13671875\n",
      "train: step 201000, cost: 10.334836959838867, perplexity: 30786.666015625\n",
      "train: step 202000, cost: 7.683480739593506, perplexity: 2172.16748046875\n",
      "train: step 203000, cost: 7.663602352142334, perplexity: 2129.41455078125\n",
      "train: step 204000, cost: 10.10507583618164, perplexity: 24466.884765625\n",
      "train: step 205000, cost: 10.807805061340332, perplexity: 49404.90625\n",
      "train: step 206000, cost: 7.187376976013184, perplexity: 1322.62939453125\n",
      "train: step 207000, cost: 9.48266315460205, perplexity: 13130.1083984375\n",
      "train: step 208000, cost: 7.32475471496582, perplexity: 1517.401611328125\n",
      "train: step 209000, cost: 8.321730613708496, perplexity: 4112.2705078125\n",
      "train: step 210000, cost: 6.969850540161133, perplexity: 1064.063720703125\n",
      "train: step 211000, cost: 6.909669399261475, perplexity: 1001.9158935546875\n",
      "train: step 212000, cost: 7.496312141418457, perplexity: 1801.3868408203125\n",
      "train: step 213000, cost: 8.217336654663086, perplexity: 3704.62255859375\n",
      "train: step 214000, cost: 9.36121654510498, perplexity: 11628.5263671875\n",
      "train: step 215000, cost: 9.01664924621582, perplexity: 8239.1240234375\n",
      "train: step 216000, cost: 9.286869049072266, perplexity: 10795.33203125\n",
      "train: step 217000, cost: 7.658118724822998, perplexity: 2117.76953125\n",
      "train: step 218000, cost: 9.004415512084961, perplexity: 8138.94189453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 219000, cost: 7.138317584991455, perplexity: 1259.307861328125\n",
      "train: step 220000, cost: 8.987711906433105, perplexity: 8004.12158203125\n",
      "train: step 221000, cost: 8.285526275634766, perplexity: 3966.051513671875\n",
      "train: step 222000, cost: 8.017208099365234, perplexity: 3032.698486328125\n",
      "train: step 223000, cost: 9.032891273498535, perplexity: 8374.0361328125\n",
      "train: step 224000, cost: 7.706980228424072, perplexity: 2223.816650390625\n",
      "train: step 225000, cost: 11.35206127166748, perplexity: 85140.765625\n",
      "train: step 226000, cost: 7.750917434692383, perplexity: 2323.703125\n",
      "train: step 227000, cost: 8.051082611083984, perplexity: 3137.189453125\n",
      "train: step 228000, cost: 11.471220016479492, perplexity: 95915.2265625\n",
      "train: step 229000, cost: 7.715759754180908, perplexity: 2243.4267578125\n",
      "train: step 230000, cost: 8.104205131530762, perplexity: 3308.35107421875\n",
      "train: step 231000, cost: 9.074076652526855, perplexity: 8726.125\n",
      "train: step 232000, cost: 7.2422332763671875, perplexity: 1397.2108154296875\n",
      "train: step 233000, cost: 8.167909622192383, perplexity: 3525.965576171875\n",
      "train: step 234000, cost: 7.642548561096191, perplexity: 2085.051025390625\n",
      "train: step 235000, cost: 9.401342391967773, perplexity: 12104.6181640625\n",
      "train: step 236000, cost: 10.062216758728027, perplexity: 23440.41015625\n",
      "train: step 237000, cost: 8.631124496459961, perplexity: 5603.3759765625\n",
      "train: step 238000, cost: 8.05039119720459, perplexity: 3135.021240234375\n",
      "train: step 239000, cost: 8.56601333618164, perplexity: 5250.1572265625\n",
      "train: step 240000, cost: 11.020041465759277, perplexity: 61086.2109375\n",
      "train: step 241000, cost: 8.801032066345215, perplexity: 6641.0947265625\n",
      "train: step 242000, cost: 8.186174392700195, perplexity: 3590.958251953125\n",
      "train: step 243000, cost: 8.280171394348145, perplexity: 3944.87060546875\n",
      "train: step 244000, cost: 9.902093887329102, perplexity: 19972.146484375\n",
      "train: step 245000, cost: 7.234792232513428, perplexity: 1386.8526611328125\n",
      "train: step 246000, cost: 8.572468757629395, perplexity: 5284.1591796875\n",
      "train: step 247000, cost: 7.713778495788574, perplexity: 2238.986328125\n",
      "train: step 248000, cost: 9.474285125732422, perplexity: 13020.5625\n",
      "train: step 249000, cost: 9.156941413879395, perplexity: 9480.017578125\n",
      "train: step 250000, cost: 8.40861701965332, perplexity: 4485.552734375\n",
      "train: step 251000, cost: 9.128595352172852, perplexity: 9215.0693359375\n",
      "train: step 252000, cost: 10.059187889099121, perplexity: 23369.51953125\n",
      "train: step 253000, cost: 7.197248458862305, perplexity: 1335.7503662109375\n",
      "train: step 254000, cost: 11.468277931213379, perplexity: 95633.4453125\n",
      "train: step 255000, cost: 9.453934669494629, perplexity: 12758.2666015625\n",
      "train: step 256000, cost: 8.91129207611084, perplexity: 7415.23583984375\n",
      "train: step 257000, cost: 7.662057399749756, perplexity: 2126.127197265625\n",
      "train: step 258000, cost: 11.24594783782959, perplexity: 76569.015625\n",
      "train: step 259000, cost: 7.16864013671875, perplexity: 1298.0782470703125\n",
      "train: step 260000, cost: 7.627538681030273, perplexity: 2053.98828125\n",
      "train: step 261000, cost: 7.421069145202637, perplexity: 1670.81884765625\n",
      "train: step 262000, cost: 12.799832344055176, perplexity: 362156.71875\n",
      "train: step 263000, cost: 9.649802207946777, perplexity: 15518.716796875\n",
      "train: step 264000, cost: 8.729691505432129, perplexity: 6183.8203125\n",
      "train: step 265000, cost: 6.1544389724731445, perplexity: 470.8026123046875\n",
      "train: step 266000, cost: 7.32659912109375, perplexity: 1520.2030029296875\n",
      "train: step 267000, cost: 9.02391242980957, perplexity: 8299.18359375\n",
      "train: step 268000, cost: 8.337850570678711, perplexity: 4179.09765625\n",
      "train: step 269000, cost: 6.830193042755127, perplexity: 925.369384765625\n",
      "train: step 270000, cost: 8.044478416442871, perplexity: 3116.539306640625\n",
      "train: step 271000, cost: 7.48464298248291, perplexity: 1780.48828125\n",
      "train: step 272000, cost: 8.186074256896973, perplexity: 3590.5986328125\n",
      "train: step 273000, cost: 7.860211372375488, perplexity: 2592.068115234375\n",
      "train: step 274000, cost: 7.1213483810424805, perplexity: 1238.11865234375\n",
      "train: step 275000, cost: 7.743170261383057, perplexity: 2305.770751953125\n",
      "train: step 276000, cost: 6.486608028411865, perplexity: 656.29345703125\n",
      "train: step 277000, cost: 7.9288249015808105, perplexity: 2776.16259765625\n",
      "train: step 278000, cost: 10.339557647705078, perplexity: 30932.34375\n",
      "train: step 279000, cost: 7.631161212921143, perplexity: 2061.4423828125\n",
      "train: step 280000, cost: 7.301924228668213, perplexity: 1483.151123046875\n",
      "train: step 281000, cost: 7.551743984222412, perplexity: 1904.0604248046875\n",
      "train: step 282000, cost: 9.820682525634766, perplexity: 18410.61328125\n",
      "train: step 283000, cost: 8.473047256469727, perplexity: 4784.07177734375\n",
      "train: step 284000, cost: 9.525354385375977, perplexity: 13702.7841796875\n",
      "train: step 285000, cost: 8.868485450744629, perplexity: 7104.5126953125\n",
      "train: step 286000, cost: 9.616494178771973, perplexity: 15010.333984375\n",
      "train: step 287000, cost: 8.888668060302734, perplexity: 7249.35693359375\n",
      "train: step 288000, cost: 9.395087242126465, perplexity: 12029.1396484375\n",
      "train: step 289000, cost: 7.697833061218262, perplexity: 2203.56787109375\n",
      "train: step 290000, cost: 10.54822826385498, perplexity: 38109.85546875\n",
      "train: step 291000, cost: 9.251336097717285, perplexity: 10418.4765625\n",
      "train: step 292000, cost: 8.06580924987793, perplexity: 3183.731689453125\n",
      "train: step 293000, cost: 8.320076942443848, perplexity: 4105.47607421875\n",
      "train: step 294000, cost: 10.588541984558105, perplexity: 39677.59765625\n",
      "train: step 295000, cost: 10.912423133850098, perplexity: 54853.6015625\n",
      "train: step 296000, cost: 12.50266170501709, perplexity: 269052.46875\n",
      "train: step 297000, cost: 9.219417572021484, perplexity: 10091.185546875\n",
      "train: step 298000, cost: 9.513456344604492, perplexity: 13540.71484375\n",
      "train: step 299000, cost: 12.741341590881348, perplexity: 341581.5\n",
      "train: step 300000, cost: 10.16830825805664, perplexity: 26063.9453125\n",
      "train: step 301000, cost: 9.091650009155273, perplexity: 8880.828125\n",
      "train: step 302000, cost: 9.098267555236816, perplexity: 8939.7919921875\n",
      "train: step 303000, cost: 7.495520114898682, perplexity: 1799.960693359375\n",
      "train: step 304000, cost: 8.959019660949707, perplexity: 7777.728515625\n",
      "train: step 305000, cost: 10.497797012329102, perplexity: 36235.58984375\n",
      "train: step 306000, cost: 14.522868156433105, perplexity: 2028623.75\n",
      "train: step 307000, cost: 9.246221542358398, perplexity: 10365.3271484375\n",
      "train: step 308000, cost: 7.453267574310303, perplexity: 1725.4920654296875\n",
      "Model saved in path: /tmp/p2_run02_2.ckpt\n",
      "validation: epoch 2, cost: 8.804615020751953, perplexity: 6664.931640625\n",
      "test: epoch 2, cost: 9.775237083435059, perplexity: [19173.516, 17592.662]\n",
      "train: step 309000, cost: 6.236927509307861, perplexity: 511.28515625\n",
      "train: step 310000, cost: 9.993318557739258, perplexity: 21879.787109375\n",
      "train: step 311000, cost: 8.678629875183105, perplexity: 5875.99072265625\n",
      "train: step 312000, cost: 7.210765361785889, perplexity: 1353.9281005859375\n",
      "train: step 313000, cost: 10.251053810119629, perplexity: 28312.361328125\n",
      "train: step 314000, cost: 7.804590225219727, perplexity: 2451.83056640625\n",
      "train: step 315000, cost: 10.679508209228516, perplexity: 43456.17578125\n",
      "train: step 316000, cost: 8.591023445129395, perplexity: 5383.1201171875\n",
      "train: step 317000, cost: 10.53165054321289, perplexity: 37483.2890625\n",
      "train: step 318000, cost: 8.124547958374023, perplexity: 3376.34130859375\n",
      "train: step 319000, cost: 8.065502166748047, perplexity: 3182.75439453125\n",
      "train: step 320000, cost: 9.957596778869629, perplexity: 21111.998046875\n",
      "train: step 321000, cost: 8.779760360717773, perplexity: 6501.31884765625\n",
      "train: step 322000, cost: 10.80309009552002, perplexity: 49172.515625\n",
      "train: step 323000, cost: 9.893927574157715, perplexity: 19809.7109375\n",
      "train: step 324000, cost: 8.356205940246582, perplexity: 4256.5146484375\n",
      "train: step 325000, cost: 7.887610912322998, perplexity: 2664.071533203125\n",
      "train: step 326000, cost: 8.450319290161133, perplexity: 4676.5654296875\n",
      "train: step 327000, cost: 11.372222900390625, perplexity: 86874.765625\n",
      "train: step 328000, cost: 8.621557235717773, perplexity: 5550.0224609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 329000, cost: 12.746240615844727, perplexity: 343259.03125\n",
      "train: step 330000, cost: 8.88845157623291, perplexity: 7247.78759765625\n",
      "train: step 331000, cost: 7.84929895401001, perplexity: 2563.936279296875\n",
      "train: step 332000, cost: 8.297170639038086, perplexity: 4012.50341796875\n",
      "train: step 333000, cost: 8.605420112609863, perplexity: 5461.1796875\n",
      "train: step 334000, cost: 8.115525245666504, perplexity: 3346.0146484375\n",
      "train: step 335000, cost: 9.31087589263916, perplexity: 11057.62890625\n",
      "train: step 336000, cost: 8.915857315063477, perplexity: 7449.16552734375\n",
      "train: step 337000, cost: 8.984391212463379, perplexity: 7977.58642578125\n",
      "train: step 338000, cost: 8.277371406555176, perplexity: 3933.84033203125\n",
      "train: step 339000, cost: 7.778325080871582, perplexity: 2388.271240234375\n",
      "train: step 340000, cost: 11.212956428527832, perplexity: 74084.109375\n",
      "train: step 341000, cost: 8.277788162231445, perplexity: 3935.47998046875\n",
      "train: step 342000, cost: 8.572175979614258, perplexity: 5282.6123046875\n",
      "train: step 343000, cost: 8.52356243133545, perplexity: 5031.9482421875\n",
      "train: step 344000, cost: 7.923468589782715, perplexity: 2761.33251953125\n",
      "train: step 345000, cost: 6.520482540130615, perplexity: 678.9058837890625\n",
      "train: step 346000, cost: 10.206149101257324, perplexity: 27069.125\n",
      "train: step 347000, cost: 7.9738383293151855, perplexity: 2903.982421875\n",
      "train: step 348000, cost: 7.124569416046143, perplexity: 1242.1131591796875\n",
      "train: step 349000, cost: 7.3955278396606445, perplexity: 1628.684326171875\n",
      "train: step 350000, cost: 10.367938995361328, perplexity: 31822.8203125\n",
      "train: step 351000, cost: 8.7528076171875, perplexity: 6328.43115234375\n",
      "train: step 352000, cost: 7.499056339263916, perplexity: 1806.3370361328125\n",
      "train: step 353000, cost: 7.379525184631348, perplexity: 1602.8284912109375\n",
      "train: step 354000, cost: 10.986865043640137, perplexity: 59092.8359375\n",
      "train: step 355000, cost: 9.994566917419434, perplexity: 21907.119140625\n",
      "train: step 356000, cost: 10.137880325317383, perplexity: 25282.818359375\n",
      "train: step 357000, cost: 11.79300308227539, perplexity: 132323.265625\n",
      "train: step 358000, cost: 8.43061351776123, perplexity: 4585.3125\n",
      "train: step 359000, cost: 8.70531177520752, perplexity: 6034.88330078125\n",
      "train: step 360000, cost: 8.558402061462402, perplexity: 5210.3486328125\n",
      "train: step 361000, cost: 9.613968849182129, perplexity: 14972.4765625\n",
      "train: step 362000, cost: 10.195755958557129, perplexity: 26789.25\n",
      "train: step 363000, cost: 7.116987228393555, perplexity: 1232.73095703125\n",
      "train: step 364000, cost: 7.773653030395508, perplexity: 2377.13916015625\n",
      "train: step 365000, cost: 8.589879035949707, perplexity: 5376.96337890625\n",
      "train: step 366000, cost: 7.592122554779053, perplexity: 1982.5169677734375\n",
      "train: step 367000, cost: 10.068525314331055, perplexity: 23588.755859375\n",
      "train: step 368000, cost: 7.608763694763184, perplexity: 2015.7843017578125\n",
      "train: step 369000, cost: 9.484211921691895, perplexity: 13150.458984375\n",
      "train: step 370000, cost: 9.085920333862305, perplexity: 8830.087890625\n",
      "train: step 371000, cost: 12.49844741821289, perplexity: 267921.0\n",
      "train: step 372000, cost: 7.828942775726318, perplexity: 2512.27197265625\n",
      "train: step 373000, cost: 7.942809104919434, perplexity: 2815.2578125\n",
      "train: step 374000, cost: 8.285019874572754, perplexity: 3964.04345703125\n",
      "train: step 375000, cost: 8.454126358032227, perplexity: 4694.4033203125\n",
      "train: step 376000, cost: 7.421750545501709, perplexity: 1671.957763671875\n",
      "train: step 377000, cost: 7.519742965698242, perplexity: 1844.09326171875\n",
      "train: step 378000, cost: 8.573883056640625, perplexity: 5291.6376953125\n",
      "train: step 379000, cost: 6.93415641784668, perplexity: 1026.752685546875\n",
      "train: step 380000, cost: 8.097262382507324, perplexity: 3285.46142578125\n",
      "train: step 381000, cost: 7.272540092468262, perplexity: 1440.2039794921875\n",
      "train: step 382000, cost: 10.116281509399414, perplexity: 24742.595703125\n",
      "train: step 383000, cost: 7.774952411651611, perplexity: 2380.22998046875\n",
      "train: step 384000, cost: 8.24215316772461, perplexity: 3797.708740234375\n",
      "train: step 385000, cost: 8.500262260437012, perplexity: 4916.0576171875\n",
      "train: step 386000, cost: 8.199210166931152, perplexity: 3638.07568359375\n",
      "train: step 387000, cost: 6.731728553771973, perplexity: 838.5955200195312\n",
      "train: step 388000, cost: 8.527446746826172, perplexity: 5051.53173828125\n",
      "train: step 389000, cost: 7.911779880523682, perplexity: 2729.243896484375\n",
      "train: step 390000, cost: 9.03390884399414, perplexity: 8382.5625\n",
      "train: step 391000, cost: 9.100420951843262, perplexity: 8959.0634765625\n",
      "train: step 392000, cost: 7.8918962478637695, perplexity: 2675.512451171875\n",
      "train: step 393000, cost: 10.651606559753418, perplexity: 42260.43359375\n",
      "train: step 394000, cost: 7.5219268798828125, perplexity: 1848.125\n",
      "train: step 395000, cost: 10.42402172088623, perplexity: 33658.52734375\n",
      "train: step 396000, cost: 12.961844444274902, perplexity: 425850.84375\n",
      "train: step 397000, cost: 7.935088634490967, perplexity: 2793.606201171875\n",
      "train: step 398000, cost: 7.110795974731445, perplexity: 1225.122314453125\n",
      "train: step 399000, cost: 8.112412452697754, perplexity: 3335.615234375\n",
      "train: step 400000, cost: 8.642772674560547, perplexity: 5669.0263671875\n",
      "train: step 401000, cost: 9.201958656311035, perplexity: 9916.533203125\n",
      "train: step 402000, cost: 9.107708930969238, perplexity: 9024.5947265625\n",
      "train: step 403000, cost: 8.561662673950195, perplexity: 5227.36572265625\n",
      "train: step 404000, cost: 10.354000091552734, perplexity: 31382.32421875\n",
      "train: step 405000, cost: 6.186473369598389, perplexity: 486.128662109375\n",
      "train: step 406000, cost: 10.349788665771484, perplexity: 31250.435546875\n",
      "train: step 407000, cost: 8.942840576171875, perplexity: 7652.90478515625\n",
      "train: step 408000, cost: 7.322329521179199, perplexity: 1513.72607421875\n",
      "train: step 409000, cost: 8.541129112243652, perplexity: 5121.123046875\n",
      "train: step 410000, cost: 8.729894638061523, perplexity: 6185.076171875\n",
      "train: step 411000, cost: 8.587590217590332, perplexity: 5364.67041015625\n",
      "train: step 412000, cost: 7.881110668182373, perplexity: 2646.810791015625\n",
      "train: step 413000, cost: 9.825864791870117, perplexity: 18506.26953125\n",
      "train: step 414000, cost: 7.977368354797363, perplexity: 2914.251708984375\n",
      "train: step 415000, cost: 7.448148727416992, perplexity: 1716.6822509765625\n",
      "train: step 416000, cost: 8.332544326782227, perplexity: 4156.98095703125\n",
      "train: step 417000, cost: 8.470918655395508, perplexity: 4773.89892578125\n",
      "train: step 418000, cost: 8.402483940124512, perplexity: 4458.12646484375\n",
      "train: step 419000, cost: 10.900575637817383, perplexity: 54207.5546875\n",
      "train: step 420000, cost: 9.241873741149902, perplexity: 10320.357421875\n",
      "train: step 421000, cost: 9.587660789489746, perplexity: 14583.71484375\n",
      "train: step 422000, cost: 8.264448165893555, perplexity: 3883.329345703125\n",
      "train: step 423000, cost: 8.27281665802002, perplexity: 3915.963134765625\n",
      "train: step 424000, cost: 10.69790267944336, perplexity: 44262.92578125\n",
      "train: step 425000, cost: 6.936926364898682, perplexity: 1029.600830078125\n",
      "train: step 426000, cost: 6.590394496917725, perplexity: 728.0680541992188\n",
      "train: step 427000, cost: 9.504813194274902, perplexity: 13424.1845703125\n",
      "train: step 428000, cost: 9.69974422454834, perplexity: 16313.4345703125\n",
      "train: step 429000, cost: 8.24477767944336, perplexity: 3807.688720703125\n",
      "train: step 430000, cost: 7.211642265319824, perplexity: 1355.115966796875\n",
      "train: step 431000, cost: 7.730847358703613, perplexity: 2277.53125\n",
      "train: step 432000, cost: 8.032987594604492, perplexity: 3080.9326171875\n",
      "train: step 433000, cost: 10.207592010498047, perplexity: 27108.212890625\n",
      "train: step 434000, cost: 7.831316947937012, perplexity: 2518.243408203125\n",
      "train: step 435000, cost: 7.712027549743652, perplexity: 2235.069580078125\n",
      "train: step 436000, cost: 10.690840721130371, perplexity: 43951.44140625\n",
      "train: step 437000, cost: 8.804487228393555, perplexity: 6664.08056640625\n",
      "train: step 438000, cost: 7.902317523956299, perplexity: 2703.540771484375\n",
      "train: step 439000, cost: 8.446335792541504, perplexity: 4657.9736328125\n",
      "train: step 440000, cost: 7.850532054901123, perplexity: 2567.099853515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 441000, cost: 9.83181381225586, perplexity: 18616.69140625\n",
      "train: step 442000, cost: 9.399762153625488, perplexity: 12085.505859375\n",
      "train: step 443000, cost: 9.636190414428711, perplexity: 15308.9111328125\n",
      "train: step 444000, cost: 8.501935958862305, perplexity: 4924.29296875\n",
      "train: step 445000, cost: 8.079543113708496, perplexity: 3227.75830078125\n",
      "train: step 446000, cost: 9.492588996887207, perplexity: 13261.083984375\n",
      "train: step 447000, cost: 8.033513069152832, perplexity: 3082.552001953125\n",
      "train: step 448000, cost: 6.814467430114746, perplexity: 910.9312744140625\n",
      "train: step 449000, cost: 8.943676948547363, perplexity: 7659.30810546875\n",
      "train: step 450000, cost: 7.854365825653076, perplexity: 2576.960205078125\n",
      "train: step 451000, cost: 11.022356033325195, perplexity: 61227.76171875\n",
      "train: step 452000, cost: 8.510138511657715, perplexity: 4964.8505859375\n",
      "train: step 453000, cost: 8.265935897827148, perplexity: 3889.11083984375\n",
      "train: step 454000, cost: 10.500885009765625, perplexity: 36347.65625\n",
      "train: step 455000, cost: 8.341296195983887, perplexity: 4193.52197265625\n",
      "train: step 456000, cost: 7.473681449890137, perplexity: 1761.078125\n",
      "train: step 457000, cost: 9.047334671020508, perplexity: 8495.86328125\n",
      "train: step 458000, cost: 7.228257179260254, perplexity: 1377.8192138671875\n",
      "train: step 459000, cost: 10.639081001281738, perplexity: 41734.3984375\n",
      "train: step 460000, cost: 6.969460964202881, perplexity: 1063.6492919921875\n",
      "train: step 461000, cost: 8.903033256530762, perplexity: 7354.2470703125\n",
      "train: step 462000, cost: 14.71497631072998, perplexity: 2458289.25\n",
      "Model saved in path: /tmp/p2_run02_3.ckpt\n",
      "validation: epoch 3, cost: 8.801153182983398, perplexity: 6641.8994140625\n",
      "test: epoch 3, cost: 9.76703929901123, perplexity: [19173.516, 17592.662, 17449.03]\n",
      "train: step 463000, cost: 8.612274169921875, perplexity: 5498.7392578125\n",
      "train: step 464000, cost: 6.5589141845703125, perplexity: 705.5052490234375\n",
      "train: step 465000, cost: 10.049436569213867, perplexity: 23142.744140625\n",
      "train: step 466000, cost: 8.47906494140625, perplexity: 4812.947265625\n",
      "train: step 467000, cost: 10.403275489807129, perplexity: 32967.43359375\n",
      "train: step 468000, cost: 13.238983154296875, perplexity: 561846.0\n",
      "train: step 469000, cost: 8.610445022583008, perplexity: 5488.69091796875\n",
      "train: step 470000, cost: 10.37914752960205, perplexity: 32181.513671875\n",
      "train: step 471000, cost: 7.785668849945068, perplexity: 2405.874755859375\n",
      "train: step 472000, cost: 10.459990501403809, perplexity: 34891.22265625\n",
      "train: step 473000, cost: 8.214193344116211, perplexity: 3692.995849609375\n",
      "train: step 474000, cost: 8.038729667663574, perplexity: 3098.67431640625\n",
      "train: step 475000, cost: 7.182148456573486, perplexity: 1315.73193359375\n",
      "train: step 476000, cost: 8.119112014770508, perplexity: 3358.03759765625\n",
      "train: step 477000, cost: 10.782751083374023, perplexity: 48182.49609375\n",
      "train: step 478000, cost: 7.588482856750488, perplexity: 1975.314453125\n",
      "train: step 479000, cost: 7.466750144958496, perplexity: 1748.9136962890625\n",
      "train: step 480000, cost: 7.542283535003662, perplexity: 1886.132080078125\n",
      "train: step 481000, cost: 8.296517372131348, perplexity: 4009.883056640625\n",
      "train: step 482000, cost: 9.178640365600586, perplexity: 9687.9716796875\n",
      "train: step 483000, cost: 10.332277297973633, perplexity: 30707.962890625\n",
      "train: step 484000, cost: 7.747011184692383, perplexity: 2314.64404296875\n",
      "train: step 485000, cost: 8.950236320495605, perplexity: 7709.7138671875\n",
      "train: step 486000, cost: 9.1126708984375, perplexity: 9069.486328125\n",
      "train: step 487000, cost: 7.680470943450928, perplexity: 2165.639404296875\n",
      "train: step 488000, cost: 7.812942028045654, perplexity: 2472.3935546875\n",
      "train: step 489000, cost: 7.618705749511719, perplexity: 2035.92529296875\n",
      "train: step 490000, cost: 8.990826606750488, perplexity: 8029.0908203125\n",
      "train: step 491000, cost: 6.4079742431640625, perplexity: 606.6635131835938\n",
      "train: step 492000, cost: 7.792999744415283, perplexity: 2423.576904296875\n",
      "train: step 493000, cost: 7.889768600463867, perplexity: 2669.825927734375\n",
      "train: step 494000, cost: 9.12199878692627, perplexity: 9154.48046875\n",
      "train: step 495000, cost: 10.056920051574707, perplexity: 23316.58203125\n",
      "train: step 496000, cost: 7.344821453094482, perplexity: 1548.158447265625\n",
      "train: step 497000, cost: 8.145559310913086, perplexity: 3448.033203125\n",
      "train: step 498000, cost: 10.625197410583496, perplexity: 41158.98046875\n",
      "train: step 499000, cost: 8.415529251098633, perplexity: 4516.66552734375\n",
      "train: step 500000, cost: 9.547441482543945, perplexity: 14008.806640625\n",
      "train: step 501000, cost: 13.605169296264648, perplexity: 810307.625\n",
      "train: step 502000, cost: 8.725118637084961, perplexity: 6155.60693359375\n",
      "train: step 503000, cost: 8.451501846313477, perplexity: 4682.09912109375\n",
      "train: step 504000, cost: 9.503067970275879, perplexity: 13400.77734375\n",
      "train: step 505000, cost: 11.553712844848633, perplexity: 104163.0625\n",
      "train: step 506000, cost: 8.918584823608398, perplexity: 7469.51123046875\n",
      "train: step 507000, cost: 9.35167407989502, perplexity: 11518.08984375\n",
      "train: step 508000, cost: 9.256063461303711, perplexity: 10467.845703125\n",
      "train: step 509000, cost: 7.737977981567383, perplexity: 2293.82958984375\n",
      "train: step 510000, cost: 9.647802352905273, perplexity: 15487.712890625\n",
      "train: step 511000, cost: 9.984301567077637, perplexity: 21683.384765625\n",
      "train: step 512000, cost: 7.090674877166748, perplexity: 1200.7177734375\n",
      "train: step 513000, cost: 9.870348930358887, perplexity: 19348.08984375\n",
      "train: step 514000, cost: 7.190425395965576, perplexity: 1326.66748046875\n",
      "train: step 515000, cost: 8.268064498901367, perplexity: 3897.398193359375\n",
      "train: step 516000, cost: 7.915290832519531, perplexity: 2738.8427734375\n",
      "train: step 517000, cost: 7.493925094604492, perplexity: 1797.0919189453125\n",
      "train: step 518000, cost: 8.04957389831543, perplexity: 3132.4599609375\n",
      "train: step 519000, cost: 9.415627479553223, perplexity: 12278.775390625\n",
      "train: step 520000, cost: 8.945718765258789, perplexity: 7674.96240234375\n",
      "train: step 521000, cost: 7.310066223144531, perplexity: 1495.276123046875\n",
      "train: step 522000, cost: 7.274832725524902, perplexity: 1443.5096435546875\n",
      "train: step 523000, cost: 9.642221450805664, perplexity: 15401.5185546875\n",
      "train: step 524000, cost: 9.222050666809082, perplexity: 10117.791015625\n",
      "train: step 525000, cost: 6.854002952575684, perplexity: 947.6668090820312\n",
      "train: step 526000, cost: 11.450112342834473, perplexity: 93911.8984375\n",
      "train: step 527000, cost: 12.60512924194336, perplexity: 298083.59375\n",
      "train: step 528000, cost: 7.2538909912109375, perplexity: 1413.594482421875\n",
      "train: step 529000, cost: 8.935022354125977, perplexity: 7593.3056640625\n",
      "train: step 530000, cost: 8.080220222473145, perplexity: 3229.944580078125\n",
      "train: step 531000, cost: 9.496968269348145, perplexity: 13319.28515625\n",
      "train: step 532000, cost: 9.006689071655273, perplexity: 8157.46728515625\n",
      "train: step 533000, cost: 7.696895122528076, perplexity: 2201.501953125\n",
      "train: step 534000, cost: 9.544909477233887, perplexity: 13973.380859375\n",
      "train: step 535000, cost: 11.93210220336914, perplexity: 152070.921875\n",
      "train: step 536000, cost: 8.886455535888672, perplexity: 7233.33544921875\n",
      "train: step 537000, cost: 9.620776176452637, perplexity: 15074.7451171875\n",
      "train: step 538000, cost: 7.792333126068115, perplexity: 2421.961669921875\n",
      "train: step 539000, cost: 9.273406028747559, perplexity: 10650.966796875\n",
      "train: step 540000, cost: 9.235088348388672, perplexity: 10250.5673828125\n",
      "train: step 541000, cost: 8.097352027893066, perplexity: 3285.756103515625\n",
      "train: step 542000, cost: 7.59130334854126, perplexity: 1980.8935546875\n",
      "train: step 543000, cost: 8.40334415435791, perplexity: 4461.96337890625\n",
      "train: step 544000, cost: 11.262001991271973, perplexity: 77808.1953125\n",
      "train: step 545000, cost: 9.788895606994629, perplexity: 17834.599609375\n",
      "train: step 546000, cost: 9.488018989562988, perplexity: 13200.619140625\n",
      "train: step 547000, cost: 8.267149925231934, perplexity: 3893.835205078125\n",
      "train: step 548000, cost: 9.229047775268555, perplexity: 10188.8349609375\n",
      "train: step 549000, cost: 10.861985206604004, perplexity: 52155.51171875\n",
      "train: step 550000, cost: 7.438403129577637, perplexity: 1700.033203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 551000, cost: 7.672486305236816, perplexity: 2148.41650390625\n",
      "train: step 552000, cost: 9.467958450317383, perplexity: 12938.4453125\n",
      "train: step 553000, cost: 9.402790069580078, perplexity: 12122.154296875\n",
      "train: step 554000, cost: 9.375687599182129, perplexity: 11798.02734375\n",
      "train: step 555000, cost: 8.133638381958008, perplexity: 3407.173583984375\n",
      "train: step 556000, cost: 9.301898002624512, perplexity: 10958.798828125\n",
      "train: step 557000, cost: 10.68166732788086, perplexity: 43550.1015625\n",
      "train: step 558000, cost: 7.482889652252197, perplexity: 1777.3692626953125\n",
      "train: step 559000, cost: 8.490822792053223, perplexity: 4869.87158203125\n",
      "train: step 560000, cost: 9.898543357849121, perplexity: 19901.359375\n",
      "train: step 561000, cost: 10.342737197875977, perplexity: 31030.849609375\n",
      "train: step 562000, cost: 9.624983787536621, perplexity: 15138.30859375\n",
      "train: step 563000, cost: 7.331030368804932, perplexity: 1526.954345703125\n",
      "train: step 564000, cost: 8.894230842590332, perplexity: 7289.7958984375\n",
      "train: step 565000, cost: 8.465426445007324, perplexity: 4747.75146484375\n",
      "train: step 566000, cost: 11.278094291687012, perplexity: 79070.4296875\n",
      "train: step 567000, cost: 8.31965446472168, perplexity: 4103.74169921875\n",
      "train: step 568000, cost: 8.274126052856445, perplexity: 3921.09423828125\n",
      "train: step 569000, cost: 8.913419723510742, perplexity: 7431.02978515625\n",
      "train: step 570000, cost: 11.54727554321289, perplexity: 103494.6875\n",
      "train: step 571000, cost: 7.967868328094482, perplexity: 2886.697265625\n",
      "train: step 572000, cost: 12.793062210083008, perplexity: 359713.125\n",
      "train: step 573000, cost: 8.051287651062012, perplexity: 3137.8330078125\n",
      "train: step 574000, cost: 8.089000701904297, perplexity: 3258.429931640625\n",
      "train: step 575000, cost: 7.824976921081543, perplexity: 2502.328369140625\n",
      "train: step 576000, cost: 11.31562614440918, perplexity: 82094.484375\n",
      "train: step 577000, cost: 8.153623580932617, perplexity: 3475.951416015625\n",
      "train: step 578000, cost: 8.532320976257324, perplexity: 5076.21435546875\n",
      "train: step 579000, cost: 8.485185623168945, perplexity: 4842.49609375\n",
      "train: step 580000, cost: 8.926267623901367, perplexity: 7527.11865234375\n",
      "train: step 581000, cost: 11.025069236755371, perplexity: 61394.109375\n",
      "train: step 582000, cost: 10.820354461669922, perplexity: 50028.8203125\n",
      "train: step 583000, cost: 6.982872486114502, perplexity: 1078.010498046875\n",
      "train: step 584000, cost: 9.040179252624512, perplexity: 8435.2890625\n",
      "train: step 585000, cost: 7.103306770324707, perplexity: 1215.9814453125\n",
      "train: step 586000, cost: 8.661543846130371, perplexity: 5776.44580078125\n",
      "train: step 587000, cost: 9.799558639526367, perplexity: 18025.787109375\n",
      "train: step 588000, cost: 8.696763038635254, perplexity: 5983.5126953125\n",
      "train: step 589000, cost: 12.349483489990234, perplexity: 230840.78125\n",
      "train: step 590000, cost: 7.819926738739014, perplexity: 2489.72314453125\n",
      "train: step 591000, cost: 10.04389476776123, perplexity: 23014.84765625\n",
      "train: step 592000, cost: 8.485210418701172, perplexity: 4842.6162109375\n",
      "train: step 593000, cost: 8.527395248413086, perplexity: 5051.27099609375\n",
      "train: step 594000, cost: 8.981365203857422, perplexity: 7953.48291015625\n",
      "train: step 595000, cost: 9.652804374694824, perplexity: 15565.376953125\n",
      "train: step 596000, cost: 10.049227714538574, perplexity: 23137.91015625\n",
      "train: step 597000, cost: 8.594050407409668, perplexity: 5399.439453125\n",
      "train: step 598000, cost: 6.824734210968018, perplexity: 920.3317260742188\n",
      "train: step 599000, cost: 9.978497505187988, perplexity: 21557.8984375\n",
      "train: step 600000, cost: 7.994614601135254, perplexity: 2964.947509765625\n",
      "train: step 601000, cost: 7.029880046844482, perplexity: 1129.89501953125\n",
      "train: step 602000, cost: 7.163279056549072, perplexity: 1291.1376953125\n",
      "train: step 603000, cost: 11.360861778259277, perplexity: 85893.359375\n",
      "train: step 604000, cost: 8.802815437316895, perplexity: 6652.94921875\n",
      "train: step 605000, cost: 8.391159057617188, perplexity: 4407.923828125\n",
      "train: step 606000, cost: 10.05126667022705, perplexity: 23185.13671875\n",
      "train: step 607000, cost: 7.95599889755249, perplexity: 2852.636474609375\n",
      "train: step 608000, cost: 11.522958755493164, perplexity: 101008.3828125\n",
      "train: step 609000, cost: 7.497097969055176, perplexity: 1802.802978515625\n",
      "train: step 610000, cost: 7.6464762687683105, perplexity: 2093.256591796875\n",
      "train: step 611000, cost: 11.178162574768066, perplexity: 71550.7734375\n",
      "train: step 612000, cost: 8.778274536132812, perplexity: 6491.66650390625\n",
      "train: step 613000, cost: 8.823193550109863, perplexity: 6789.91357421875\n",
      "train: step 614000, cost: 9.676674842834473, perplexity: 15941.400390625\n",
      "train: step 615000, cost: 8.289687156677246, perplexity: 3982.588134765625\n",
      "train: step 616000, cost: 7.864619731903076, perplexity: 2603.52001953125\n",
      "train: step 617000, cost: 8.891348838806152, perplexity: 7268.81640625\n",
      "Model saved in path: /tmp/p2_run02_4.ckpt\n",
      "validation: epoch 4, cost: 9.026239395141602, perplexity: 8318.517578125\n",
      "test: epoch 4, cost: 9.325942039489746, perplexity: [19173.516, 17592.662, 17449.03, 11225.486]\n",
      "train: step 618000, cost: 8.1734037399292, perplexity: 3545.39111328125\n",
      "train: step 619000, cost: 9.036863327026367, perplexity: 8407.3642578125\n",
      "train: step 620000, cost: 7.430116653442383, perplexity: 1686.0042724609375\n",
      "train: step 621000, cost: 9.79397201538086, perplexity: 17925.365234375\n",
      "train: step 622000, cost: 9.789652824401855, perplexity: 17848.109375\n",
      "train: step 623000, cost: 8.755949974060059, perplexity: 6348.3486328125\n",
      "train: step 624000, cost: 8.75609016418457, perplexity: 6349.23876953125\n",
      "train: step 625000, cost: 8.665432929992676, perplexity: 5798.95458984375\n",
      "train: step 626000, cost: 9.384406089782715, perplexity: 11901.337890625\n",
      "train: step 627000, cost: 7.904021263122559, perplexity: 2708.150634765625\n",
      "train: step 628000, cost: 7.851933002471924, perplexity: 2570.69873046875\n",
      "train: step 629000, cost: 8.324772834777832, perplexity: 4124.80029296875\n",
      "train: step 630000, cost: 8.500753402709961, perplexity: 4918.47314453125\n",
      "train: step 631000, cost: 8.51423168182373, perplexity: 4985.21435546875\n",
      "train: step 632000, cost: 7.177500247955322, perplexity: 1309.6304931640625\n",
      "train: step 633000, cost: 8.281047821044922, perplexity: 3948.32958984375\n",
      "train: step 634000, cost: 10.070097923278809, perplexity: 23625.87890625\n",
      "train: step 635000, cost: 10.247159957885742, perplexity: 28202.33203125\n",
      "train: step 636000, cost: 8.10867691040039, perplexity: 3323.17822265625\n",
      "train: step 637000, cost: 7.17913293838501, perplexity: 1311.7703857421875\n",
      "train: step 638000, cost: 11.813399314880371, perplexity: 135049.859375\n",
      "train: step 639000, cost: 6.6366682052612305, perplexity: 762.5501098632812\n",
      "train: step 640000, cost: 11.039870262145996, perplexity: 62309.5625\n",
      "train: step 641000, cost: 9.78384017944336, perplexity: 17744.666015625\n",
      "train: step 642000, cost: 11.41756820678711, perplexity: 90904.8125\n",
      "train: step 643000, cost: 12.419462203979492, perplexity: 247573.375\n",
      "train: step 644000, cost: 7.671525955200195, perplexity: 2146.354248046875\n",
      "train: step 645000, cost: 8.379243850708008, perplexity: 4355.71435546875\n",
      "train: step 646000, cost: 8.219669342041016, perplexity: 3713.2744140625\n",
      "train: step 647000, cost: 8.976530075073242, perplexity: 7915.11962890625\n",
      "train: step 648000, cost: 11.954030990600586, perplexity: 155442.46875\n",
      "train: step 649000, cost: 8.262345314025879, perplexity: 3875.171875\n",
      "train: step 650000, cost: 10.760778427124023, perplexity: 47135.34765625\n",
      "train: step 651000, cost: 8.17879867553711, perplexity: 3564.570068359375\n",
      "train: step 652000, cost: 14.222487449645996, perplexity: 1502269.375\n",
      "train: step 653000, cost: 7.963072776794434, perplexity: 2872.88720703125\n",
      "train: step 654000, cost: 10.907588958740234, perplexity: 54589.06640625\n",
      "train: step 655000, cost: 8.02571964263916, perplexity: 3058.62158203125\n",
      "train: step 656000, cost: 8.884965896606445, perplexity: 7222.568359375\n",
      "train: step 657000, cost: 8.22602653503418, perplexity: 3736.95556640625\n",
      "train: step 658000, cost: 8.597944259643555, perplexity: 5420.5048828125\n",
      "train: step 659000, cost: 8.951090812683105, perplexity: 7716.30419921875\n",
      "train: step 660000, cost: 12.15728759765625, perplexity: 190477.171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 661000, cost: 8.788479804992676, perplexity: 6558.2548828125\n",
      "train: step 662000, cost: 7.801431179046631, perplexity: 2444.097412109375\n",
      "train: step 663000, cost: 8.750329971313477, perplexity: 6312.77099609375\n",
      "train: step 664000, cost: 7.3908209800720215, perplexity: 1621.0364990234375\n",
      "train: step 665000, cost: 7.528721809387207, perplexity: 1860.7255859375\n",
      "train: step 666000, cost: 7.566553592681885, perplexity: 1932.4686279296875\n",
      "train: step 667000, cost: 9.113621711730957, perplexity: 9078.11328125\n",
      "train: step 668000, cost: 8.537043571472168, perplexity: 5100.2431640625\n",
      "train: step 669000, cost: 9.93743896484375, perplexity: 20690.6875\n",
      "train: step 670000, cost: 7.916560173034668, perplexity: 2742.321533203125\n",
      "train: step 671000, cost: 7.727060794830322, perplexity: 2268.923583984375\n",
      "train: step 672000, cost: 9.232931137084961, perplexity: 10228.478515625\n",
      "train: step 673000, cost: 8.70007610321045, perplexity: 6003.369140625\n",
      "train: step 674000, cost: 6.987756252288818, perplexity: 1083.2880859375\n",
      "train: step 675000, cost: 9.184972763061523, perplexity: 9749.5146484375\n",
      "train: step 676000, cost: 8.106959342956543, perplexity: 3317.4755859375\n",
      "train: step 677000, cost: 9.297475814819336, perplexity: 10910.4443359375\n",
      "train: step 678000, cost: 7.883615016937256, perplexity: 2653.447509765625\n",
      "train: step 679000, cost: 9.741837501525879, perplexity: 17014.77734375\n",
      "train: step 680000, cost: 6.764608383178711, perplexity: 866.626708984375\n",
      "train: step 681000, cost: 10.101205825805664, perplexity: 24372.380859375\n",
      "train: step 682000, cost: 8.829611778259277, perplexity: 6833.63330078125\n",
      "train: step 683000, cost: 9.053383827209473, perplexity: 8547.412109375\n",
      "train: step 684000, cost: 7.09997034072876, perplexity: 1211.93115234375\n",
      "train: step 685000, cost: 8.368027687072754, perplexity: 4307.1328125\n",
      "train: step 686000, cost: 8.992756843566895, perplexity: 8044.60400390625\n",
      "train: step 687000, cost: 9.376871109008789, perplexity: 11811.9990234375\n",
      "train: step 688000, cost: 12.596985816955566, perplexity: 295666.03125\n",
      "train: step 689000, cost: 9.114501953125, perplexity: 9086.1083984375\n",
      "train: step 690000, cost: 8.31989574432373, perplexity: 4104.73193359375\n",
      "train: step 691000, cost: 15.691514015197754, perplexity: 6527366.0\n",
      "train: step 692000, cost: 11.875730514526367, perplexity: 143735.5625\n",
      "train: step 693000, cost: 8.540749549865723, perplexity: 5119.18017578125\n",
      "train: step 694000, cost: 8.55743408203125, perplexity: 5205.30712890625\n",
      "train: step 695000, cost: 8.736799240112305, perplexity: 6227.9296875\n",
      "train: step 696000, cost: 9.479474067687988, perplexity: 13088.3017578125\n",
      "train: step 697000, cost: 9.988887786865234, perplexity: 21783.05859375\n",
      "train: step 698000, cost: 7.716229438781738, perplexity: 2244.480712890625\n",
      "train: step 699000, cost: 8.118489265441895, perplexity: 3355.947021484375\n",
      "train: step 700000, cost: 9.164323806762695, perplexity: 9550.26171875\n",
      "train: step 701000, cost: 11.108519554138184, perplexity: 66737.3203125\n",
      "train: step 702000, cost: 8.666387557983398, perplexity: 5804.4931640625\n",
      "train: step 703000, cost: 7.804903030395508, perplexity: 2452.59765625\n",
      "train: step 704000, cost: 7.282254219055176, perplexity: 1454.2625732421875\n",
      "train: step 705000, cost: 9.173312187194824, perplexity: 9636.4892578125\n",
      "train: step 706000, cost: 7.957990646362305, perplexity: 2858.32373046875\n",
      "train: step 707000, cost: 8.10543155670166, perplexity: 3312.410888671875\n",
      "train: step 708000, cost: 7.901883125305176, perplexity: 2702.36669921875\n",
      "train: step 709000, cost: 12.694083213806152, perplexity: 325814.40625\n",
      "train: step 710000, cost: 7.512932300567627, perplexity: 1831.5762939453125\n",
      "train: step 711000, cost: 7.906669616699219, perplexity: 2715.332275390625\n",
      "train: step 712000, cost: 7.6879377365112305, perplexity: 2181.870361328125\n",
      "train: step 713000, cost: 6.547635078430176, perplexity: 697.5924682617188\n",
      "train: step 714000, cost: 10.656390190124512, perplexity: 42463.078125\n",
      "train: step 715000, cost: 8.409807205200195, perplexity: 4490.89453125\n",
      "train: step 716000, cost: 9.114961624145508, perplexity: 9090.2861328125\n",
      "train: step 717000, cost: 9.108402252197266, perplexity: 9030.8544921875\n",
      "train: step 718000, cost: 9.434918403625488, perplexity: 12517.9443359375\n",
      "train: step 719000, cost: 6.805453300476074, perplexity: 902.7568969726562\n",
      "train: step 720000, cost: 7.818759441375732, perplexity: 2486.818603515625\n",
      "train: step 721000, cost: 8.86056137084961, perplexity: 7048.43798828125\n",
      "train: step 722000, cost: 6.7621235847473145, perplexity: 864.4760131835938\n",
      "train: step 723000, cost: 7.350739479064941, perplexity: 1557.34765625\n",
      "train: step 724000, cost: 6.574257850646973, perplexity: 716.4137573242188\n",
      "train: step 725000, cost: 9.03439998626709, perplexity: 8386.6796875\n",
      "train: step 726000, cost: 8.003376007080078, perplexity: 2991.03857421875\n",
      "train: step 727000, cost: 8.3463773727417, perplexity: 4214.88427734375\n",
      "train: step 728000, cost: 6.978513240814209, perplexity: 1073.3214111328125\n",
      "train: step 729000, cost: 9.364642143249512, perplexity: 11668.4306640625\n",
      "train: step 730000, cost: 10.760973930358887, perplexity: 47144.5625\n",
      "train: step 731000, cost: 7.051563739776611, perplexity: 1154.6629638671875\n",
      "train: step 732000, cost: 8.528539657592773, perplexity: 5057.05517578125\n",
      "train: step 733000, cost: 13.17278003692627, perplexity: 525854.625\n",
      "train: step 734000, cost: 8.286336898803711, perplexity: 3969.267578125\n",
      "train: step 735000, cost: 8.666979789733887, perplexity: 5807.931640625\n",
      "train: step 736000, cost: 8.75027847290039, perplexity: 6312.44580078125\n",
      "train: step 737000, cost: 11.89702320098877, perplexity: 146828.890625\n",
      "train: step 738000, cost: 8.113678932189941, perplexity: 3339.842529296875\n",
      "train: step 739000, cost: 10.006182670593262, perplexity: 22163.0703125\n",
      "train: step 740000, cost: 7.5248589515686035, perplexity: 1853.5516357421875\n",
      "train: step 741000, cost: 11.548952102661133, perplexity: 103668.34375\n",
      "train: step 742000, cost: 8.146824836730957, perplexity: 3452.399658203125\n",
      "train: step 743000, cost: 8.317662239074707, perplexity: 4095.574462890625\n",
      "train: step 744000, cost: 11.37692928314209, perplexity: 87284.59375\n",
      "train: step 745000, cost: 8.954554557800293, perplexity: 7743.078125\n",
      "train: step 746000, cost: 8.33625602722168, perplexity: 4172.43896484375\n",
      "train: step 747000, cost: 10.865767478942871, perplexity: 52353.15234375\n",
      "train: step 748000, cost: 7.797109603881836, perplexity: 2433.557861328125\n",
      "train: step 749000, cost: 10.390107154846191, perplexity: 32536.15234375\n",
      "train: step 750000, cost: 10.409381866455078, perplexity: 33169.359375\n",
      "train: step 751000, cost: 7.070260524749756, perplexity: 1176.45458984375\n",
      "train: step 752000, cost: 9.8394136428833, perplexity: 18758.712890625\n",
      "train: step 753000, cost: 7.845349311828613, perplexity: 2553.82958984375\n",
      "train: step 754000, cost: 8.052377700805664, perplexity: 3141.255126953125\n",
      "train: step 755000, cost: 9.702527046203613, perplexity: 16358.89453125\n",
      "train: step 756000, cost: 8.793901443481445, perplexity: 6593.908203125\n",
      "train: step 757000, cost: 8.145732879638672, perplexity: 3448.6318359375\n",
      "train: step 758000, cost: 8.328207969665527, perplexity: 4138.99365234375\n",
      "train: step 759000, cost: 9.365911483764648, perplexity: 11683.25\n",
      "train: step 760000, cost: 9.809708595275879, perplexity: 18209.6796875\n",
      "train: step 761000, cost: 8.384428977966309, perplexity: 4378.357421875\n",
      "train: step 762000, cost: 11.367730140686035, perplexity: 86485.3359375\n",
      "train: step 763000, cost: 9.79783821105957, perplexity: 17994.80078125\n",
      "train: step 764000, cost: 10.446199417114258, perplexity: 34413.3359375\n",
      "train: step 765000, cost: 10.82748031616211, perplexity: 50386.58984375\n",
      "train: step 766000, cost: 8.922632217407227, perplexity: 7499.80419921875\n",
      "train: step 767000, cost: 8.987513542175293, perplexity: 8002.53369140625\n",
      "train: step 768000, cost: 7.027956962585449, perplexity: 1127.724365234375\n",
      "train: step 769000, cost: 8.083924293518066, perplexity: 3241.9306640625\n",
      "train: step 770000, cost: 12.812127113342285, perplexity: 366636.84375\n",
      "train: step 771000, cost: 7.844593524932861, perplexity: 2551.900146484375\n",
      "Model saved in path: /tmp/p2_run02_5.ckpt\n",
      "validation: epoch 5, cost: 9.05196762084961, perplexity: 8535.31640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: epoch 5, cost: 9.968306541442871, perplexity: [19173.516, 17592.662, 17449.03, 11225.486, 21339.318]\n",
      "train: step 772000, cost: 7.396712303161621, perplexity: 1630.6146240234375\n",
      "train: step 773000, cost: 8.687042236328125, perplexity: 5925.6298828125\n",
      "train: step 774000, cost: 8.935282707214355, perplexity: 7595.283203125\n",
      "train: step 775000, cost: 8.17245101928711, perplexity: 3542.014892578125\n",
      "train: step 776000, cost: 8.583642959594727, perplexity: 5343.53662109375\n",
      "train: step 777000, cost: 7.963517189025879, perplexity: 2874.164306640625\n",
      "train: step 778000, cost: 6.548261642456055, perplexity: 698.0296630859375\n",
      "train: step 779000, cost: 9.762935638427734, perplexity: 17377.572265625\n",
      "train: step 780000, cost: 7.634828567504883, perplexity: 2069.016357421875\n",
      "train: step 781000, cost: 8.482333183288574, perplexity: 4828.703125\n",
      "train: step 782000, cost: 10.62047290802002, perplexity: 40964.98046875\n",
      "train: step 783000, cost: 8.780109405517578, perplexity: 6503.5888671875\n",
      "train: step 784000, cost: 7.7719011306762695, perplexity: 2372.978515625\n",
      "train: step 785000, cost: 9.693115234375, perplexity: 16205.6494140625\n",
      "train: step 786000, cost: 7.948030948638916, perplexity: 2829.9970703125\n",
      "train: step 787000, cost: 7.935737133026123, perplexity: 2795.418701171875\n",
      "train: step 788000, cost: 7.939933776855469, perplexity: 2807.174560546875\n",
      "train: step 789000, cost: 8.06892204284668, perplexity: 3193.657470703125\n",
      "train: step 790000, cost: 6.707271099090576, perplexity: 818.3344116210938\n",
      "train: step 791000, cost: 10.713811874389648, perplexity: 44972.7421875\n",
      "train: step 792000, cost: 8.875580787658691, perplexity: 7155.1005859375\n",
      "train: step 793000, cost: 8.867008209228516, perplexity: 7094.025390625\n",
      "train: step 794000, cost: 7.183711528778076, perplexity: 1317.790283203125\n",
      "train: step 795000, cost: 9.130812644958496, perplexity: 9235.5244140625\n",
      "train: step 796000, cost: 10.254283905029297, perplexity: 28403.9609375\n",
      "train: step 797000, cost: 9.798161506652832, perplexity: 18000.62109375\n",
      "train: step 798000, cost: 8.766637802124023, perplexity: 6416.56201171875\n",
      "train: step 799000, cost: 11.461618423461914, perplexity: 94998.6875\n",
      "train: step 800000, cost: 7.85476541519165, perplexity: 2577.990234375\n",
      "train: step 801000, cost: 8.856171607971191, perplexity: 7017.56494140625\n",
      "train: step 802000, cost: 9.074938774108887, perplexity: 8733.6513671875\n",
      "train: step 803000, cost: 8.54964828491211, perplexity: 5164.9375\n",
      "train: step 804000, cost: 9.950397491455078, perplexity: 20960.552734375\n",
      "train: step 805000, cost: 9.120797157287598, perplexity: 9143.4873046875\n",
      "train: step 806000, cost: 8.403972625732422, perplexity: 4464.7685546875\n",
      "train: step 807000, cost: 9.2481689453125, perplexity: 10385.5322265625\n",
      "train: step 808000, cost: 7.728798866271973, perplexity: 2272.87060546875\n",
      "train: step 809000, cost: 7.926693916320801, perplexity: 2770.2529296875\n",
      "train: step 810000, cost: 9.644380569458008, perplexity: 15434.80859375\n",
      "train: step 811000, cost: 9.199414253234863, perplexity: 9891.3330078125\n",
      "train: step 812000, cost: 11.709741592407227, perplexity: 121752.0234375\n",
      "train: step 813000, cost: 7.2747697830200195, perplexity: 1443.4189453125\n",
      "train: step 814000, cost: 8.841218948364258, perplexity: 6913.4140625\n",
      "train: step 815000, cost: 8.0768404006958, perplexity: 3219.046142578125\n",
      "train: step 816000, cost: 14.511137008666992, perplexity: 2004964.75\n",
      "train: step 817000, cost: 9.897013664245605, perplexity: 19870.94140625\n",
      "train: step 818000, cost: 7.966235160827637, perplexity: 2881.98681640625\n",
      "train: step 819000, cost: 6.908874988555908, perplexity: 1001.1203002929688\n",
      "train: step 820000, cost: 10.788875579833984, perplexity: 48478.49609375\n",
      "train: step 821000, cost: 10.35065746307373, perplexity: 31277.599609375\n",
      "train: step 822000, cost: 8.982279777526855, perplexity: 7960.759765625\n",
      "train: step 823000, cost: 8.844197273254395, perplexity: 6934.03564453125\n",
      "train: step 824000, cost: 7.3411173820495605, perplexity: 1542.4346923828125\n",
      "train: step 825000, cost: 8.451380729675293, perplexity: 4681.5322265625\n",
      "train: step 826000, cost: 7.669196605682373, perplexity: 2141.3603515625\n",
      "train: step 827000, cost: 8.204855918884277, perplexity: 3658.673583984375\n",
      "train: step 828000, cost: 7.212331771850586, perplexity: 1356.050537109375\n",
      "train: step 829000, cost: 8.327994346618652, perplexity: 4138.10986328125\n",
      "train: step 830000, cost: 6.577026844024658, perplexity: 718.4002685546875\n",
      "train: step 831000, cost: 8.374797821044922, perplexity: 4336.3916015625\n",
      "train: step 832000, cost: 7.584097385406494, perplexity: 1966.670654296875\n",
      "train: step 833000, cost: 9.114209175109863, perplexity: 9083.4482421875\n",
      "train: step 834000, cost: 9.457399368286133, perplexity: 12802.5458984375\n",
      "train: step 835000, cost: 7.980153560638428, perplexity: 2922.3798828125\n",
      "train: step 836000, cost: 8.384439468383789, perplexity: 4378.4033203125\n",
      "train: step 837000, cost: 10.382144927978516, perplexity: 32278.119140625\n",
      "train: step 838000, cost: 7.270040988922119, perplexity: 1436.609375\n",
      "train: step 839000, cost: 11.916960716247559, perplexity: 149785.671875\n",
      "train: step 840000, cost: 10.783032417297363, perplexity: 48196.0546875\n",
      "train: step 841000, cost: 8.913498878479004, perplexity: 7431.6181640625\n",
      "train: step 842000, cost: 8.820154190063477, perplexity: 6769.30810546875\n",
      "train: step 843000, cost: 9.183026313781738, perplexity: 9730.556640625\n",
      "train: step 844000, cost: 7.827070236206055, perplexity: 2507.572021484375\n",
      "train: step 845000, cost: 8.094743728637695, perplexity: 3277.197021484375\n",
      "train: step 846000, cost: 10.462786674499512, perplexity: 34988.91796875\n",
      "train: step 847000, cost: 8.16248607635498, perplexity: 3506.89404296875\n",
      "train: step 848000, cost: 7.403044700622559, perplexity: 1640.97314453125\n",
      "train: step 849000, cost: 9.059207916259766, perplexity: 8597.337890625\n",
      "train: step 850000, cost: 7.438440799713135, perplexity: 1700.0972900390625\n",
      "train: step 851000, cost: 12.101289749145508, perplexity: 180104.0\n",
      "train: step 852000, cost: 9.691786766052246, perplexity: 16184.1357421875\n",
      "train: step 853000, cost: 8.832576751708984, perplexity: 6853.9248046875\n",
      "train: step 854000, cost: 9.952567100524902, perplexity: 21006.078125\n",
      "train: step 855000, cost: 10.223174095153809, perplexity: 27533.921875\n",
      "train: step 856000, cost: 8.558345794677734, perplexity: 5210.05517578125\n",
      "train: step 857000, cost: 9.111639022827148, perplexity: 9060.1318359375\n",
      "train: step 858000, cost: 6.909331321716309, perplexity: 1001.5772705078125\n",
      "train: step 859000, cost: 7.600447654724121, perplexity: 1999.090576171875\n",
      "train: step 860000, cost: 8.40037727355957, perplexity: 4448.7451171875\n",
      "train: step 861000, cost: 10.283336639404297, perplexity: 29241.279296875\n",
      "train: step 862000, cost: 7.917379379272461, perplexity: 2744.569091796875\n",
      "train: step 863000, cost: 9.283799171447754, perplexity: 10762.2412109375\n",
      "train: step 864000, cost: 9.163187026977539, perplexity: 9539.4111328125\n",
      "train: step 865000, cost: 9.954483032226562, perplexity: 21046.36328125\n",
      "train: step 866000, cost: 8.838213920593262, perplexity: 6892.6708984375\n",
      "train: step 867000, cost: 10.177062034606934, perplexity: 26293.10546875\n",
      "train: step 868000, cost: 11.447663307189941, perplexity: 93682.1875\n",
      "train: step 869000, cost: 7.395444869995117, perplexity: 1628.54931640625\n",
      "train: step 870000, cost: 7.334053039550781, perplexity: 1531.5767822265625\n",
      "train: step 871000, cost: 8.472807884216309, perplexity: 4782.92626953125\n",
      "train: step 872000, cost: 10.039525985717773, perplexity: 22914.517578125\n",
      "train: step 873000, cost: 8.843582153320312, perplexity: 6929.771484375\n",
      "train: step 874000, cost: 7.740299701690674, perplexity: 2299.161376953125\n",
      "train: step 875000, cost: 12.034428596496582, perplexity: 168455.78125\n",
      "train: step 876000, cost: 9.763192176818848, perplexity: 17382.03125\n",
      "train: step 877000, cost: 8.235878944396973, perplexity: 3773.95556640625\n",
      "train: step 878000, cost: 12.435763359069824, perplexity: 251642.171875\n",
      "train: step 879000, cost: 8.043843269348145, perplexity: 3114.560302734375\n",
      "train: step 880000, cost: 9.511710166931152, perplexity: 13517.0908203125\n",
      "train: step 881000, cost: 8.828993797302246, perplexity: 6829.4111328125\n",
      "train: step 882000, cost: 10.31997013092041, perplexity: 30332.349609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 883000, cost: 8.581656455993652, perplexity: 5332.93212890625\n",
      "train: step 884000, cost: 9.221948623657227, perplexity: 10116.7587890625\n",
      "train: step 885000, cost: 9.919014930725098, perplexity: 20312.970703125\n",
      "train: step 886000, cost: 7.621848106384277, perplexity: 2042.3331298828125\n",
      "train: step 887000, cost: 10.59366226196289, perplexity: 39881.27734375\n",
      "train: step 888000, cost: 8.199646949768066, perplexity: 3639.665283203125\n",
      "train: step 889000, cost: 10.070283889770508, perplexity: 23630.271484375\n",
      "train: step 890000, cost: 9.633790969848633, perplexity: 15272.22265625\n",
      "train: step 891000, cost: 7.612883567810059, perplexity: 2024.1063232421875\n",
      "train: step 892000, cost: 11.42963695526123, perplexity: 92008.5625\n",
      "train: step 893000, cost: 7.923646926879883, perplexity: 2761.8251953125\n",
      "train: step 894000, cost: 9.19273853302002, perplexity: 9825.521484375\n",
      "train: step 895000, cost: 8.457805633544922, perplexity: 4711.70751953125\n",
      "train: step 896000, cost: 8.493993759155273, perplexity: 4885.337890625\n",
      "train: step 897000, cost: 9.730411529541016, perplexity: 16821.474609375\n",
      "train: step 898000, cost: 7.801198959350586, perplexity: 2443.52978515625\n",
      "train: step 899000, cost: 6.746450901031494, perplexity: 851.0330200195312\n",
      "train: step 900000, cost: 9.046743392944336, perplexity: 8490.841796875\n",
      "train: step 901000, cost: 8.158795356750488, perplexity: 3493.974853515625\n",
      "train: step 902000, cost: 9.050664901733398, perplexity: 8524.2041015625\n",
      "train: step 903000, cost: 8.775135040283203, perplexity: 6471.31787109375\n",
      "train: step 904000, cost: 6.736016750335693, perplexity: 842.1994018554688\n",
      "train: step 905000, cost: 6.815803050994873, perplexity: 912.1487426757812\n",
      "train: step 906000, cost: 7.397294044494629, perplexity: 1631.5634765625\n",
      "train: step 907000, cost: 9.769826889038086, perplexity: 17497.736328125\n",
      "train: step 908000, cost: 11.184298515319824, perplexity: 71991.1484375\n",
      "train: step 909000, cost: 12.342557907104492, perplexity: 229247.609375\n",
      "train: step 910000, cost: 11.47195053100586, perplexity: 95985.3203125\n",
      "train: step 911000, cost: 8.661398887634277, perplexity: 5775.60888671875\n",
      "train: step 912000, cost: 8.385795593261719, perplexity: 4384.34521484375\n",
      "train: step 913000, cost: 11.083121299743652, perplexity: 65063.6484375\n",
      "train: step 914000, cost: 10.616215705871582, perplexity: 40790.95703125\n",
      "train: step 915000, cost: 7.4714155197143555, perplexity: 1757.0921630859375\n",
      "train: step 916000, cost: 7.391241550445557, perplexity: 1621.7183837890625\n",
      "train: step 917000, cost: 9.04343318939209, perplexity: 8462.78125\n",
      "train: step 918000, cost: 8.936116218566895, perplexity: 7601.6162109375\n",
      "train: step 919000, cost: 8.002843856811523, perplexity: 2989.447509765625\n",
      "train: step 920000, cost: 7.596364498138428, perplexity: 1990.944580078125\n",
      "train: step 921000, cost: 7.413267135620117, perplexity: 1657.833984375\n",
      "train: step 922000, cost: 9.639074325561523, perplexity: 15353.1240234375\n",
      "train: step 923000, cost: 6.933581352233887, perplexity: 1026.1624755859375\n",
      "train: step 924000, cost: 9.839038848876953, perplexity: 18751.685546875\n",
      "train: step 925000, cost: 8.688140869140625, perplexity: 5932.1435546875\n",
      "WARNING:tensorflow:From /home/b/anaconda3/envs/nlp/lib/python3.7/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Model saved in path: /tmp/p2_run02_6.ckpt\n",
      "validation: epoch 6, cost: 9.231215476989746, perplexity: 10210.9453125\n",
      "test: epoch 6, cost: 10.111226081848145, perplexity: [19173.516, 17592.662, 17449.03, 11225.486, 21339.318, 24617.826]\n",
      "train: step 926000, cost: 8.557332038879395, perplexity: 5204.77685546875\n",
      "train: step 927000, cost: 7.283628940582275, perplexity: 1456.26318359375\n",
      "train: step 928000, cost: 7.887481212615967, perplexity: 2663.72607421875\n",
      "train: step 929000, cost: 11.760056495666504, perplexity: 128034.6875\n",
      "train: step 930000, cost: 9.563135147094727, perplexity: 14230.390625\n",
      "train: step 931000, cost: 8.857304573059082, perplexity: 7025.5205078125\n",
      "train: step 932000, cost: 8.705078125, perplexity: 6033.4736328125\n",
      "train: step 933000, cost: 6.967418193817139, perplexity: 1061.4786376953125\n",
      "train: step 934000, cost: 10.279016494750977, perplexity: 29115.22265625\n",
      "train: step 935000, cost: 8.091196060180664, perplexity: 3265.591064453125\n",
      "train: step 936000, cost: 8.858471870422363, perplexity: 7033.72607421875\n",
      "train: step 937000, cost: 7.391629695892334, perplexity: 1622.347900390625\n",
      "train: step 938000, cost: 11.14632511138916, perplexity: 69308.6640625\n",
      "train: step 939000, cost: 8.330491065979004, perplexity: 4148.4541015625\n",
      "train: step 940000, cost: 8.157488822937012, perplexity: 3489.412841796875\n",
      "train: step 941000, cost: 9.401321411132812, perplexity: 12104.3642578125\n",
      "train: step 942000, cost: 7.813175678253174, perplexity: 2472.97119140625\n",
      "train: step 943000, cost: 8.396480560302734, perplexity: 4431.443359375\n",
      "train: step 944000, cost: 9.802033424377441, perplexity: 18070.451171875\n",
      "train: step 945000, cost: 9.217473030090332, perplexity: 10071.58203125\n",
      "train: step 946000, cost: 8.556841850280762, perplexity: 5202.2255859375\n",
      "train: step 947000, cost: 8.0037841796875, perplexity: 2992.259765625\n",
      "train: step 948000, cost: 7.621289253234863, perplexity: 2041.19189453125\n",
      "train: step 949000, cost: 8.19139575958252, perplexity: 3609.7568359375\n",
      "train: step 950000, cost: 9.06967544555664, perplexity: 8687.8037109375\n",
      "train: step 951000, cost: 7.282154560089111, perplexity: 1454.11767578125\n",
      "train: step 952000, cost: 8.904462814331055, perplexity: 7364.767578125\n",
      "train: step 953000, cost: 9.820446968078613, perplexity: 18406.275390625\n",
      "train: step 954000, cost: 10.768546104431152, perplexity: 47502.90234375\n",
      "train: step 955000, cost: 9.277740478515625, perplexity: 10697.234375\n",
      "train: step 956000, cost: 7.510764122009277, perplexity: 1827.609619140625\n",
      "train: step 957000, cost: 9.447383880615234, perplexity: 12674.962890625\n",
      "train: step 958000, cost: 6.568723678588867, perplexity: 712.4598999023438\n",
      "train: step 959000, cost: 8.732481956481934, perplexity: 6201.10009765625\n",
      "train: step 960000, cost: 8.25631332397461, perplexity: 3851.867431640625\n",
      "train: step 961000, cost: 8.156867027282715, perplexity: 3487.243896484375\n",
      "train: step 962000, cost: 8.93166446685791, perplexity: 7567.85107421875\n",
      "train: step 963000, cost: 9.684083938598633, perplexity: 16059.951171875\n",
      "train: step 964000, cost: 7.188756465911865, perplexity: 1324.4552001953125\n",
      "train: step 965000, cost: 7.827734470367432, perplexity: 2509.238037109375\n",
      "train: step 966000, cost: 8.368111610412598, perplexity: 4307.494140625\n",
      "train: step 967000, cost: 9.243613243103027, perplexity: 10338.326171875\n",
      "train: step 968000, cost: 7.772464275360107, perplexity: 2374.31494140625\n",
      "train: step 969000, cost: 8.335893630981445, perplexity: 4170.92724609375\n",
      "train: step 970000, cost: 8.171767234802246, perplexity: 3539.59375\n",
      "train: step 971000, cost: 8.141186714172363, perplexity: 3432.9892578125\n",
      "train: step 972000, cost: 8.460254669189453, perplexity: 4723.2607421875\n",
      "train: step 973000, cost: 12.00157356262207, perplexity: 163011.09375\n",
      "train: step 974000, cost: 9.20721435546875, perplexity: 9968.7880859375\n",
      "train: step 975000, cost: 8.293045997619629, perplexity: 3995.9873046875\n",
      "train: step 976000, cost: 7.393989086151123, perplexity: 1626.18017578125\n",
      "train: step 977000, cost: 7.283565044403076, perplexity: 1456.170166015625\n",
      "train: step 978000, cost: 9.28095531463623, perplexity: 10731.6787109375\n",
      "train: step 979000, cost: 10.324403762817383, perplexity: 30467.130859375\n",
      "train: step 980000, cost: 7.780013084411621, perplexity: 2392.305908203125\n",
      "train: step 981000, cost: 7.633616924285889, perplexity: 2066.510986328125\n",
      "train: step 982000, cost: 12.079266548156738, perplexity: 176180.890625\n",
      "train: step 983000, cost: 8.2786226272583, perplexity: 3938.765380859375\n",
      "train: step 984000, cost: 8.682845115661621, perplexity: 5900.8115234375\n",
      "train: step 985000, cost: 6.794156074523926, perplexity: 892.6156616210938\n",
      "train: step 986000, cost: 8.4931640625, perplexity: 4881.28662109375\n",
      "train: step 987000, cost: 10.533717155456543, perplexity: 37560.8359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 988000, cost: 8.250611305236816, perplexity: 3829.96630859375\n",
      "train: step 989000, cost: 10.207501411437988, perplexity: 27105.755859375\n",
      "train: step 990000, cost: 8.859749794006348, perplexity: 7042.72021484375\n",
      "train: step 991000, cost: 7.554003715515137, perplexity: 1908.367919921875\n",
      "train: step 992000, cost: 8.773538589477539, perplexity: 6460.9951171875\n",
      "train: step 993000, cost: 7.017693042755127, perplexity: 1116.20849609375\n",
      "train: step 994000, cost: 11.379189491271973, perplexity: 87482.1015625\n",
      "train: step 995000, cost: 9.239218711853027, perplexity: 10292.994140625\n",
      "train: step 996000, cost: 8.592455863952637, perplexity: 5390.83642578125\n",
      "train: step 997000, cost: 6.651933670043945, perplexity: 774.2800903320312\n",
      "train: step 998000, cost: 6.959527492523193, perplexity: 1053.1358642578125\n",
      "train: step 999000, cost: 7.854163646697998, perplexity: 2576.439453125\n",
      "train: step 1000000, cost: 11.170331001281738, perplexity: 70992.609375\n",
      "train: step 1001000, cost: 7.661062240600586, perplexity: 2124.012451171875\n",
      "train: step 1002000, cost: 10.40425968170166, perplexity: 32999.8984375\n",
      "train: step 1003000, cost: 8.848126411437988, perplexity: 6961.333984375\n",
      "train: step 1004000, cost: 12.820268630981445, perplexity: 369634.0\n",
      "train: step 1005000, cost: 9.775205612182617, perplexity: 17592.107421875\n",
      "train: step 1006000, cost: 10.33178424835205, perplexity: 30692.82421875\n",
      "train: step 1007000, cost: 9.20705509185791, perplexity: 9967.201171875\n",
      "train: step 1008000, cost: 8.248952865600586, perplexity: 3823.619873046875\n",
      "train: step 1009000, cost: 11.802099227905273, perplexity: 133532.375\n",
      "train: step 1010000, cost: 8.670857429504395, perplexity: 5830.49658203125\n",
      "train: step 1011000, cost: 8.094514846801758, perplexity: 3276.447021484375\n",
      "train: step 1012000, cost: 9.379114151000977, perplexity: 11838.5234375\n",
      "train: step 1013000, cost: 9.297686576843262, perplexity: 10912.744140625\n",
      "train: step 1014000, cost: 6.746229648590088, perplexity: 850.8446655273438\n",
      "train: step 1015000, cost: 8.823177337646484, perplexity: 6789.8037109375\n",
      "train: step 1016000, cost: 6.906922340393066, perplexity: 999.1674194335938\n",
      "train: step 1017000, cost: 7.814030170440674, perplexity: 2475.085205078125\n",
      "train: step 1018000, cost: 7.879223346710205, perplexity: 2641.820068359375\n",
      "train: step 1019000, cost: 7.93829870223999, perplexity: 2802.58837890625\n",
      "train: step 1020000, cost: 8.531420707702637, perplexity: 5071.64599609375\n",
      "train: step 1021000, cost: 10.256945610046387, perplexity: 28479.6640625\n",
      "train: step 1022000, cost: 9.472975730895996, perplexity: 13003.525390625\n",
      "train: step 1023000, cost: 8.484247207641602, perplexity: 4837.9541015625\n",
      "train: step 1024000, cost: 8.809267044067383, perplexity: 6696.00927734375\n",
      "train: step 1025000, cost: 7.907553195953369, perplexity: 2717.732421875\n",
      "train: step 1026000, cost: 9.043683052062988, perplexity: 8464.896484375\n",
      "train: step 1027000, cost: 8.364107131958008, perplexity: 4290.279296875\n",
      "train: step 1028000, cost: 9.569127082824707, perplexity: 14315.9140625\n",
      "train: step 1029000, cost: 8.882980346679688, perplexity: 7208.24169921875\n",
      "train: step 1030000, cost: 8.027383804321289, perplexity: 3063.7158203125\n",
      "train: step 1031000, cost: 8.499513626098633, perplexity: 4912.37890625\n",
      "train: step 1032000, cost: 7.214140892028809, perplexity: 1358.5059814453125\n",
      "train: step 1033000, cost: 9.860052108764648, perplexity: 19149.88671875\n",
      "train: step 1034000, cost: 8.721097946166992, perplexity: 6130.90673828125\n",
      "train: step 1035000, cost: 8.844755172729492, perplexity: 6937.90478515625\n",
      "train: step 1036000, cost: 7.8886637687683105, perplexity: 2666.8779296875\n",
      "train: step 1037000, cost: 6.979027271270752, perplexity: 1073.8731689453125\n",
      "train: step 1038000, cost: 6.028907299041748, perplexity: 415.26104736328125\n",
      "train: step 1039000, cost: 8.626469612121582, perplexity: 5577.35302734375\n",
      "train: step 1040000, cost: 6.344033718109131, perplexity: 569.0872192382812\n",
      "train: step 1041000, cost: 8.700311660766602, perplexity: 6004.78369140625\n",
      "train: step 1042000, cost: 7.886219501495361, perplexity: 2660.3671875\n",
      "train: step 1043000, cost: 8.612491607666016, perplexity: 5499.935546875\n",
      "train: step 1044000, cost: 9.822210311889648, perplexity: 18438.76171875\n",
      "train: step 1045000, cost: 8.975687980651855, perplexity: 7908.45703125\n",
      "train: step 1046000, cost: 11.376970291137695, perplexity: 87288.171875\n",
      "train: step 1047000, cost: 10.725699424743652, perplexity: 45510.546875\n",
      "train: step 1048000, cost: 7.667492389678955, perplexity: 2137.714111328125\n",
      "train: step 1049000, cost: 9.834147453308105, perplexity: 18660.185546875\n",
      "train: step 1050000, cost: 8.246917724609375, perplexity: 3815.845947265625\n",
      "train: step 1051000, cost: 8.60881233215332, perplexity: 5479.736328125\n",
      "train: step 1052000, cost: 9.71035385131836, perplexity: 16487.435546875\n",
      "train: step 1053000, cost: 10.296189308166504, perplexity: 29619.53125\n",
      "train: step 1054000, cost: 7.196969509124756, perplexity: 1335.3778076171875\n",
      "train: step 1055000, cost: 7.8069915771484375, perplexity: 2457.7255859375\n",
      "train: step 1056000, cost: 8.22286319732666, perplexity: 3725.15283203125\n",
      "train: step 1057000, cost: 7.309371471405029, perplexity: 1494.2376708984375\n",
      "train: step 1058000, cost: 8.353163719177246, perplexity: 4243.5849609375\n",
      "train: step 1059000, cost: 6.284322261810303, perplexity: 536.100830078125\n",
      "train: step 1060000, cost: 8.176471710205078, perplexity: 3556.28466796875\n",
      "train: step 1061000, cost: 9.37712574005127, perplexity: 11815.0078125\n",
      "train: step 1062000, cost: 9.058735847473145, perplexity: 8593.2802734375\n",
      "train: step 1063000, cost: 8.4071683883667, perplexity: 4479.0595703125\n",
      "train: step 1064000, cost: 9.389362335205078, perplexity: 11960.4697265625\n",
      "train: step 1065000, cost: 8.30715274810791, perplexity: 4052.75732421875\n",
      "train: step 1066000, cost: 7.728536605834961, perplexity: 2272.274658203125\n",
      "train: step 1067000, cost: 7.993052959442139, perplexity: 2960.321044921875\n",
      "train: step 1068000, cost: 9.877782821655273, perplexity: 19492.45703125\n",
      "train: step 1069000, cost: 7.6937665939331055, perplexity: 2194.625244140625\n",
      "train: step 1070000, cost: 7.414483070373535, perplexity: 1659.8509521484375\n",
      "train: step 1071000, cost: 10.162030220031738, perplexity: 25900.828125\n",
      "train: step 1072000, cost: 7.907293796539307, perplexity: 2717.02783203125\n",
      "train: step 1073000, cost: 11.390769004821777, perplexity: 88500.9921875\n",
      "train: step 1074000, cost: 8.130121231079102, perplexity: 3395.2109375\n",
      "train: step 1075000, cost: 9.098641395568848, perplexity: 8943.1337890625\n",
      "train: step 1076000, cost: 9.855379104614258, perplexity: 19060.609375\n",
      "train: step 1077000, cost: 8.03526782989502, perplexity: 3087.966064453125\n",
      "train: step 1078000, cost: 11.723814010620117, perplexity: 123477.4765625\n",
      "train: step 1079000, cost: 9.202753067016602, perplexity: 9924.4140625\n",
      "Model saved in path: /tmp/p2_run02_7.ckpt\n",
      "validation: epoch 7, cost: 9.104384422302246, perplexity: 8994.642578125\n",
      "test: epoch 7, cost: 10.017213821411133, perplexity: [19173.516, 17592.662, 17449.03, 11225.486, 21339.318, 24617.826, 22408.908]\n",
      "train: step 1080000, cost: 6.292988300323486, perplexity: 540.766845703125\n",
      "train: step 1081000, cost: 9.168986320495605, perplexity: 9594.8935546875\n",
      "train: step 1082000, cost: 7.843225002288818, perplexity: 2548.41015625\n",
      "train: step 1083000, cost: 10.917835235595703, perplexity: 55151.27734375\n",
      "train: step 1084000, cost: 9.167527198791504, perplexity: 9580.9033203125\n",
      "train: step 1085000, cost: 12.185029983520508, perplexity: 195835.4375\n",
      "train: step 1086000, cost: 12.74333667755127, perplexity: 342263.65625\n",
      "train: step 1087000, cost: 8.913305282592773, perplexity: 7430.17919921875\n",
      "train: step 1088000, cost: 7.530153274536133, perplexity: 1863.3909912109375\n",
      "train: step 1089000, cost: 8.298376083374023, perplexity: 4017.34326171875\n",
      "train: step 1090000, cost: 8.58967113494873, perplexity: 5375.845703125\n",
      "train: step 1091000, cost: 8.30883502960205, perplexity: 4059.580810546875\n",
      "train: step 1092000, cost: 10.755579948425293, perplexity: 46890.94921875\n",
      "train: step 1093000, cost: 7.787830829620361, perplexity: 2411.081787109375\n",
      "train: step 1094000, cost: 8.19921875, perplexity: 3638.106689453125\n",
      "train: step 1095000, cost: 9.195429801940918, perplexity: 9852.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 1096000, cost: 7.454923152923584, perplexity: 1728.35107421875\n",
      "train: step 1097000, cost: 7.531123161315918, perplexity: 1865.19921875\n",
      "train: step 1098000, cost: 7.558241844177246, perplexity: 1916.4730224609375\n",
      "train: step 1099000, cost: 8.237527847290039, perplexity: 3780.183349609375\n",
      "train: step 1100000, cost: 8.165376663208008, perplexity: 3517.0458984375\n",
      "train: step 1101000, cost: 7.668654918670654, perplexity: 2140.20068359375\n",
      "train: step 1102000, cost: 7.311812877655029, perplexity: 1497.8902587890625\n",
      "train: step 1103000, cost: 9.12411880493164, perplexity: 9173.9091796875\n",
      "train: step 1104000, cost: 8.938554763793945, perplexity: 7620.17578125\n",
      "train: step 1105000, cost: 9.690580368041992, perplexity: 16164.623046875\n",
      "train: step 1106000, cost: 10.233036041259766, perplexity: 27806.802734375\n",
      "train: step 1107000, cost: 9.297528266906738, perplexity: 10911.0166015625\n",
      "train: step 1108000, cost: 16.534141540527344, perplexity: 15159555.0\n",
      "train: step 1109000, cost: 7.6246538162231445, perplexity: 2048.0712890625\n",
      "train: step 1110000, cost: 9.237756729125977, perplexity: 10277.9560546875\n",
      "train: step 1111000, cost: 8.307758331298828, perplexity: 4055.21240234375\n",
      "train: step 1112000, cost: 9.38105583190918, perplexity: 11861.5322265625\n",
      "train: step 1113000, cost: 7.632612228393555, perplexity: 2064.435791015625\n",
      "train: step 1114000, cost: 7.946225166320801, perplexity: 2824.891357421875\n",
      "train: step 1115000, cost: 8.564618110656738, perplexity: 5242.83740234375\n",
      "train: step 1116000, cost: 8.882821083068848, perplexity: 7207.09375\n",
      "train: step 1117000, cost: 7.6964335441589355, perplexity: 2200.486083984375\n",
      "train: step 1118000, cost: 12.928918838500977, perplexity: 412057.78125\n",
      "train: step 1119000, cost: 10.684076309204102, perplexity: 43655.140625\n",
      "train: step 1120000, cost: 7.4325175285339355, perplexity: 1690.0570068359375\n",
      "train: step 1121000, cost: 12.944548606872559, perplexity: 418548.75\n",
      "train: step 1122000, cost: 8.730921745300293, perplexity: 6191.4326171875\n",
      "train: step 1123000, cost: 8.374104499816895, perplexity: 4333.3857421875\n",
      "train: step 1124000, cost: 10.706174850463867, perplexity: 44630.59375\n",
      "train: step 1125000, cost: 8.242552757263184, perplexity: 3799.226318359375\n",
      "train: step 1126000, cost: 9.245293617248535, perplexity: 10355.712890625\n",
      "train: step 1127000, cost: 9.136655807495117, perplexity: 9289.646484375\n",
      "train: step 1128000, cost: 9.34335708618164, perplexity: 11422.6904296875\n",
      "train: step 1129000, cost: 10.922725677490234, perplexity: 55421.65625\n",
      "train: step 1130000, cost: 9.022623062133789, perplexity: 8288.4892578125\n",
      "train: step 1131000, cost: 11.354569435119629, perplexity: 85354.5859375\n",
      "train: step 1132000, cost: 9.330327987670898, perplexity: 11274.8291015625\n",
      "train: step 1133000, cost: 7.1765289306640625, perplexity: 1308.3590087890625\n",
      "train: step 1134000, cost: 7.123532295227051, perplexity: 1240.82568359375\n",
      "train: step 1135000, cost: 9.441418647766113, perplexity: 12599.578125\n",
      "train: step 1136000, cost: 9.320127487182617, perplexity: 11160.404296875\n",
      "train: step 1137000, cost: 8.914237022399902, perplexity: 7437.10546875\n",
      "train: step 1138000, cost: 9.328946113586426, perplexity: 11259.259765625\n",
      "train: step 1139000, cost: 9.892332077026367, perplexity: 19778.12890625\n",
      "train: step 1140000, cost: 7.569587707519531, perplexity: 1938.3409423828125\n",
      "train: step 1141000, cost: 9.482504844665527, perplexity: 13128.029296875\n",
      "train: step 1142000, cost: 8.546697616577148, perplexity: 5149.72021484375\n",
      "train: step 1143000, cost: 8.222112655639648, perplexity: 3722.358154296875\n",
      "train: step 1144000, cost: 8.998144149780273, perplexity: 8088.0595703125\n",
      "train: step 1145000, cost: 7.859575271606445, perplexity: 2590.419921875\n",
      "train: step 1146000, cost: 8.656957626342773, perplexity: 5750.0146484375\n",
      "train: step 1147000, cost: 6.701945781707764, perplexity: 813.9880981445312\n",
      "train: step 1148000, cost: 9.338994026184082, perplexity: 11372.9619140625\n",
      "train: step 1149000, cost: 7.814940452575684, perplexity: 2477.33935546875\n",
      "train: step 1150000, cost: 8.637910842895508, perplexity: 5641.53173828125\n",
      "train: step 1151000, cost: 7.606762886047363, perplexity: 2011.755126953125\n",
      "train: step 1152000, cost: 10.208100318908691, perplexity: 27121.994140625\n",
      "train: step 1153000, cost: 8.165045738220215, perplexity: 3515.882080078125\n",
      "train: step 1154000, cost: 9.046586036682129, perplexity: 8489.505859375\n",
      "train: step 1155000, cost: 9.258426666259766, perplexity: 10492.6123046875\n",
      "train: step 1156000, cost: 7.339440822601318, perplexity: 1539.850830078125\n",
      "train: step 1157000, cost: 10.208657264709473, perplexity: 27137.10546875\n",
      "train: step 1158000, cost: 8.935684204101562, perplexity: 7598.3330078125\n",
      "train: step 1159000, cost: 8.171360969543457, perplexity: 3538.156005859375\n",
      "train: step 1160000, cost: 12.702245712280273, perplexity: 328484.78125\n",
      "train: step 1161000, cost: 8.91565990447998, perplexity: 7447.6953125\n",
      "train: step 1162000, cost: 9.26335620880127, perplexity: 10544.462890625\n",
      "train: step 1163000, cost: 8.53071117401123, perplexity: 5068.048828125\n",
      "train: step 1164000, cost: 8.797452926635742, perplexity: 6617.36767578125\n",
      "train: step 1165000, cost: 8.720108032226562, perplexity: 6124.8408203125\n",
      "train: step 1166000, cost: 13.074827194213867, perplexity: 476788.0\n",
      "train: step 1167000, cost: 10.97057056427002, perplexity: 58137.75390625\n",
      "train: step 1168000, cost: 8.682404518127441, perplexity: 5898.2119140625\n",
      "train: step 1169000, cost: 9.303231239318848, perplexity: 10973.4189453125\n",
      "train: step 1170000, cost: 10.63214111328125, perplexity: 41445.76953125\n",
      "train: step 1171000, cost: 8.271661758422852, perplexity: 3911.443115234375\n",
      "train: step 1172000, cost: 7.739284038543701, perplexity: 2296.827392578125\n",
      "train: step 1173000, cost: 8.20275592803955, perplexity: 3650.998291015625\n",
      "train: step 1174000, cost: 8.319791793823242, perplexity: 4104.30517578125\n",
      "train: step 1175000, cost: 9.434947967529297, perplexity: 12518.314453125\n",
      "train: step 1176000, cost: 7.793959617614746, perplexity: 2425.904296875\n",
      "train: step 1177000, cost: 7.155510425567627, perplexity: 1281.1461181640625\n",
      "train: step 1178000, cost: 10.0677490234375, perplexity: 23570.44921875\n",
      "train: step 1179000, cost: 9.522022247314453, perplexity: 13657.201171875\n",
      "train: step 1180000, cost: 8.223278999328613, perplexity: 3726.702392578125\n",
      "train: step 1181000, cost: 7.835210800170898, perplexity: 2528.068359375\n",
      "train: step 1182000, cost: 10.302776336669922, perplexity: 29815.28125\n",
      "train: step 1183000, cost: 8.98859977722168, perplexity: 8011.2314453125\n",
      "train: step 1184000, cost: 12.551772117614746, perplexity: 282595.59375\n",
      "train: step 1185000, cost: 7.996277809143066, perplexity: 2969.8828125\n",
      "train: step 1186000, cost: 10.587696075439453, perplexity: 39644.046875\n",
      "train: step 1187000, cost: 9.85478687286377, perplexity: 19049.322265625\n",
      "train: step 1188000, cost: 12.257946968078613, perplexity: 210648.671875\n",
      "train: step 1189000, cost: 8.137986183166504, perplexity: 3422.019775390625\n",
      "train: step 1190000, cost: 11.087100982666016, perplexity: 65323.09765625\n",
      "train: step 1191000, cost: 8.369587898254395, perplexity: 4313.85791015625\n",
      "train: step 1192000, cost: 7.6642608642578125, perplexity: 2130.8173828125\n",
      "train: step 1193000, cost: 8.793664932250977, perplexity: 6592.34814453125\n",
      "train: step 1194000, cost: 8.39529800415039, perplexity: 4426.2060546875\n",
      "train: step 1195000, cost: 7.830740451812744, perplexity: 2516.792236328125\n",
      "train: step 1196000, cost: 7.765449047088623, perplexity: 2357.716796875\n",
      "train: step 1197000, cost: 8.369670867919922, perplexity: 4314.2158203125\n",
      "train: step 1198000, cost: 6.854751110076904, perplexity: 948.3760375976562\n",
      "train: step 1199000, cost: 11.935168266296387, perplexity: 152537.890625\n",
      "train: step 1200000, cost: 6.983762264251709, perplexity: 1078.9700927734375\n",
      "train: step 1201000, cost: 10.622404098510742, perplexity: 41044.171875\n",
      "train: step 1202000, cost: 8.267436981201172, perplexity: 3894.953125\n",
      "train: step 1203000, cost: 6.846879959106445, perplexity: 940.9405517578125\n",
      "train: step 1204000, cost: 9.626999855041504, perplexity: 15168.8583984375\n",
      "train: step 1205000, cost: 9.824283599853516, perplexity: 18477.03125\n",
      "train: step 1206000, cost: 7.015737056732178, perplexity: 1114.0274658203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 1207000, cost: 12.07160472869873, perplexity: 174836.171875\n",
      "train: step 1208000, cost: 10.364848136901855, perplexity: 31724.61328125\n",
      "train: step 1209000, cost: 10.200850486755371, perplexity: 26926.078125\n",
      "train: step 1210000, cost: 9.292946815490723, perplexity: 10861.142578125\n",
      "train: step 1211000, cost: 15.365299224853516, perplexity: 4710474.5\n",
      "train: step 1212000, cost: 7.598989009857178, perplexity: 1996.1766357421875\n",
      "train: step 1213000, cost: 8.371265411376953, perplexity: 4321.1005859375\n",
      "train: step 1214000, cost: 7.899675369262695, perplexity: 2696.406982421875\n",
      "train: step 1215000, cost: 9.093072891235352, perplexity: 8893.47265625\n",
      "train: step 1216000, cost: 9.91537094116211, perplexity: 20239.0859375\n",
      "train: step 1217000, cost: 8.894959449768066, perplexity: 7295.109375\n",
      "train: step 1218000, cost: 10.422497749328613, perplexity: 33607.2734375\n",
      "train: step 1219000, cost: 8.603041648864746, perplexity: 5448.2060546875\n",
      "train: step 1220000, cost: 7.647765636444092, perplexity: 2095.957275390625\n",
      "train: step 1221000, cost: 6.835114002227783, perplexity: 929.9343872070312\n",
      "train: step 1222000, cost: 10.110662460327148, perplexity: 24603.955078125\n",
      "train: step 1223000, cost: 9.9332275390625, perplexity: 20603.732421875\n",
      "train: step 1224000, cost: 7.592190265655518, perplexity: 1982.6512451171875\n",
      "train: step 1225000, cost: 10.758928298950195, perplexity: 47048.22265625\n",
      "train: step 1226000, cost: 7.712969779968262, perplexity: 2237.17626953125\n",
      "train: step 1227000, cost: 9.550856590270996, perplexity: 14056.7294921875\n",
      "train: step 1228000, cost: 10.211010932922363, perplexity: 27201.05078125\n",
      "train: step 1229000, cost: 6.639590263366699, perplexity: 764.7815551757812\n",
      "train: step 1230000, cost: 6.644455909729004, perplexity: 768.5117797851562\n",
      "train: step 1231000, cost: 9.562603950500488, perplexity: 14222.8330078125\n",
      "train: step 1232000, cost: 5.976980209350586, perplexity: 394.248046875\n",
      "train: step 1233000, cost: 7.870289325714111, perplexity: 2618.322998046875\n",
      "train: step 1234000, cost: 7.734655857086182, perplexity: 2286.2216796875\n",
      "Model saved in path: /tmp/p2_run02_8.ckpt\n",
      "validation: epoch 8, cost: 10.166156768798828, perplexity: 26007.9296875\n",
      "test: epoch 8, cost: 11.112408638000488, perplexity: [19173.516, 17592.662, 17449.03, 11225.486, 21339.318, 24617.826, 22408.908, 66997.37]\n",
      "train: step 1235000, cost: 8.025639533996582, perplexity: 3058.376708984375\n",
      "train: step 1236000, cost: 8.747748374938965, perplexity: 6296.4951171875\n",
      "train: step 1237000, cost: 8.638060569763184, perplexity: 5642.37646484375\n",
      "train: step 1238000, cost: 6.825908184051514, perplexity: 921.412841796875\n",
      "train: step 1239000, cost: 10.120011329650879, perplexity: 24835.052734375\n",
      "train: step 1240000, cost: 7.855154991149902, perplexity: 2578.994873046875\n",
      "train: step 1241000, cost: 7.172101974487305, perplexity: 1302.5797119140625\n",
      "train: step 1242000, cost: 8.063045501708984, perplexity: 3174.94482421875\n",
      "train: step 1243000, cost: 9.680438041687012, perplexity: 16001.50390625\n",
      "train: step 1244000, cost: 8.545336723327637, perplexity: 5142.716796875\n",
      "train: step 1245000, cost: 7.526069164276123, perplexity: 1855.796142578125\n",
      "train: step 1246000, cost: 8.386082649230957, perplexity: 4385.60400390625\n",
      "train: step 1247000, cost: 9.355426788330078, perplexity: 11561.39453125\n",
      "train: step 1248000, cost: 8.03147029876709, perplexity: 3076.261474609375\n",
      "train: step 1249000, cost: 7.7345051765441895, perplexity: 2285.87744140625\n",
      "train: step 1250000, cost: 7.858445167541504, perplexity: 2587.493896484375\n",
      "train: step 1251000, cost: 8.179841041564941, perplexity: 3568.28759765625\n",
      "train: step 1252000, cost: 8.18245792388916, perplexity: 3577.637451171875\n",
      "train: step 1253000, cost: 11.31732177734375, perplexity: 82233.8125\n",
      "train: step 1254000, cost: 8.440873146057129, perplexity: 4632.59814453125\n",
      "train: step 1255000, cost: 9.141698837280273, perplexity: 9336.61328125\n",
      "train: step 1256000, cost: 8.22999382019043, perplexity: 3751.810546875\n",
      "train: step 1257000, cost: 9.824057579040527, perplexity: 18472.853515625\n",
      "train: step 1258000, cost: 7.703178882598877, perplexity: 2215.379150390625\n",
      "train: step 1259000, cost: 8.230537414550781, perplexity: 3753.850341796875\n",
      "train: step 1260000, cost: 10.619523048400879, perplexity: 40926.08984375\n",
      "train: step 1261000, cost: 9.596356391906738, perplexity: 14711.08203125\n",
      "train: step 1262000, cost: 9.85501766204834, perplexity: 19053.71875\n",
      "train: step 1263000, cost: 8.486063957214355, perplexity: 4846.75146484375\n",
      "train: step 1264000, cost: 7.770022392272949, perplexity: 2368.5244140625\n",
      "train: step 1265000, cost: 9.485709190368652, perplexity: 13170.1630859375\n",
      "train: step 1266000, cost: 9.66487979888916, perplexity: 15754.4755859375\n",
      "train: step 1267000, cost: 8.061034202575684, perplexity: 3168.565185546875\n",
      "train: step 1268000, cost: 9.428658485412598, perplexity: 12439.8271484375\n",
      "train: step 1269000, cost: 10.058565139770508, perplexity: 23354.97265625\n",
      "train: step 1270000, cost: 8.8993501663208, perplexity: 7327.21044921875\n",
      "train: step 1271000, cost: 6.834353446960449, perplexity: 929.2273559570312\n",
      "train: step 1272000, cost: 9.790545463562012, perplexity: 17864.046875\n",
      "train: step 1273000, cost: 5.323834419250488, perplexity: 205.16908264160156\n",
      "train: step 1274000, cost: 10.595876693725586, perplexity: 39969.69140625\n",
      "train: step 1275000, cost: 8.374645233154297, perplexity: 4335.72998046875\n",
      "train: step 1276000, cost: 8.232266426086426, perplexity: 3760.346435546875\n",
      "train: step 1277000, cost: 11.424117088317871, perplexity: 91502.09375\n",
      "train: step 1278000, cost: 9.293157577514648, perplexity: 10863.4326171875\n",
      "train: step 1279000, cost: 12.212963104248047, perplexity: 201382.84375\n",
      "train: step 1280000, cost: 8.500231742858887, perplexity: 4915.90771484375\n",
      "train: step 1281000, cost: 8.472478866577148, perplexity: 4781.35302734375\n",
      "train: step 1282000, cost: 7.898711681365967, perplexity: 2693.8095703125\n",
      "train: step 1283000, cost: 9.064566612243652, perplexity: 8643.5322265625\n",
      "train: step 1284000, cost: 7.366448879241943, perplexity: 1582.0059814453125\n",
      "train: step 1285000, cost: 9.876314163208008, perplexity: 19463.849609375\n",
      "train: step 1286000, cost: 9.33436107635498, perplexity: 11320.3935546875\n",
      "train: step 1287000, cost: 9.954103469848633, perplexity: 21038.375\n",
      "train: step 1288000, cost: 7.159918308258057, perplexity: 1286.805908203125\n",
      "train: step 1289000, cost: 8.508156776428223, perplexity: 4955.021484375\n",
      "train: step 1290000, cost: 6.944157123565674, perplexity: 1037.072509765625\n",
      "train: step 1291000, cost: 9.474228858947754, perplexity: 13019.830078125\n",
      "train: step 1292000, cost: 7.705392360687256, perplexity: 2220.288330078125\n",
      "train: step 1293000, cost: 7.977059364318848, perplexity: 2913.3515625\n",
      "train: step 1294000, cost: 7.912520408630371, perplexity: 2731.265625\n",
      "train: step 1295000, cost: 7.134119510650635, perplexity: 1254.0323486328125\n",
      "train: step 1296000, cost: 8.705411911010742, perplexity: 6035.4873046875\n",
      "train: step 1297000, cost: 10.672826766967773, perplexity: 43166.7890625\n",
      "train: step 1298000, cost: 10.260526657104492, perplexity: 28581.833984375\n",
      "train: step 1299000, cost: 7.388469219207764, perplexity: 1617.2286376953125\n",
      "train: step 1300000, cost: 8.218541145324707, perplexity: 3709.08740234375\n",
      "train: step 1301000, cost: 9.66528034210205, perplexity: 15760.7880859375\n",
      "train: step 1302000, cost: 9.443573951721191, perplexity: 12626.763671875\n",
      "train: step 1303000, cost: 8.732236862182617, perplexity: 6199.580078125\n",
      "train: step 1304000, cost: 7.52119255065918, perplexity: 1846.768310546875\n",
      "train: step 1305000, cost: 8.717389106750488, perplexity: 6108.21044921875\n",
      "train: step 1306000, cost: 8.029263496398926, perplexity: 3069.480224609375\n",
      "train: step 1307000, cost: 11.517136573791504, perplexity: 100422.0\n",
      "train: step 1308000, cost: 7.8392653465271, perplexity: 2538.33935546875\n",
      "train: step 1309000, cost: 8.252579689025879, perplexity: 3837.512451171875\n",
      "train: step 1310000, cost: 8.732818603515625, perplexity: 6203.18798828125\n",
      "train: step 1311000, cost: 7.844778060913086, perplexity: 2552.37109375\n",
      "train: step 1312000, cost: 8.090773582458496, perplexity: 3264.211669921875\n",
      "train: step 1313000, cost: 8.271634101867676, perplexity: 3911.335205078125\n",
      "train: step 1314000, cost: 13.666017532348633, perplexity: 861144.4375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 1315000, cost: 9.496832847595215, perplexity: 13317.4814453125\n",
      "train: step 1316000, cost: 9.767396926879883, perplexity: 17455.271484375\n",
      "train: step 1317000, cost: 9.44998836517334, perplexity: 12708.017578125\n",
      "train: step 1318000, cost: 9.752084732055664, perplexity: 17190.02734375\n",
      "train: step 1319000, cost: 7.512099266052246, perplexity: 1830.05126953125\n",
      "train: step 1320000, cost: 6.621031284332275, perplexity: 750.7189331054688\n",
      "train: step 1321000, cost: 10.511414527893066, perplexity: 36732.40234375\n",
      "train: step 1322000, cost: 7.736257076263428, perplexity: 2289.88525390625\n",
      "train: step 1323000, cost: 7.852627754211426, perplexity: 2572.4853515625\n",
      "train: step 1324000, cost: 7.2337422370910645, perplexity: 1385.3973388671875\n",
      "train: step 1325000, cost: 6.978491306304932, perplexity: 1073.2978515625\n",
      "train: step 1326000, cost: 9.784563064575195, perplexity: 17757.498046875\n",
      "train: step 1327000, cost: 9.588376998901367, perplexity: 14594.1640625\n",
      "train: step 1328000, cost: 9.916509628295898, perplexity: 20262.14453125\n",
      "train: step 1329000, cost: 8.283764839172363, perplexity: 3959.071533203125\n",
      "train: step 1330000, cost: 11.350808143615723, perplexity: 85034.140625\n",
      "train: step 1331000, cost: 9.666604042053223, perplexity: 15781.6630859375\n",
      "train: step 1332000, cost: 7.040334224700928, perplexity: 1141.7691650390625\n",
      "train: step 1333000, cost: 8.653374671936035, perplexity: 5729.44921875\n",
      "train: step 1334000, cost: 7.4461989402771, perplexity: 1713.3382568359375\n",
      "train: step 1335000, cost: 7.41680908203125, perplexity: 1663.71630859375\n",
      "train: step 1336000, cost: 10.507720947265625, perplexity: 36596.9765625\n",
      "train: step 1337000, cost: 8.871561050415039, perplexity: 7126.39697265625\n",
      "train: step 1338000, cost: 8.714813232421875, perplexity: 6092.49658203125\n",
      "train: step 1339000, cost: 7.6993408203125, perplexity: 2206.892822265625\n",
      "train: step 1340000, cost: 8.01609992980957, perplexity: 3029.339599609375\n",
      "train: step 1341000, cost: 8.914814949035645, perplexity: 7441.40478515625\n",
      "train: step 1342000, cost: 7.939283847808838, perplexity: 2805.350830078125\n",
      "train: step 1343000, cost: 7.512188911437988, perplexity: 1830.21533203125\n",
      "train: step 1344000, cost: 9.134166717529297, perplexity: 9266.552734375\n",
      "train: step 1345000, cost: 10.515921592712402, perplexity: 36898.33203125\n",
      "train: step 1346000, cost: 9.632061958312988, perplexity: 15245.83984375\n",
      "train: step 1347000, cost: 8.156913757324219, perplexity: 3487.406982421875\n",
      "train: step 1348000, cost: 8.906148910522461, perplexity: 7377.19580078125\n",
      "train: step 1349000, cost: 7.591427803039551, perplexity: 1981.14013671875\n",
      "train: step 1350000, cost: 7.890809059143066, perplexity: 2672.60546875\n",
      "train: step 1351000, cost: 10.351070404052734, perplexity: 31290.517578125\n",
      "train: step 1352000, cost: 9.032403945922852, perplexity: 8369.9560546875\n",
      "train: step 1353000, cost: 8.271955490112305, perplexity: 3912.59228515625\n",
      "train: step 1354000, cost: 11.889764785766602, perplexity: 145767.0\n",
      "train: step 1355000, cost: 10.336260795593262, perplexity: 30830.53125\n",
      "train: step 1356000, cost: 9.183823585510254, perplexity: 9738.31640625\n",
      "train: step 1357000, cost: 11.3395357131958, perplexity: 84080.984375\n",
      "train: step 1358000, cost: 6.649509906768799, perplexity: 772.4057006835938\n",
      "train: step 1359000, cost: 7.878232955932617, perplexity: 2639.204833984375\n",
      "train: step 1360000, cost: 10.859960556030273, perplexity: 52050.02734375\n",
      "train: step 1361000, cost: 8.742162704467773, perplexity: 6261.4228515625\n",
      "train: step 1362000, cost: 8.444090843200684, perplexity: 4647.52880859375\n",
      "train: step 1363000, cost: 7.561704635620117, perplexity: 1923.120849609375\n",
      "train: step 1364000, cost: 12.274638175964355, perplexity: 214194.15625\n",
      "train: step 1365000, cost: 8.552536964416504, perplexity: 5179.87939453125\n",
      "train: step 1366000, cost: 8.712553977966309, perplexity: 6078.74755859375\n",
      "train: step 1367000, cost: 8.964871406555176, perplexity: 7823.375\n",
      "train: step 1368000, cost: 7.001577854156494, perplexity: 1098.3648681640625\n",
      "train: step 1369000, cost: 14.523673057556152, perplexity: 2030257.375\n",
      "train: step 1370000, cost: 7.347618579864502, perplexity: 1552.4949951171875\n",
      "train: step 1371000, cost: 7.145819664001465, perplexity: 1268.7908935546875\n",
      "train: step 1372000, cost: 8.752771377563477, perplexity: 6328.20166015625\n",
      "train: step 1373000, cost: 9.333239555358887, perplexity: 11307.7041015625\n",
      "train: step 1374000, cost: 7.779449462890625, perplexity: 2390.9580078125\n",
      "train: step 1375000, cost: 6.4116058349609375, perplexity: 608.8706665039062\n",
      "train: step 1376000, cost: 9.497774124145508, perplexity: 13330.0234375\n",
      "train: step 1377000, cost: 8.369630813598633, perplexity: 4314.04296875\n",
      "train: step 1378000, cost: 7.779110431671143, perplexity: 2390.1474609375\n",
      "train: step 1379000, cost: 8.240200996398926, perplexity: 3790.302001953125\n",
      "train: step 1380000, cost: 9.057245254516602, perplexity: 8580.4814453125\n",
      "train: step 1381000, cost: 8.163296699523926, perplexity: 3509.73828125\n",
      "train: step 1382000, cost: 7.159992694854736, perplexity: 1286.901611328125\n",
      "train: step 1383000, cost: 6.881103038787842, perplexity: 973.69970703125\n",
      "train: step 1384000, cost: 10.423176765441895, perplexity: 33630.09765625\n",
      "train: step 1385000, cost: 10.018387794494629, perplexity: 22435.23046875\n",
      "train: step 1386000, cost: 6.736998558044434, perplexity: 843.026611328125\n",
      "train: step 1387000, cost: 9.96495532989502, perplexity: 21267.92578125\n",
      "train: step 1388000, cost: 7.76060676574707, perplexity: 2346.327880859375\n",
      "Model saved in path: /tmp/p2_run02_9.ckpt\n",
      "validation: epoch 9, cost: 8.731062889099121, perplexity: 6192.306640625\n",
      "test: epoch 9, cost: 9.588712692260742, perplexity: [19173.516, 17592.662, 17449.03, 11225.486, 21339.318, 24617.826, 22408.908, 66997.37, 14599.063]\n",
      "train: step 1389000, cost: 9.298303604125977, perplexity: 10919.4794921875\n",
      "train: step 1390000, cost: 7.807620048522949, perplexity: 2459.2705078125\n",
      "train: step 1391000, cost: 9.077984809875488, perplexity: 8760.294921875\n",
      "train: step 1392000, cost: 8.500738143920898, perplexity: 4918.39794921875\n",
      "train: step 1393000, cost: 7.963164329528809, perplexity: 2873.150146484375\n",
      "train: step 1394000, cost: 9.323427200317383, perplexity: 11197.2919921875\n",
      "train: step 1395000, cost: 8.339689254760742, perplexity: 4186.78857421875\n",
      "train: step 1396000, cost: 8.43397331237793, perplexity: 4600.744140625\n",
      "train: step 1397000, cost: 12.381282806396484, perplexity: 238299.328125\n",
      "train: step 1398000, cost: 7.6606526374816895, perplexity: 2123.142578125\n",
      "train: step 1399000, cost: 8.407819747924805, perplexity: 4481.97802734375\n",
      "train: step 1400000, cost: 11.20701789855957, perplexity: 73645.46875\n",
      "train: step 1401000, cost: 10.432394981384277, perplexity: 33941.54296875\n",
      "train: step 1402000, cost: 11.56091022491455, perplexity: 104915.46875\n",
      "train: step 1403000, cost: 8.330138206481934, perplexity: 4146.990234375\n",
      "train: step 1404000, cost: 7.681236743927002, perplexity: 2167.298583984375\n",
      "train: step 1405000, cost: 11.699498176574707, perplexity: 120511.2265625\n",
      "train: step 1406000, cost: 9.769186019897461, perplexity: 17486.52734375\n",
      "train: step 1407000, cost: 8.472658157348633, perplexity: 4782.21044921875\n",
      "train: step 1408000, cost: 9.35818099975586, perplexity: 11593.2802734375\n",
      "train: step 1409000, cost: 8.05998706817627, perplexity: 3165.249267578125\n",
      "train: step 1410000, cost: 7.8105926513671875, perplexity: 2466.591796875\n",
      "train: step 1411000, cost: 8.513346672058105, perplexity: 4980.80419921875\n",
      "train: step 1412000, cost: 8.498187065124512, perplexity: 4905.86669921875\n",
      "train: step 1413000, cost: 8.436298370361328, perplexity: 4611.453125\n",
      "train: step 1414000, cost: 8.27720832824707, perplexity: 3933.19873046875\n",
      "train: step 1415000, cost: 8.344012260437012, perplexity: 4204.92724609375\n",
      "train: step 1416000, cost: 6.723135948181152, perplexity: 831.4207763671875\n",
      "train: step 1417000, cost: 9.749207496643066, perplexity: 17140.638671875\n",
      "train: step 1418000, cost: 9.12298583984375, perplexity: 9163.521484375\n",
      "train: step 1419000, cost: 7.60610294342041, perplexity: 2010.4278564453125\n",
      "train: step 1420000, cost: 8.236922264099121, perplexity: 3777.894775390625\n",
      "train: step 1421000, cost: 8.431873321533203, perplexity: 4591.0927734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 1422000, cost: 8.342727661132812, perplexity: 4199.529296875\n",
      "train: step 1423000, cost: 7.3337483406066895, perplexity: 1531.110107421875\n",
      "train: step 1424000, cost: 7.921192646026611, perplexity: 2755.054931640625\n",
      "train: step 1425000, cost: 8.204920768737793, perplexity: 3658.91064453125\n",
      "train: step 1426000, cost: 7.838963508605957, perplexity: 2537.5732421875\n",
      "train: step 1427000, cost: 11.216910362243652, perplexity: 74377.6171875\n",
      "train: step 1428000, cost: 8.94020938873291, perplexity: 7632.794921875\n",
      "train: step 1429000, cost: 8.486146926879883, perplexity: 4847.15380859375\n",
      "train: step 1430000, cost: 7.592470169067383, perplexity: 1983.206298828125\n",
      "train: step 1431000, cost: 6.827824115753174, perplexity: 923.1798706054688\n",
      "train: step 1432000, cost: 10.001317024230957, perplexity: 22055.494140625\n",
      "train: step 1433000, cost: 10.812566757202148, perplexity: 49640.71875\n",
      "train: step 1434000, cost: 9.343729019165039, perplexity: 11426.9404296875\n",
      "train: step 1435000, cost: 8.951034545898438, perplexity: 7715.8701171875\n",
      "train: step 1436000, cost: 8.87164306640625, perplexity: 7126.9814453125\n",
      "train: step 1437000, cost: 10.580318450927734, perplexity: 39352.64453125\n",
      "train: step 1438000, cost: 9.858829498291016, perplexity: 19126.48828125\n",
      "train: step 1439000, cost: 7.625844478607178, perplexity: 2050.511474609375\n",
      "train: step 1440000, cost: 8.262989044189453, perplexity: 3877.667236328125\n",
      "train: step 1441000, cost: 8.024596214294434, perplexity: 3055.187255859375\n",
      "train: step 1442000, cost: 7.358017921447754, perplexity: 1568.7242431640625\n",
      "train: step 1443000, cost: 8.11190414428711, perplexity: 3333.92041015625\n",
      "train: step 1444000, cost: 8.533039093017578, perplexity: 5079.86083984375\n",
      "train: step 1445000, cost: 8.75425910949707, perplexity: 6337.62353515625\n",
      "train: step 1446000, cost: 8.636370658874512, perplexity: 5632.84912109375\n",
      "train: step 1447000, cost: 11.26255989074707, perplexity: 77851.609375\n",
      "train: step 1448000, cost: 8.40867805480957, perplexity: 4485.82666015625\n",
      "train: step 1449000, cost: 7.75050163269043, perplexity: 2322.7373046875\n",
      "train: step 1450000, cost: 7.793765068054199, perplexity: 2425.432373046875\n",
      "train: step 1451000, cost: 8.98944091796875, perplexity: 8017.97314453125\n",
      "train: step 1452000, cost: 7.435213565826416, perplexity: 1694.61962890625\n",
      "train: step 1453000, cost: 7.910280227661133, perplexity: 2725.154052734375\n",
      "train: step 1454000, cost: 8.25053882598877, perplexity: 3829.6884765625\n",
      "train: step 1455000, cost: 9.411681175231934, perplexity: 12230.4150390625\n",
      "train: step 1456000, cost: 10.058956146240234, perplexity: 23364.10546875\n",
      "train: step 1457000, cost: 7.591731548309326, perplexity: 1981.741943359375\n",
      "train: step 1458000, cost: 9.66125774383545, perplexity: 15697.5146484375\n",
      "train: step 1459000, cost: 8.17895221710205, perplexity: 3565.1171875\n",
      "train: step 1460000, cost: 8.342730522155762, perplexity: 4199.541015625\n",
      "train: step 1461000, cost: 8.254398345947266, perplexity: 3844.498046875\n",
      "train: step 1462000, cost: 8.27357292175293, perplexity: 3918.926025390625\n",
      "train: step 1463000, cost: 8.075103759765625, perplexity: 3213.460693359375\n",
      "train: step 1464000, cost: 9.533411026000977, perplexity: 13813.62890625\n",
      "train: step 1465000, cost: 8.711844444274902, perplexity: 6074.43603515625\n",
      "train: step 1466000, cost: 9.2059907913208, perplexity: 9956.5986328125\n",
      "train: step 1467000, cost: 9.299015045166016, perplexity: 10927.2509765625\n",
      "train: step 1468000, cost: 8.19944953918457, perplexity: 3638.94677734375\n",
      "train: step 1469000, cost: 6.353804111480713, perplexity: 574.6746826171875\n",
      "train: step 1470000, cost: 9.737646102905273, perplexity: 16943.611328125\n",
      "train: step 1471000, cost: 10.914532661437988, perplexity: 54969.4375\n",
      "train: step 1472000, cost: 9.473674774169922, perplexity: 13012.6181640625\n",
      "train: step 1473000, cost: 9.250045776367188, perplexity: 10405.0419921875\n",
      "train: step 1474000, cost: 8.528421401977539, perplexity: 5056.45751953125\n",
      "train: step 1475000, cost: 7.720828533172607, perplexity: 2254.826904296875\n",
      "train: step 1476000, cost: 7.809269905090332, perplexity: 2463.331298828125\n",
      "train: step 1477000, cost: 7.304995536804199, perplexity: 1487.71337890625\n",
      "train: step 1478000, cost: 10.587284088134766, perplexity: 39627.71875\n",
      "train: step 1479000, cost: 7.109250068664551, perplexity: 1223.2298583984375\n",
      "train: step 1480000, cost: 13.909908294677734, perplexity: 1098996.75\n",
      "train: step 1481000, cost: 8.124055862426758, perplexity: 3374.68017578125\n",
      "train: step 1482000, cost: 11.719043731689453, perplexity: 122889.859375\n",
      "train: step 1483000, cost: 6.7580485343933105, perplexity: 860.9603881835938\n",
      "train: step 1484000, cost: 6.23381233215332, perplexity: 509.6949157714844\n",
      "train: step 1485000, cost: 11.505936622619629, perplexity: 99303.546875\n",
      "train: step 1486000, cost: 7.743563652038574, perplexity: 2306.677978515625\n",
      "train: step 1487000, cost: 7.469449996948242, perplexity: 1753.6419677734375\n",
      "train: step 1488000, cost: 8.599974632263184, perplexity: 5431.52197265625\n",
      "train: step 1489000, cost: 9.46621036529541, perplexity: 12915.8486328125\n",
      "train: step 1490000, cost: 10.687856674194336, perplexity: 43820.484375\n",
      "train: step 1491000, cost: 8.056264877319336, perplexity: 3153.489501953125\n",
      "train: step 1492000, cost: 11.593099594116211, perplexity: 108347.578125\n",
      "train: step 1493000, cost: 8.419413566589355, perplexity: 4534.24365234375\n",
      "train: step 1494000, cost: 11.580092430114746, perplexity: 106947.3984375\n",
      "train: step 1495000, cost: 7.921987056732178, perplexity: 2757.244384765625\n",
      "train: step 1496000, cost: 7.028750419616699, perplexity: 1128.619384765625\n",
      "train: step 1497000, cost: 8.827213287353516, perplexity: 6817.26220703125\n",
      "train: step 1498000, cost: 10.943037986755371, perplexity: 56558.90625\n",
      "train: step 1499000, cost: 7.709828853607178, perplexity: 2230.16064453125\n",
      "train: step 1500000, cost: 9.00350570678711, perplexity: 8131.54052734375\n",
      "train: step 1501000, cost: 10.57918930053711, perplexity: 39308.234375\n",
      "train: step 1502000, cost: 7.148603916168213, perplexity: 1272.328369140625\n",
      "train: step 1503000, cost: 9.408025741577148, perplexity: 12185.7900390625\n",
      "train: step 1504000, cost: 10.465163230895996, perplexity: 35072.171875\n",
      "train: step 1505000, cost: 8.377328872680664, perplexity: 4347.380859375\n",
      "train: step 1506000, cost: 8.386996269226074, perplexity: 4389.6123046875\n",
      "train: step 1507000, cost: 8.686785697937012, perplexity: 5924.10986328125\n",
      "train: step 1508000, cost: 8.895745277404785, perplexity: 7300.84423828125\n",
      "train: step 1509000, cost: 9.45918083190918, perplexity: 12825.3740234375\n",
      "train: step 1510000, cost: 7.781397342681885, perplexity: 2395.619873046875\n",
      "train: step 1511000, cost: 11.360855102539062, perplexity: 85892.78125\n",
      "train: step 1512000, cost: 6.974033832550049, perplexity: 1068.5244140625\n",
      "train: step 1513000, cost: 9.798308372497559, perplexity: 18003.263671875\n",
      "train: step 1514000, cost: 7.771202564239502, perplexity: 2371.3212890625\n",
      "train: step 1515000, cost: 8.741567611694336, perplexity: 6257.69775390625\n",
      "train: step 1516000, cost: 8.347432136535645, perplexity: 4219.33203125\n",
      "train: step 1517000, cost: 10.070219039916992, perplexity: 23628.740234375\n",
      "train: step 1518000, cost: 7.340599536895752, perplexity: 1541.6361083984375\n",
      "train: step 1519000, cost: 8.701281547546387, perplexity: 6010.6103515625\n",
      "train: step 1520000, cost: 9.190463066101074, perplexity: 9803.189453125\n",
      "train: step 1521000, cost: 7.735135078430176, perplexity: 2287.317626953125\n",
      "train: step 1522000, cost: 7.296998977661133, perplexity: 1475.8642578125\n",
      "train: step 1523000, cost: 9.91014575958252, perplexity: 20133.609375\n",
      "train: step 1524000, cost: 8.213675498962402, perplexity: 3691.083984375\n",
      "train: step 1525000, cost: 8.924169540405273, perplexity: 7511.34228515625\n",
      "train: step 1526000, cost: 9.607462882995605, perplexity: 14875.380859375\n",
      "train: step 1527000, cost: 11.200753211975098, perplexity: 73185.5390625\n",
      "train: step 1528000, cost: 8.595464706420898, perplexity: 5407.08154296875\n",
      "train: step 1529000, cost: 10.463485717773438, perplexity: 35013.3828125\n",
      "train: step 1530000, cost: 7.808155536651611, perplexity: 2460.587646484375\n",
      "train: step 1531000, cost: 10.292715072631836, perplexity: 29516.8046875\n",
      "train: step 1532000, cost: 10.468607902526855, perplexity: 35193.19140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 1533000, cost: 6.258790016174316, perplexity: 522.5862426757812\n",
      "train: step 1534000, cost: 9.471610069274902, perplexity: 12985.7783203125\n",
      "train: step 1535000, cost: 9.1372652053833, perplexity: 9295.3095703125\n",
      "train: step 1536000, cost: 8.307751655578613, perplexity: 4055.185302734375\n",
      "train: step 1537000, cost: 8.882161140441895, perplexity: 7202.3388671875\n",
      "train: step 1538000, cost: 7.886435031890869, perplexity: 2660.94091796875\n",
      "train: step 1539000, cost: 7.724729537963867, perplexity: 2263.640380859375\n",
      "train: step 1540000, cost: 8.838825225830078, perplexity: 6896.88525390625\n",
      "train: step 1541000, cost: 8.434706687927246, perplexity: 4604.119140625\n",
      "train: step 1542000, cost: 9.126843452453613, perplexity: 9198.939453125\n",
      "Model saved in path: /tmp/p2_run02_10.ckpt\n",
      "validation: epoch 10, cost: 9.12000560760498, perplexity: 9136.251953125\n",
      "test: epoch 10, cost: 10.004762649536133, perplexity: [19173.516, 17592.662, 17449.03, 11225.486, 21339.318, 24617.826, 22408.908, 66997.37, 14599.063, 22131.621]\n",
      "train: step 1543000, cost: 11.93690299987793, perplexity: 152802.734375\n",
      "train: step 1544000, cost: 7.71099853515625, perplexity: 2232.7705078125\n",
      "train: step 1545000, cost: 9.025091171264648, perplexity: 8308.9716796875\n",
      "train: step 1546000, cost: 8.293523788452148, perplexity: 3997.89697265625\n",
      "train: step 1547000, cost: 9.467698097229004, perplexity: 12935.078125\n",
      "train: step 1548000, cost: 7.454663276672363, perplexity: 1727.9019775390625\n",
      "train: step 1549000, cost: 9.726465225219727, perplexity: 16755.22265625\n",
      "train: step 1550000, cost: 10.209135055541992, perplexity: 27150.07421875\n",
      "train: step 1551000, cost: 7.864670276641846, perplexity: 2603.65185546875\n",
      "train: step 1552000, cost: 9.018324851989746, perplexity: 8252.9404296875\n",
      "train: step 1553000, cost: 8.984244346618652, perplexity: 7976.4150390625\n",
      "train: step 1554000, cost: 6.568549633026123, perplexity: 712.3359375\n",
      "train: step 1555000, cost: 9.187430381774902, perplexity: 9773.5048828125\n",
      "train: step 1556000, cost: 7.370093822479248, perplexity: 1587.7828369140625\n",
      "train: step 1557000, cost: 9.867446899414062, perplexity: 19292.021484375\n",
      "train: step 1558000, cost: 12.018630027770996, perplexity: 165815.34375\n",
      "train: step 1559000, cost: 7.849627494812012, perplexity: 2564.77880859375\n",
      "train: step 1560000, cost: 10.191115379333496, perplexity: 26665.21875\n",
      "train: step 1561000, cost: 10.057127952575684, perplexity: 23321.4296875\n",
      "train: step 1562000, cost: 8.184772491455078, perplexity: 3585.927734375\n",
      "train: step 1563000, cost: 7.592551231384277, perplexity: 1983.3670654296875\n",
      "train: step 1564000, cost: 9.734952926635742, perplexity: 16898.041015625\n",
      "train: step 1565000, cost: 8.476726531982422, perplexity: 4801.70556640625\n",
      "train: step 1566000, cost: 11.325684547424316, perplexity: 82924.3984375\n",
      "train: step 1567000, cost: 9.545001983642578, perplexity: 13974.673828125\n",
      "train: step 1568000, cost: 7.095536231994629, perplexity: 1206.5692138671875\n",
      "train: step 1569000, cost: 8.093375205993652, perplexity: 3272.715087890625\n",
      "train: step 1570000, cost: 9.363771438598633, perplexity: 11658.2744140625\n",
      "train: step 1571000, cost: 10.175413131713867, perplexity: 26249.787109375\n",
      "train: step 1572000, cost: 8.027850151062012, perplexity: 3065.14501953125\n",
      "train: step 1573000, cost: 8.821768760681152, perplexity: 6780.24658203125\n",
      "train: step 1574000, cost: 8.74301528930664, perplexity: 6266.76318359375\n",
      "train: step 1575000, cost: 8.349743843078613, perplexity: 4229.09716796875\n",
      "train: step 1576000, cost: 7.727837085723877, perplexity: 2270.685546875\n",
      "train: step 1577000, cost: 9.39087963104248, perplexity: 11978.6318359375\n",
      "train: step 1578000, cost: 9.179657936096191, perplexity: 9697.8349609375\n",
      "train: step 1579000, cost: 8.405247688293457, perplexity: 4470.46533203125\n",
      "train: step 1580000, cost: 10.161761283874512, perplexity: 25893.86328125\n",
      "train: step 1581000, cost: 9.27597427368164, perplexity: 10678.357421875\n",
      "train: step 1582000, cost: 8.340386390686035, perplexity: 4189.70849609375\n",
      "train: step 1583000, cost: 10.036660194396973, perplexity: 22848.943359375\n",
      "train: step 1584000, cost: 10.455997467041016, perplexity: 34752.17578125\n",
      "train: step 1585000, cost: 8.907732963562012, perplexity: 7388.890625\n",
      "train: step 1586000, cost: 7.2974162101745605, perplexity: 1476.4801025390625\n",
      "train: step 1587000, cost: 9.841025352478027, perplexity: 18788.97265625\n",
      "train: step 1588000, cost: 9.681166648864746, perplexity: 16013.1669921875\n",
      "train: step 1589000, cost: 9.413832664489746, perplexity: 12256.7568359375\n",
      "train: step 1590000, cost: 8.613161087036133, perplexity: 5503.61865234375\n",
      "train: step 1591000, cost: 11.164806365966797, perplexity: 70601.4765625\n",
      "train: step 1592000, cost: 8.146126747131348, perplexity: 3449.990234375\n",
      "train: step 1593000, cost: 7.669848442077637, perplexity: 2142.7568359375\n",
      "train: step 1594000, cost: 9.037365913391113, perplexity: 8411.5908203125\n",
      "train: step 1595000, cost: 8.641425132751465, perplexity: 5661.39208984375\n",
      "train: step 1596000, cost: 10.197408676147461, perplexity: 26833.560546875\n",
      "train: step 1597000, cost: 9.83691692352295, perplexity: 18711.9375\n",
      "train: step 1598000, cost: 6.632213115692139, perplexity: 759.160400390625\n",
      "train: step 1599000, cost: 8.3317232131958, perplexity: 4153.56884765625\n",
      "train: step 1600000, cost: 8.278487205505371, perplexity: 3938.23193359375\n",
      "train: step 1601000, cost: 7.76557731628418, perplexity: 2358.01953125\n",
      "train: step 1602000, cost: 9.768102645874023, perplexity: 17467.59375\n",
      "train: step 1603000, cost: 8.092805862426758, perplexity: 3270.852294921875\n",
      "train: step 1604000, cost: 8.616270065307617, perplexity: 5520.755859375\n",
      "train: step 1605000, cost: 10.48135757446289, perplexity: 35644.765625\n",
      "train: step 1606000, cost: 7.205381870269775, perplexity: 1346.6588134765625\n",
      "train: step 1607000, cost: 8.245662689208984, perplexity: 3811.059814453125\n",
      "train: step 1608000, cost: 10.566082954406738, perplexity: 38796.40625\n",
      "train: step 1609000, cost: 12.150453567504883, perplexity: 189179.875\n",
      "train: step 1610000, cost: 8.805251121520996, perplexity: 6669.1728515625\n",
      "train: step 1611000, cost: 8.396764755249023, perplexity: 4432.70263671875\n",
      "train: step 1612000, cost: 9.344137191772461, perplexity: 11431.6044921875\n",
      "train: step 1613000, cost: 10.739985466003418, perplexity: 46165.3828125\n",
      "train: step 1614000, cost: 9.484912872314453, perplexity: 13159.6796875\n",
      "train: step 1615000, cost: 7.442108154296875, perplexity: 1706.3436279296875\n",
      "train: step 1616000, cost: 10.31994915008545, perplexity: 30331.71484375\n",
      "train: step 1617000, cost: 9.621573448181152, perplexity: 15086.7685546875\n",
      "train: step 1618000, cost: 10.183670997619629, perplexity: 26467.451171875\n",
      "train: step 1619000, cost: 7.76957893371582, perplexity: 2367.47412109375\n",
      "train: step 1620000, cost: 8.280916213989258, perplexity: 3947.809814453125\n",
      "train: step 1621000, cost: 9.22193431854248, perplexity: 10116.6142578125\n",
      "train: step 1622000, cost: 10.997117042541504, perplexity: 59701.7734375\n",
      "train: step 1623000, cost: 8.150435447692871, perplexity: 3464.887451171875\n",
      "train: step 1624000, cost: 7.471747875213623, perplexity: 1757.6761474609375\n",
      "train: step 1625000, cost: 10.476214408874512, perplexity: 35461.91015625\n",
      "train: step 1626000, cost: 10.638839721679688, perplexity: 41724.328125\n",
      "train: step 1627000, cost: 7.4688873291015625, perplexity: 1752.6553955078125\n",
      "train: step 1628000, cost: 8.691585540771484, perplexity: 5952.61328125\n",
      "train: step 1629000, cost: 7.996943473815918, perplexity: 2971.8603515625\n",
      "train: step 1630000, cost: 8.562585830688477, perplexity: 5232.193359375\n",
      "train: step 1631000, cost: 8.43835163116455, perplexity: 4620.931640625\n",
      "train: step 1632000, cost: 8.62417221069336, perplexity: 5564.5546875\n",
      "train: step 1633000, cost: 9.794116020202637, perplexity: 17927.9453125\n",
      "train: step 1634000, cost: 9.10708999633789, perplexity: 9019.01171875\n",
      "train: step 1635000, cost: 9.117239952087402, perplexity: 9111.0205078125\n",
      "train: step 1636000, cost: 7.706636428833008, perplexity: 2223.05224609375\n",
      "train: step 1637000, cost: 7.631632328033447, perplexity: 2062.413818359375\n",
      "train: step 1638000, cost: 9.456851959228516, perplexity: 12795.5390625\n",
      "train: step 1639000, cost: 7.440323352813721, perplexity: 1703.30078125\n",
      "train: step 1640000, cost: 9.039204597473145, perplexity: 8427.0712890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 1641000, cost: 7.275949478149414, perplexity: 1445.12255859375\n",
      "train: step 1642000, cost: 9.082924842834473, perplexity: 8803.677734375\n",
      "train: step 1643000, cost: 8.215330123901367, perplexity: 3697.196533203125\n",
      "train: step 1644000, cost: 8.11795711517334, perplexity: 3354.16162109375\n",
      "train: step 1645000, cost: 7.4772562980651855, perplexity: 1767.3848876953125\n",
      "train: step 1646000, cost: 9.84532642364502, perplexity: 18869.958984375\n",
      "train: step 1647000, cost: 9.471701622009277, perplexity: 12986.9677734375\n",
      "train: step 1648000, cost: 7.208427906036377, perplexity: 1350.76708984375\n",
      "train: step 1649000, cost: 7.700467109680176, perplexity: 2209.3798828125\n",
      "train: step 1650000, cost: 8.756184577941895, perplexity: 6349.837890625\n",
      "train: step 1651000, cost: 8.869584083557129, perplexity: 7112.322265625\n",
      "train: step 1652000, cost: 6.837033748626709, perplexity: 931.7213134765625\n",
      "train: step 1653000, cost: 7.987273216247559, perplexity: 2943.260498046875\n",
      "train: step 1654000, cost: 8.756593704223633, perplexity: 6352.4365234375\n",
      "train: step 1655000, cost: 7.6550798416137695, perplexity: 2111.34375\n",
      "train: step 1656000, cost: 8.44272518157959, perplexity: 4641.185546875\n",
      "train: step 1657000, cost: 8.003788948059082, perplexity: 2992.274169921875\n",
      "train: step 1658000, cost: 9.341568946838379, perplexity: 11402.283203125\n",
      "train: step 1659000, cost: 7.50958776473999, perplexity: 1825.4608154296875\n",
      "train: step 1660000, cost: 8.999367713928223, perplexity: 8097.9619140625\n",
      "train: step 1661000, cost: 8.030208587646484, perplexity: 3072.382568359375\n",
      "train: step 1662000, cost: 7.982574939727783, perplexity: 2929.464599609375\n",
      "train: step 1663000, cost: 8.528051376342773, perplexity: 5054.5869140625\n",
      "train: step 1664000, cost: 7.657135009765625, perplexity: 2115.687255859375\n",
      "train: step 1665000, cost: 10.65314769744873, perplexity: 42325.61328125\n",
      "train: step 1666000, cost: 13.641733169555664, perplexity: 840484.0\n",
      "train: step 1667000, cost: 7.415133476257324, perplexity: 1660.930908203125\n",
      "train: step 1668000, cost: 8.791109085083008, perplexity: 6575.52099609375\n",
      "train: step 1669000, cost: 10.082898139953613, perplexity: 23930.23828125\n",
      "train: step 1670000, cost: 9.247054100036621, perplexity: 10373.9599609375\n",
      "train: step 1671000, cost: 9.508620262145996, perplexity: 13475.3896484375\n",
      "train: step 1672000, cost: 8.942500114440918, perplexity: 7650.2998046875\n",
      "train: step 1673000, cost: 9.178877830505371, perplexity: 9690.2724609375\n",
      "train: step 1674000, cost: 8.343377113342285, perplexity: 4202.25732421875\n",
      "train: step 1675000, cost: 10.805636405944824, perplexity: 49297.8828125\n",
      "train: step 1676000, cost: 8.061467170715332, perplexity: 3169.9375\n",
      "train: step 1677000, cost: 9.153094291687012, perplexity: 9443.6162109375\n",
      "train: step 1678000, cost: 8.392361640930176, perplexity: 4413.22802734375\n",
      "train: step 1679000, cost: 9.395782470703125, perplexity: 12037.5048828125\n",
      "train: step 1680000, cost: 6.943015098571777, perplexity: 1035.8887939453125\n",
      "train: step 1681000, cost: 9.415807723999023, perplexity: 12280.9892578125\n",
      "train: step 1682000, cost: 8.012518882751465, perplexity: 3018.510986328125\n",
      "train: step 1683000, cost: 8.699983596801758, perplexity: 6002.81396484375\n",
      "train: step 1684000, cost: 7.950630187988281, perplexity: 2837.3623046875\n",
      "train: step 1685000, cost: 9.904661178588867, perplexity: 20023.486328125\n",
      "train: step 1686000, cost: 9.589269638061523, perplexity: 14607.197265625\n",
      "train: step 1687000, cost: 9.42121410369873, perplexity: 12347.564453125\n",
      "train: step 1688000, cost: 9.212854385375977, perplexity: 10025.171875\n",
      "train: step 1689000, cost: 7.350573539733887, perplexity: 1557.08935546875\n",
      "train: step 1690000, cost: 8.267476081848145, perplexity: 3895.105712890625\n",
      "train: step 1691000, cost: 8.14515209197998, perplexity: 3446.629638671875\n",
      "train: step 1692000, cost: 7.682925224304199, perplexity: 2170.9609375\n",
      "train: step 1693000, cost: 10.289003372192383, perplexity: 29407.44921875\n",
      "train: step 1694000, cost: 7.396657466888428, perplexity: 1630.525146484375\n",
      "train: step 1695000, cost: 8.1531400680542, perplexity: 3474.271484375\n",
      "train: step 1696000, cost: 8.04322624206543, perplexity: 3112.63916015625\n",
      "train: step 1697000, cost: 8.81185531616211, perplexity: 6713.36328125\n",
      "Model saved in path: /tmp/p2_run02_11.ckpt\n",
      "validation: epoch 11, cost: 10.526460647583008, perplexity: 37289.26171875\n",
      "test: epoch 11, cost: 10.723620414733887, perplexity: [19173.516, 17592.662, 17449.03, 11225.486, 21339.318, 24617.826, 22408.908, 66997.37, 14599.063, 22131.621, 45416.027]\n",
      "train: step 1698000, cost: 8.866808891296387, perplexity: 7092.611328125\n",
      "train: step 1699000, cost: 8.350876808166504, perplexity: 4233.89111328125\n",
      "train: step 1700000, cost: 9.172406196594238, perplexity: 9627.7626953125\n",
      "train: step 1701000, cost: 8.02676010131836, perplexity: 3061.8056640625\n",
      "train: step 1702000, cost: 8.987082481384277, perplexity: 7999.0849609375\n",
      "train: step 1703000, cost: 12.226082801818848, perplexity: 204042.34375\n",
      "train: step 1704000, cost: 10.350214004516602, perplexity: 31263.732421875\n",
      "train: step 1705000, cost: 11.120637893676758, perplexity: 67550.984375\n",
      "train: step 1706000, cost: 8.58916187286377, perplexity: 5373.1083984375\n",
      "train: step 1707000, cost: 10.95481014251709, perplexity: 57228.66015625\n",
      "train: step 1708000, cost: 6.932219505310059, perplexity: 1024.765869140625\n",
      "train: step 1709000, cost: 12.787158966064453, perplexity: 357595.9375\n",
      "train: step 1710000, cost: 9.948895454406738, perplexity: 20929.09375\n",
      "train: step 1711000, cost: 9.728670120239258, perplexity: 16792.20703125\n",
      "train: step 1712000, cost: 9.846288681030273, perplexity: 18888.125\n",
      "train: step 1713000, cost: 7.677711009979248, perplexity: 2159.670654296875\n",
      "train: step 1714000, cost: 10.775728225708008, perplexity: 47845.3046875\n",
      "train: step 1715000, cost: 10.47431468963623, perplexity: 35394.60546875\n",
      "train: step 1716000, cost: 13.485563278198242, perplexity: 718961.625\n",
      "train: step 1717000, cost: 7.209898948669434, perplexity: 1352.755615234375\n",
      "train: step 1718000, cost: 7.91643762588501, perplexity: 2741.985595703125\n",
      "train: step 1719000, cost: 8.712030410766602, perplexity: 6075.56591796875\n",
      "train: step 1720000, cost: 8.206986427307129, perplexity: 3666.4765625\n",
      "train: step 1721000, cost: 8.324626922607422, perplexity: 4124.19873046875\n",
      "train: step 1722000, cost: 9.213349342346191, perplexity: 10030.134765625\n",
      "train: step 1723000, cost: 8.191141128540039, perplexity: 3608.837646484375\n",
      "train: step 1724000, cost: 8.191746711730957, perplexity: 3611.02392578125\n",
      "train: step 1725000, cost: 10.968026161193848, perplexity: 57990.015625\n",
      "train: step 1726000, cost: 8.784245491027832, perplexity: 6530.54345703125\n",
      "train: step 1727000, cost: 10.965266227722168, perplexity: 57830.1875\n",
      "train: step 1728000, cost: 8.51550579071045, perplexity: 4991.5703125\n",
      "train: step 1729000, cost: 10.444457054138184, perplexity: 34353.42578125\n",
      "train: step 1730000, cost: 6.845456123352051, perplexity: 939.6017456054688\n",
      "train: step 1731000, cost: 8.437570571899414, perplexity: 4617.32421875\n",
      "train: step 1732000, cost: 7.729469299316406, perplexity: 2274.394775390625\n",
      "train: step 1733000, cost: 8.450165748596191, perplexity: 4675.84765625\n",
      "train: step 1734000, cost: 8.21086311340332, perplexity: 3680.718017578125\n",
      "train: step 1735000, cost: 9.144563674926758, perplexity: 9363.3994140625\n",
      "train: step 1736000, cost: 8.198826789855957, perplexity: 3636.68115234375\n",
      "train: step 1737000, cost: 9.324613571166992, perplexity: 11210.5830078125\n",
      "train: step 1738000, cost: 8.313688278198242, perplexity: 4079.330810546875\n",
      "train: step 1739000, cost: 8.626387596130371, perplexity: 5576.89599609375\n",
      "train: step 1740000, cost: 8.903977394104004, perplexity: 7361.19384765625\n",
      "train: step 1741000, cost: 8.543709754943848, perplexity: 5134.3564453125\n",
      "train: step 1742000, cost: 9.902905464172363, perplexity: 19988.361328125\n",
      "train: step 1743000, cost: 8.189804077148438, perplexity: 3604.015869140625\n",
      "train: step 1744000, cost: 8.473325729370117, perplexity: 4785.40380859375\n",
      "train: step 1745000, cost: 14.660005569458008, perplexity: 2326802.5\n",
      "train: step 1746000, cost: 9.535238265991211, perplexity: 13838.892578125\n",
      "train: step 1747000, cost: 8.607538223266602, perplexity: 5472.75927734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 1748000, cost: 9.163071632385254, perplexity: 9538.310546875\n",
      "train: step 1749000, cost: 9.404598236083984, perplexity: 12144.09375\n",
      "train: step 1750000, cost: 9.986812591552734, perplexity: 21737.900390625\n",
      "train: step 1751000, cost: 10.117599487304688, perplexity: 24775.224609375\n",
      "train: step 1752000, cost: 9.980194091796875, perplexity: 21594.50390625\n",
      "train: step 1753000, cost: 12.003253936767578, perplexity: 163285.234375\n",
      "train: step 1754000, cost: 8.414060592651367, perplexity: 4510.03662109375\n",
      "train: step 1755000, cost: 9.26014518737793, perplexity: 10510.6591796875\n",
      "train: step 1756000, cost: 7.284888744354248, perplexity: 1458.098876953125\n",
      "train: step 1757000, cost: 8.27754020690918, perplexity: 3934.50439453125\n",
      "train: step 1758000, cost: 7.918837547302246, perplexity: 2748.573974609375\n",
      "train: step 1759000, cost: 13.453200340270996, perplexity: 696066.375\n",
      "train: step 1760000, cost: 8.461926460266113, perplexity: 4731.1640625\n",
      "train: step 1761000, cost: 6.683236122131348, perplexity: 798.9002685546875\n",
      "train: step 1762000, cost: 8.150835990905762, perplexity: 3466.275634765625\n",
      "train: step 1763000, cost: 7.095146656036377, perplexity: 1206.0992431640625\n",
      "train: step 1764000, cost: 10.618060111999512, perplexity: 40866.26171875\n",
      "train: step 1765000, cost: 11.41673755645752, perplexity: 90829.3359375\n",
      "train: step 1766000, cost: 8.13388729095459, perplexity: 3408.021728515625\n",
      "train: step 1767000, cost: 9.560032844543457, perplexity: 14186.3115234375\n",
      "train: step 1768000, cost: 8.207944869995117, perplexity: 3669.992431640625\n",
      "train: step 1769000, cost: 10.67538833618164, perplexity: 43277.5078125\n",
      "train: step 1770000, cost: 8.913729667663574, perplexity: 7433.33349609375\n",
      "train: step 1771000, cost: 7.046257495880127, perplexity: 1148.55224609375\n",
      "train: step 1772000, cost: 9.604569435119629, perplexity: 14832.40234375\n",
      "train: step 1773000, cost: 8.670332908630371, perplexity: 5827.43896484375\n",
      "train: step 1774000, cost: 10.079390525817871, perplexity: 23846.44921875\n",
      "train: step 1775000, cost: 8.217041969299316, perplexity: 3703.531005859375\n",
      "train: step 1776000, cost: 11.139498710632324, perplexity: 68837.140625\n",
      "train: step 1777000, cost: 8.547770500183105, perplexity: 5155.248046875\n",
      "train: step 1778000, cost: 8.417571067810059, perplexity: 4525.89697265625\n",
      "train: step 1779000, cost: 8.625980377197266, perplexity: 5574.62548828125\n",
      "train: step 1780000, cost: 9.708426475524902, perplexity: 16455.6875\n",
      "train: step 1781000, cost: 7.930080890655518, perplexity: 2779.651611328125\n",
      "train: step 1782000, cost: 6.983917236328125, perplexity: 1079.1373291015625\n",
      "train: step 1783000, cost: 11.11981201171875, perplexity: 67495.21875\n",
      "train: step 1784000, cost: 9.505620002746582, perplexity: 13435.01953125\n",
      "train: step 1785000, cost: 8.018636703491211, perplexity: 3037.0341796875\n",
      "train: step 1786000, cost: 9.74144172668457, perplexity: 17008.044921875\n",
      "train: step 1787000, cost: 10.068259239196777, perplexity: 23582.48046875\n",
      "train: step 1788000, cost: 8.439698219299316, perplexity: 4627.158203125\n",
      "train: step 1789000, cost: 8.735108375549316, perplexity: 6217.408203125\n",
      "train: step 1790000, cost: 7.7654194831848145, perplexity: 2357.6474609375\n",
      "train: step 1791000, cost: 6.861760139465332, perplexity: 955.046630859375\n",
      "train: step 1792000, cost: 7.762387275695801, perplexity: 2350.50927734375\n",
      "train: step 1793000, cost: 9.36191177368164, perplexity: 11636.6142578125\n",
      "train: step 1794000, cost: 8.207255363464355, perplexity: 3667.462646484375\n",
      "train: step 1795000, cost: 8.486006736755371, perplexity: 4846.47412109375\n",
      "train: step 1796000, cost: 7.398684501647949, perplexity: 1633.833740234375\n",
      "train: step 1797000, cost: 10.004850387573242, perplexity: 22133.564453125\n",
      "train: step 1798000, cost: 8.622967720031738, perplexity: 5557.85595703125\n",
      "train: step 1799000, cost: 14.268807411193848, perplexity: 1573491.25\n",
      "train: step 1800000, cost: 8.29518985748291, perplexity: 4004.563232421875\n",
      "train: step 1801000, cost: 8.741151809692383, perplexity: 6255.09619140625\n",
      "train: step 1802000, cost: 10.054868698120117, perplexity: 23268.798828125\n",
      "train: step 1803000, cost: 9.254973411560059, perplexity: 10456.4404296875\n",
      "train: step 1804000, cost: 9.761605262756348, perplexity: 17354.46875\n",
      "train: step 1805000, cost: 8.295230865478516, perplexity: 4004.727783203125\n",
      "train: step 1806000, cost: 8.41828727722168, perplexity: 4529.1396484375\n",
      "train: step 1807000, cost: 8.140340805053711, perplexity: 3430.086669921875\n",
      "train: step 1808000, cost: 7.339010715484619, perplexity: 1539.1885986328125\n",
      "train: step 1809000, cost: 9.17422866821289, perplexity: 9645.326171875\n",
      "train: step 1810000, cost: 14.614561080932617, perplexity: 2223429.0\n",
      "train: step 1811000, cost: 8.626340866088867, perplexity: 5576.63525390625\n",
      "train: step 1812000, cost: 8.467394828796387, perplexity: 4757.1064453125\n",
      "train: step 1813000, cost: 8.319438934326172, perplexity: 4102.857421875\n",
      "train: step 1814000, cost: 9.504202842712402, perplexity: 13415.9931640625\n",
      "train: step 1815000, cost: 7.652283668518066, perplexity: 2105.4482421875\n",
      "train: step 1816000, cost: 8.165937423706055, perplexity: 3519.0185546875\n",
      "train: step 1817000, cost: 8.843320846557617, perplexity: 6927.9609375\n",
      "train: step 1818000, cost: 6.956324100494385, perplexity: 1049.767578125\n",
      "train: step 1819000, cost: 7.680091381072998, perplexity: 2164.817626953125\n",
      "train: step 1820000, cost: 8.136876106262207, perplexity: 3418.222900390625\n",
      "train: step 1821000, cost: 11.928206443786621, perplexity: 151479.625\n",
      "train: step 1822000, cost: 9.868778228759766, perplexity: 19317.72265625\n",
      "train: step 1823000, cost: 10.685807228088379, perplexity: 43730.76953125\n",
      "train: step 1824000, cost: 9.49609375, perplexity: 13307.6435546875\n",
      "train: step 1825000, cost: 11.203935623168945, perplexity: 73418.828125\n",
      "train: step 1826000, cost: 8.583724021911621, perplexity: 5343.9697265625\n",
      "train: step 1827000, cost: 8.109156608581543, perplexity: 3324.77294921875\n",
      "train: step 1828000, cost: 7.802506446838379, perplexity: 2446.726806640625\n",
      "train: step 1829000, cost: 9.682778358459473, perplexity: 16038.99609375\n",
      "train: step 1830000, cost: 8.721147537231445, perplexity: 6131.2109375\n",
      "train: step 1831000, cost: 9.328131675720215, perplexity: 11250.0927734375\n",
      "train: step 1832000, cost: 9.925201416015625, perplexity: 20439.02734375\n",
      "train: step 1833000, cost: 7.707688331604004, perplexity: 2225.39208984375\n",
      "train: step 1834000, cost: 9.163026809692383, perplexity: 9537.8837890625\n",
      "train: step 1835000, cost: 8.691240310668945, perplexity: 5950.55859375\n",
      "train: step 1836000, cost: 7.005517959594727, perplexity: 1102.7010498046875\n",
      "train: step 1837000, cost: 8.432899475097656, perplexity: 4595.80615234375\n",
      "train: step 1838000, cost: 8.659218788146973, perplexity: 5763.03125\n",
      "train: step 1839000, cost: 9.527504920959473, perplexity: 13732.28515625\n",
      "train: step 1840000, cost: 8.348904609680176, perplexity: 4225.54931640625\n",
      "train: step 1841000, cost: 15.673051834106445, perplexity: 6407962.0\n",
      "train: step 1842000, cost: 7.8716721534729, perplexity: 2621.9462890625\n",
      "train: step 1843000, cost: 8.10975170135498, perplexity: 3326.751953125\n",
      "train: step 1844000, cost: 11.349457740783691, perplexity: 84919.390625\n",
      "train: step 1845000, cost: 8.632827758789062, perplexity: 5612.927734375\n",
      "train: step 1846000, cost: 11.823028564453125, perplexity: 136356.5625\n",
      "train: step 1847000, cost: 10.712141036987305, perplexity: 44897.6640625\n",
      "train: step 1848000, cost: 9.678630828857422, perplexity: 15972.6123046875\n",
      "train: step 1849000, cost: 10.081439971923828, perplexity: 23895.369140625\n",
      "train: step 1850000, cost: 9.841126441955566, perplexity: 18790.87109375\n",
      "train: step 1851000, cost: 14.480973243713379, perplexity: 1945390.5\n",
      "Model saved in path: /tmp/p2_run02_12.ckpt\n",
      "validation: epoch 12, cost: 10.209124565124512, perplexity: 27149.7890625\n",
      "test: epoch 12, cost: 11.076287269592285, perplexity: [19173.516, 17592.662, 17449.03, 11225.486, 21339.318, 24617.826, 22408.908, 66997.37, 14599.063, 22131.621, 45416.027, 64620.516]\n",
      "train: step 1852000, cost: 8.015030860900879, perplexity: 3026.102783203125\n",
      "train: step 1853000, cost: 10.531882286071777, perplexity: 37491.98046875\n",
      "train: step 1854000, cost: 9.200821876525879, perplexity: 9905.2666015625\n",
      "train: step 1855000, cost: 7.509515285491943, perplexity: 1825.3284912109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 1856000, cost: 8.479073524475098, perplexity: 4812.98876953125\n",
      "train: step 1857000, cost: 10.336679458618164, perplexity: 30843.44140625\n",
      "train: step 1858000, cost: 7.853916645050049, perplexity: 2575.802978515625\n",
      "train: step 1859000, cost: 8.980850219726562, perplexity: 7949.3876953125\n",
      "train: step 1860000, cost: 7.439599514007568, perplexity: 1702.068359375\n",
      "train: step 1861000, cost: 10.257023811340332, perplexity: 28481.890625\n",
      "train: step 1862000, cost: 12.311875343322754, perplexity: 222320.515625\n",
      "train: step 1863000, cost: 9.095097541809082, perplexity: 8911.4970703125\n",
      "train: step 1864000, cost: 7.2673139572143555, perplexity: 1432.697021484375\n",
      "train: step 1865000, cost: 14.492012977600098, perplexity: 1966986.0\n",
      "train: step 1866000, cost: 9.747325897216797, perplexity: 17108.41796875\n",
      "train: step 1867000, cost: 8.588139533996582, perplexity: 5367.6181640625\n",
      "train: step 1868000, cost: 8.024430274963379, perplexity: 3054.680419921875\n",
      "train: step 1869000, cost: 8.479902267456055, perplexity: 4816.97900390625\n",
      "train: step 1870000, cost: 8.792718887329102, perplexity: 6586.11474609375\n",
      "train: step 1871000, cost: 9.484869003295898, perplexity: 13159.1025390625\n",
      "train: step 1872000, cost: 10.065645217895508, perplexity: 23520.9140625\n",
      "train: step 1873000, cost: 8.627653121948242, perplexity: 5583.9580078125\n",
      "train: step 1874000, cost: 6.3639984130859375, perplexity: 580.5630493164062\n",
      "train: step 1875000, cost: 9.368733406066895, perplexity: 11716.2666015625\n",
      "train: step 1876000, cost: 11.817081451416016, perplexity: 135548.046875\n",
      "train: step 1877000, cost: 9.354202270507812, perplexity: 11547.24609375\n",
      "train: step 1878000, cost: 7.321841239929199, perplexity: 1512.9871826171875\n",
      "train: step 1879000, cost: 10.708307266235352, perplexity: 44725.8671875\n",
      "train: step 1880000, cost: 7.473345756530762, perplexity: 1760.4869384765625\n",
      "train: step 1881000, cost: 8.116742134094238, perplexity: 3350.0888671875\n",
      "train: step 1882000, cost: 9.349499702453613, perplexity: 11493.0712890625\n",
      "train: step 1883000, cost: 7.641758441925049, perplexity: 2083.404052734375\n",
      "train: step 1884000, cost: 7.990498065948486, perplexity: 2952.767333984375\n",
      "train: step 1885000, cost: 6.64068603515625, perplexity: 765.6200561523438\n",
      "train: step 1886000, cost: 8.95057201385498, perplexity: 7712.3017578125\n",
      "train: step 1887000, cost: 13.277807235717773, perplexity: 584088.1875\n",
      "train: step 1888000, cost: 6.714782238006592, perplexity: 824.5042114257812\n",
      "train: step 1889000, cost: 8.388143539428711, perplexity: 4394.65185546875\n",
      "train: step 1890000, cost: 7.276214122772217, perplexity: 1445.505126953125\n",
      "train: step 1891000, cost: 8.378926277160645, perplexity: 4354.33154296875\n",
      "train: step 1892000, cost: 7.100683212280273, perplexity: 1212.79541015625\n",
      "train: step 1893000, cost: 6.440028667449951, perplexity: 626.4247436523438\n",
      "train: step 1894000, cost: 11.362160682678223, perplexity: 86005.0\n",
      "train: step 1895000, cost: 8.842360496520996, perplexity: 6921.31103515625\n",
      "train: step 1896000, cost: 7.157923221588135, perplexity: 1284.2410888671875\n",
      "train: step 1897000, cost: 8.513747215270996, perplexity: 4982.7998046875\n",
      "train: step 1898000, cost: 6.981536388397217, perplexity: 1076.571044921875\n",
      "train: step 1899000, cost: 8.60238265991211, perplexity: 5444.61669921875\n",
      "train: step 1900000, cost: 8.367447853088379, perplexity: 4304.6357421875\n",
      "train: step 1901000, cost: 7.855984210968018, perplexity: 2581.134033203125\n",
      "train: step 1902000, cost: 7.2983479499816895, perplexity: 1477.8564453125\n",
      "train: step 1903000, cost: 9.558895111083984, perplexity: 14170.1806640625\n",
      "train: step 1904000, cost: 8.082350730895996, perplexity: 3236.833251953125\n",
      "train: step 1905000, cost: 7.995659351348877, perplexity: 2968.046875\n",
      "train: step 1906000, cost: 8.304182052612305, perplexity: 4040.735595703125\n",
      "train: step 1907000, cost: 8.026407241821289, perplexity: 3060.7255859375\n",
      "train: step 1908000, cost: 10.700078964233398, perplexity: 44359.359375\n",
      "train: step 1909000, cost: 6.860657691955566, perplexity: 953.9943237304688\n",
      "train: step 1910000, cost: 9.468473434448242, perplexity: 12945.111328125\n",
      "train: step 1911000, cost: 12.957014083862305, perplexity: 423798.78125\n",
      "train: step 1912000, cost: 8.441272735595703, perplexity: 4634.44970703125\n",
      "train: step 1913000, cost: 10.485898971557617, perplexity: 35807.0078125\n",
      "train: step 1914000, cost: 7.751683712005615, perplexity: 2325.484619140625\n",
      "train: step 1915000, cost: 8.944304466247559, perplexity: 7664.11572265625\n",
      "train: step 1916000, cost: 11.003265380859375, perplexity: 60069.96875\n",
      "train: step 1917000, cost: 9.907389640808105, perplexity: 20078.1953125\n",
      "train: step 1918000, cost: 8.23469352722168, perplexity: 3769.484130859375\n",
      "train: step 1919000, cost: 7.102072238922119, perplexity: 1214.481201171875\n",
      "train: step 1920000, cost: 8.598453521728516, perplexity: 5423.26611328125\n",
      "train: step 1921000, cost: 6.891797065734863, perplexity: 984.16845703125\n",
      "train: step 1922000, cost: 8.355240821838379, perplexity: 4252.408203125\n",
      "train: step 1923000, cost: 9.353750228881836, perplexity: 11542.02734375\n",
      "train: step 1924000, cost: 8.442248344421387, perplexity: 4638.97314453125\n",
      "train: step 1925000, cost: 7.407100200653076, perplexity: 1647.6416015625\n",
      "train: step 1926000, cost: 8.386932373046875, perplexity: 4389.33203125\n",
      "train: step 1927000, cost: 9.525394439697266, perplexity: 13703.333984375\n",
      "train: step 1928000, cost: 9.124780654907227, perplexity: 9179.9833984375\n",
      "train: step 1929000, cost: 10.049564361572266, perplexity: 23145.701171875\n",
      "train: step 1930000, cost: 8.510730743408203, perplexity: 4967.7919921875\n",
      "train: step 1931000, cost: 8.750643730163574, perplexity: 6314.751953125\n",
      "train: step 1932000, cost: 8.46684455871582, perplexity: 4754.4892578125\n",
      "train: step 1933000, cost: 8.648195266723633, perplexity: 5699.8505859375\n",
      "train: step 1934000, cost: 7.550939083099365, perplexity: 1902.5284423828125\n",
      "train: step 1935000, cost: 7.39107608795166, perplexity: 1621.449951171875\n",
      "train: step 1936000, cost: 10.433547019958496, perplexity: 33980.6640625\n",
      "train: step 1937000, cost: 8.047130584716797, perplexity: 3124.815673828125\n",
      "train: step 1938000, cost: 10.251936912536621, perplexity: 28337.376953125\n",
      "train: step 1939000, cost: 9.21753978729248, perplexity: 10072.25390625\n",
      "train: step 1940000, cost: 12.593438148498535, perplexity: 294618.96875\n",
      "train: step 1941000, cost: 6.850674629211426, perplexity: 944.5178833007812\n",
      "train: step 1942000, cost: 12.70633316040039, perplexity: 329830.15625\n",
      "train: step 1943000, cost: 9.50245189666748, perplexity: 13392.5234375\n",
      "train: step 1944000, cost: 10.636494636535645, perplexity: 41626.59765625\n",
      "train: step 1945000, cost: 11.92978286743164, perplexity: 151718.609375\n",
      "train: step 1946000, cost: 8.867363929748535, perplexity: 7096.54931640625\n",
      "train: step 1947000, cost: 10.706357955932617, perplexity: 44638.765625\n",
      "train: step 1948000, cost: 6.928203105926514, perplexity: 1020.6583251953125\n",
      "train: step 1949000, cost: 11.290376663208008, perplexity: 80047.59375\n",
      "train: step 1950000, cost: 7.664732456207275, perplexity: 2131.822509765625\n",
      "train: step 1951000, cost: 12.108083724975586, perplexity: 181331.796875\n",
      "train: step 1952000, cost: 8.08975601196289, perplexity: 3260.891845703125\n",
      "train: step 1953000, cost: 9.756158828735352, perplexity: 17260.205078125\n",
      "train: step 1954000, cost: 7.787622928619385, perplexity: 2410.58056640625\n",
      "train: step 1955000, cost: 6.901224613189697, perplexity: 993.4906005859375\n",
      "train: step 1956000, cost: 8.072562217712402, perplexity: 3205.303955078125\n",
      "train: step 1957000, cost: 8.39376163482666, perplexity: 4419.41064453125\n",
      "train: step 1958000, cost: 8.537729263305664, perplexity: 5103.7421875\n",
      "train: step 1959000, cost: 10.085463523864746, perplexity: 23991.70703125\n",
      "train: step 1960000, cost: 6.584878444671631, perplexity: 724.06298828125\n",
      "train: step 1961000, cost: 7.248915672302246, perplexity: 1406.578857421875\n",
      "train: step 1962000, cost: 8.789111137390137, perplexity: 6562.396484375\n",
      "train: step 1963000, cost: 7.512114524841309, perplexity: 1830.0792236328125\n",
      "train: step 1964000, cost: 8.27808666229248, perplexity: 3936.655029296875\n",
      "train: step 1965000, cost: 8.882596969604492, perplexity: 7205.47900390625\n",
      "train: step 1966000, cost: 8.882128715515137, perplexity: 7202.10595703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 1967000, cost: 8.331609725952148, perplexity: 4153.09716796875\n",
      "train: step 1968000, cost: 7.9657368659973145, perplexity: 2880.551025390625\n",
      "train: step 1969000, cost: 8.7710599899292, perplexity: 6445.00048828125\n",
      "train: step 1970000, cost: 8.74741268157959, perplexity: 6294.38134765625\n",
      "train: step 1971000, cost: 8.972835540771484, perplexity: 7885.9306640625\n",
      "train: step 1972000, cost: 7.511946678161621, perplexity: 1829.77197265625\n",
      "train: step 1973000, cost: 11.281149864196777, perplexity: 79312.40625\n",
      "train: step 1974000, cost: 8.60567569732666, perplexity: 5462.57568359375\n",
      "train: step 1975000, cost: 7.952330112457275, perplexity: 2842.189697265625\n",
      "train: step 1976000, cost: 7.686087131500244, perplexity: 2177.83642578125\n",
      "train: step 1977000, cost: 9.412363052368164, perplexity: 12238.7578125\n",
      "train: step 1978000, cost: 8.037740707397461, perplexity: 3095.611572265625\n",
      "train: step 1979000, cost: 14.23836898803711, perplexity: 1526318.25\n",
      "train: step 1980000, cost: 9.08285903930664, perplexity: 8803.0986328125\n",
      "train: step 1981000, cost: 7.968742847442627, perplexity: 2889.22314453125\n",
      "train: step 1982000, cost: 9.947357177734375, perplexity: 20896.921875\n",
      "train: step 1983000, cost: 9.185113906860352, perplexity: 9750.890625\n",
      "train: step 1984000, cost: 9.144960403442383, perplexity: 9367.1142578125\n",
      "train: step 1985000, cost: 8.469595909118652, perplexity: 4767.5888671875\n",
      "train: step 1986000, cost: 9.342061996459961, perplexity: 11407.9072265625\n",
      "train: step 1987000, cost: 10.306221961975098, perplexity: 29918.189453125\n",
      "train: step 1988000, cost: 8.500212669372559, perplexity: 4915.81396484375\n",
      "train: step 1989000, cost: 12.321124076843262, perplexity: 224386.234375\n",
      "train: step 1990000, cost: 10.187051773071289, perplexity: 26557.083984375\n",
      "train: step 1991000, cost: 9.213247299194336, perplexity: 10029.111328125\n",
      "train: step 1992000, cost: 6.9997053146362305, perplexity: 1096.31005859375\n",
      "train: step 1993000, cost: 9.321673393249512, perplexity: 11177.6708984375\n",
      "train: step 1994000, cost: 7.839001655578613, perplexity: 2537.670166015625\n",
      "train: step 1995000, cost: 7.407930374145508, perplexity: 1649.010009765625\n",
      "train: step 1996000, cost: 7.684266567230225, perplexity: 2173.875244140625\n",
      "train: step 1997000, cost: 8.595108985900879, perplexity: 5405.158203125\n",
      "train: step 1998000, cost: 8.818716049194336, perplexity: 6759.580078125\n",
      "train: step 1999000, cost: 10.525110244750977, perplexity: 37238.9375\n",
      "train: step 2000000, cost: 6.822228908538818, perplexity: 918.0289306640625\n",
      "train: step 2001000, cost: 8.541609764099121, perplexity: 5123.58544921875\n",
      "train: step 2002000, cost: 8.691434860229492, perplexity: 5951.7158203125\n",
      "train: step 2003000, cost: 7.776577949523926, perplexity: 2384.1025390625\n",
      "train: step 2004000, cost: 6.573368549346924, perplexity: 715.77685546875\n",
      "train: step 2005000, cost: 8.820027351379395, perplexity: 6768.44970703125\n",
      "Model saved in path: /tmp/p2_run02_13.ckpt\n",
      "validation: epoch 13, cost: 8.809744834899902, perplexity: 6699.2099609375\n",
      "test: epoch 13, cost: 9.739787101745605, perplexity: [19173.516, 17592.662, 17449.03, 11225.486, 21339.318, 24617.826, 22408.908, 66997.37, 14599.063, 22131.621, 45416.027, 64620.516, 16979.926]\n",
      "train: step 2006000, cost: 7.796771049499512, perplexity: 2432.734130859375\n",
      "train: step 2007000, cost: 7.7218194007873535, perplexity: 2257.0625\n",
      "train: step 2008000, cost: 9.971846580505371, perplexity: 21414.994140625\n",
      "train: step 2009000, cost: 7.050678730010986, perplexity: 1153.6414794921875\n",
      "train: step 2010000, cost: 10.776928901672363, perplexity: 47902.78515625\n",
      "train: step 2011000, cost: 8.062515258789062, perplexity: 3173.261474609375\n",
      "train: step 2012000, cost: 8.060778617858887, perplexity: 3167.755615234375\n",
      "train: step 2013000, cost: 7.4269561767578125, perplexity: 1680.68408203125\n",
      "train: step 2014000, cost: 10.403257369995117, perplexity: 32966.8359375\n",
      "train: step 2015000, cost: 9.591370582580566, perplexity: 14637.9189453125\n",
      "train: step 2016000, cost: 6.754166603088379, perplexity: 857.6246948242188\n",
      "train: step 2017000, cost: 10.40068531036377, perplexity: 32882.15234375\n",
      "train: step 2018000, cost: 7.917572975158691, perplexity: 2745.1005859375\n",
      "train: step 2019000, cost: 8.086323738098145, perplexity: 3249.71875\n",
      "train: step 2020000, cost: 9.298846244812012, perplexity: 10925.40625\n",
      "train: step 2021000, cost: 10.61856460571289, perplexity: 40886.8828125\n",
      "train: step 2022000, cost: 8.015507698059082, perplexity: 3027.5458984375\n",
      "train: step 2023000, cost: 7.682476997375488, perplexity: 2169.98828125\n",
      "train: step 2024000, cost: 9.568593978881836, perplexity: 14308.28515625\n",
      "train: step 2025000, cost: 8.908461570739746, perplexity: 7394.2763671875\n",
      "train: step 2026000, cost: 9.05260944366455, perplexity: 8540.7958984375\n",
      "train: step 2027000, cost: 10.173066139221191, perplexity: 26188.251953125\n",
      "train: step 2028000, cost: 12.187173843383789, perplexity: 196255.71875\n",
      "train: step 2029000, cost: 10.064797401428223, perplexity: 23500.982421875\n",
      "train: step 2030000, cost: 9.262506484985352, perplexity: 10535.5078125\n",
      "train: step 2031000, cost: 8.852072715759277, perplexity: 6988.85986328125\n",
      "train: step 2032000, cost: 8.507798194885254, perplexity: 4953.2451171875\n",
      "train: step 2033000, cost: 8.042393684387207, perplexity: 3110.048828125\n",
      "train: step 2034000, cost: 9.028979301452637, perplexity: 8341.3408203125\n",
      "train: step 2035000, cost: 9.589874267578125, perplexity: 14616.03125\n",
      "train: step 2036000, cost: 8.381911277770996, perplexity: 4367.34814453125\n",
      "train: step 2037000, cost: 9.769787788391113, perplexity: 17497.052734375\n",
      "train: step 2038000, cost: 7.121885299682617, perplexity: 1238.78369140625\n",
      "train: step 2039000, cost: 8.157159805297852, perplexity: 3488.26513671875\n",
      "train: step 2040000, cost: 8.916827201843262, perplexity: 7456.39404296875\n",
      "train: step 2041000, cost: 9.116729736328125, perplexity: 9106.373046875\n",
      "train: step 2042000, cost: 8.810440063476562, perplexity: 6703.86865234375\n",
      "train: step 2043000, cost: 8.375094413757324, perplexity: 4337.67822265625\n",
      "train: step 2044000, cost: 8.917354583740234, perplexity: 7460.3271484375\n",
      "train: step 2045000, cost: 12.703354835510254, perplexity: 328849.3125\n",
      "train: step 2046000, cost: 7.843425273895264, perplexity: 2548.920654296875\n",
      "train: step 2047000, cost: 9.695712089538574, perplexity: 16247.7880859375\n",
      "train: step 2048000, cost: 7.521348476409912, perplexity: 1847.0562744140625\n",
      "train: step 2049000, cost: 7.6774582862854, perplexity: 2159.124755859375\n",
      "train: step 2050000, cost: 7.993218898773193, perplexity: 2960.812255859375\n",
      "train: step 2051000, cost: 9.418988227844238, perplexity: 12320.111328125\n",
      "train: step 2052000, cost: 9.913885116577148, perplexity: 20209.03515625\n",
      "train: step 2053000, cost: 10.133638381958008, perplexity: 25175.796875\n",
      "train: step 2054000, cost: 7.65729284286499, perplexity: 2116.021240234375\n",
      "train: step 2055000, cost: 7.856996536254883, perplexity: 2583.74853515625\n",
      "train: step 2056000, cost: 8.924641609191895, perplexity: 7514.88916015625\n",
      "train: step 2057000, cost: 8.989412307739258, perplexity: 8017.7431640625\n",
      "train: step 2058000, cost: 9.534613609313965, perplexity: 13830.2509765625\n",
      "train: step 2059000, cost: 7.528189182281494, perplexity: 1859.7347412109375\n",
      "train: step 2060000, cost: 8.401175498962402, perplexity: 4452.29736328125\n",
      "train: step 2061000, cost: 7.004960060119629, perplexity: 1102.0860595703125\n",
      "train: step 2062000, cost: 7.678457736968994, perplexity: 2161.283935546875\n",
      "train: step 2063000, cost: 6.963362693786621, perplexity: 1057.1826171875\n",
      "train: step 2064000, cost: 9.370100975036621, perplexity: 11732.2998046875\n",
      "train: step 2065000, cost: 8.43268871307373, perplexity: 4594.837890625\n",
      "train: step 2066000, cost: 8.457171440124512, perplexity: 4708.720703125\n",
      "train: step 2067000, cost: 10.214815139770508, perplexity: 27304.7265625\n",
      "train: step 2068000, cost: 7.1520161628723145, perplexity: 1276.67724609375\n",
      "train: step 2069000, cost: 8.210305213928223, perplexity: 3678.6650390625\n",
      "train: step 2070000, cost: 8.270478248596191, perplexity: 3906.816650390625\n",
      "train: step 2071000, cost: 6.857848167419434, perplexity: 951.3177490234375\n",
      "train: step 2072000, cost: 8.885894775390625, perplexity: 7229.27978515625\n",
      "train: step 2073000, cost: 9.080415725708008, perplexity: 8781.615234375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 2074000, cost: 8.171845436096191, perplexity: 3539.87060546875\n",
      "train: step 2075000, cost: 8.123970985412598, perplexity: 3374.393798828125\n",
      "train: step 2076000, cost: 8.313226699829102, perplexity: 4077.448486328125\n",
      "train: step 2077000, cost: 9.470011711120605, perplexity: 12965.0390625\n",
      "train: step 2078000, cost: 8.34264850616455, perplexity: 4199.19677734375\n",
      "train: step 2079000, cost: 8.673700332641602, perplexity: 5847.095703125\n",
      "train: step 2080000, cost: 8.175755500793457, perplexity: 3553.738525390625\n",
      "train: step 2081000, cost: 9.169801712036133, perplexity: 9602.720703125\n",
      "train: step 2082000, cost: 8.988001823425293, perplexity: 8006.44189453125\n",
      "train: step 2083000, cost: 8.412457466125488, perplexity: 4502.8125\n",
      "train: step 2084000, cost: 6.761212348937988, perplexity: 863.6886596679688\n",
      "train: step 2085000, cost: 7.590880393981934, perplexity: 1980.055908203125\n",
      "train: step 2086000, cost: 9.19435977935791, perplexity: 9841.46484375\n",
      "train: step 2087000, cost: 10.555127143859863, perplexity: 38373.68359375\n",
      "train: step 2088000, cost: 7.6359333992004395, perplexity: 2071.303466796875\n",
      "train: step 2089000, cost: 11.58260440826416, perplexity: 107216.3828125\n",
      "train: step 2090000, cost: 7.988966941833496, perplexity: 2948.25\n",
      "train: step 2091000, cost: 8.97242546081543, perplexity: 7882.697265625\n",
      "train: step 2092000, cost: 8.384038925170898, perplexity: 4376.650390625\n",
      "train: step 2093000, cost: 11.772994041442871, perplexity: 129701.90625\n",
      "train: step 2094000, cost: 8.944806098937988, perplexity: 7667.96142578125\n",
      "train: step 2095000, cost: 10.301072120666504, perplexity: 29764.51171875\n",
      "train: step 2096000, cost: 10.994579315185547, perplexity: 59550.4609375\n",
      "train: step 2097000, cost: 6.8657989501953125, perplexity: 958.91162109375\n",
      "train: step 2098000, cost: 9.211079597473145, perplexity: 10007.39453125\n",
      "train: step 2099000, cost: 10.527142524719238, perplexity: 37314.6953125\n",
      "train: step 2100000, cost: 8.547882080078125, perplexity: 5155.8232421875\n",
      "train: step 2101000, cost: 7.7153639793396, perplexity: 2242.5390625\n",
      "train: step 2102000, cost: 6.889579772949219, perplexity: 981.9887084960938\n",
      "train: step 2103000, cost: 10.877945899963379, perplexity: 52994.6328125\n",
      "train: step 2104000, cost: 13.265055656433105, perplexity: 576687.375\n",
      "train: step 2105000, cost: 8.957233428955078, perplexity: 7763.84814453125\n",
      "train: step 2106000, cost: 8.445595741271973, perplexity: 4654.52783203125\n",
      "train: step 2107000, cost: 9.060876846313477, perplexity: 8611.6982421875\n",
      "train: step 2108000, cost: 10.375696182250977, perplexity: 32070.63671875\n",
      "train: step 2109000, cost: 10.598588943481445, perplexity: 40078.24609375\n",
      "train: step 2110000, cost: 11.67866039276123, perplexity: 118026.0234375\n",
      "train: step 2111000, cost: 8.244250297546387, perplexity: 3805.680908203125\n",
      "train: step 2112000, cost: 8.149460792541504, perplexity: 3461.51220703125\n",
      "train: step 2113000, cost: 8.809194564819336, perplexity: 6695.52392578125\n",
      "train: step 2114000, cost: 8.235854148864746, perplexity: 3773.862060546875\n",
      "train: step 2115000, cost: 10.908140182495117, perplexity: 54619.16796875\n",
      "train: step 2116000, cost: 8.133794784545898, perplexity: 3407.706298828125\n",
      "train: step 2117000, cost: 8.017624855041504, perplexity: 3033.962646484375\n",
      "train: step 2118000, cost: 9.667745590209961, perplexity: 15799.6904296875\n",
      "train: step 2119000, cost: 8.874457359313965, perplexity: 7147.06689453125\n",
      "train: step 2120000, cost: 7.968023777008057, perplexity: 2887.14599609375\n",
      "train: step 2121000, cost: 7.699799060821533, perplexity: 2207.904296875\n",
      "train: step 2122000, cost: 6.3343048095703125, perplexity: 563.5774536132812\n",
      "train: step 2123000, cost: 8.005863189697266, perplexity: 2998.4873046875\n",
      "train: step 2124000, cost: 9.37486743927002, perplexity: 11788.35546875\n",
      "train: step 2125000, cost: 8.271527290344238, perplexity: 3910.91748046875\n",
      "train: step 2126000, cost: 8.032001495361328, perplexity: 3077.89599609375\n",
      "train: step 2127000, cost: 7.702136039733887, perplexity: 2213.0703125\n",
      "train: step 2128000, cost: 12.275687217712402, perplexity: 214418.96875\n",
      "train: step 2129000, cost: 8.227594375610352, perplexity: 3742.819091796875\n",
      "train: step 2130000, cost: 9.980902671813965, perplexity: 21609.810546875\n",
      "train: step 2131000, cost: 9.048291206359863, perplexity: 8503.994140625\n",
      "train: step 2132000, cost: 8.804428100585938, perplexity: 6663.68603515625\n",
      "train: step 2133000, cost: 6.655064105987549, perplexity: 776.707763671875\n",
      "train: step 2134000, cost: 8.668172836303711, perplexity: 5814.86474609375\n",
      "train: step 2135000, cost: 8.237712860107422, perplexity: 3780.8828125\n",
      "train: step 2136000, cost: 7.615288257598877, perplexity: 2028.9794921875\n",
      "train: step 2137000, cost: 9.219266891479492, perplexity: 10089.6650390625\n",
      "train: step 2138000, cost: 8.146204948425293, perplexity: 3450.26025390625\n",
      "train: step 2139000, cost: 8.388616561889648, perplexity: 4396.73095703125\n",
      "train: step 2140000, cost: 7.512715816497803, perplexity: 1831.1800537109375\n",
      "train: step 2141000, cost: 8.886275291442871, perplexity: 7232.03125\n",
      "train: step 2142000, cost: 7.625575542449951, perplexity: 2049.9599609375\n",
      "train: step 2143000, cost: 8.715075492858887, perplexity: 6094.0947265625\n",
      "train: step 2144000, cost: 8.431681632995605, perplexity: 4590.212890625\n",
      "train: step 2145000, cost: 8.990434646606445, perplexity: 8025.9443359375\n",
      "train: step 2146000, cost: 10.058091163635254, perplexity: 23343.904296875\n",
      "train: step 2147000, cost: 9.512675285339355, perplexity: 13530.142578125\n",
      "train: step 2148000, cost: 7.033454418182373, perplexity: 1133.94091796875\n",
      "train: step 2149000, cost: 8.93785285949707, perplexity: 7614.82958984375\n",
      "train: step 2150000, cost: 8.606919288635254, perplexity: 5469.373046875\n",
      "train: step 2151000, cost: 8.590088844299316, perplexity: 5378.09130859375\n",
      "train: step 2152000, cost: 9.223297119140625, perplexity: 10130.41015625\n",
      "train: step 2153000, cost: 11.597021102905273, perplexity: 108773.2890625\n",
      "train: step 2154000, cost: 8.30307388305664, perplexity: 4036.260009765625\n",
      "train: step 2155000, cost: 9.883031845092773, perplexity: 19595.041015625\n",
      "train: step 2156000, cost: 7.774742603302002, perplexity: 2379.730712890625\n",
      "train: step 2157000, cost: 8.482715606689453, perplexity: 4830.5498046875\n",
      "train: step 2158000, cost: 8.109685897827148, perplexity: 3326.533203125\n",
      "train: step 2159000, cost: 9.118993759155273, perplexity: 9127.013671875\n",
      "Model saved in path: /tmp/p2_run02_14.ckpt\n",
      "validation: epoch 14, cost: 9.887422561645508, perplexity: 19681.267578125\n",
      "test: epoch 14, cost: 10.216410636901855, perplexity: [19173.516, 17592.662, 17449.03, 11225.486, 21339.318, 24617.826, 22408.908, 66997.37, 14599.063, 22131.621, 45416.027, 64620.516, 16979.926, 27348.324]\n",
      "train: step 2160000, cost: 7.8402099609375, perplexity: 2540.73828125\n",
      "train: step 2161000, cost: 7.3536787033081055, perplexity: 1561.931884765625\n",
      "train: step 2162000, cost: 9.308648109436035, perplexity: 11033.0224609375\n",
      "train: step 2163000, cost: 8.052443504333496, perplexity: 3141.4619140625\n",
      "train: step 2164000, cost: 7.996724605560303, perplexity: 2971.210205078125\n",
      "train: step 2165000, cost: 9.31653881072998, perplexity: 11120.4248046875\n",
      "train: step 2166000, cost: 10.186938285827637, perplexity: 26554.068359375\n",
      "train: step 2167000, cost: 8.6297025680542, perplexity: 5595.41357421875\n",
      "train: step 2168000, cost: 8.693960189819336, perplexity: 5966.76513671875\n",
      "train: step 2169000, cost: 8.171285629272461, perplexity: 3537.889404296875\n",
      "train: step 2170000, cost: 7.061103820800781, perplexity: 1165.731201171875\n",
      "train: step 2171000, cost: 8.627256393432617, perplexity: 5581.7431640625\n",
      "train: step 2172000, cost: 7.473816394805908, perplexity: 1761.315673828125\n",
      "train: step 2173000, cost: 10.012422561645508, perplexity: 22301.798828125\n",
      "train: step 2174000, cost: 8.653972625732422, perplexity: 5732.87646484375\n",
      "train: step 2175000, cost: 9.09823226928711, perplexity: 8939.4765625\n",
      "train: step 2176000, cost: 11.467618942260742, perplexity: 95570.453125\n",
      "train: step 2177000, cost: 8.056756973266602, perplexity: 3155.041748046875\n",
      "train: step 2178000, cost: 7.798541069030762, perplexity: 2437.0439453125\n",
      "train: step 2179000, cost: 7.7284016609191895, perplexity: 2271.968017578125\n",
      "train: step 2180000, cost: 12.116663932800293, perplexity: 182894.34375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 2181000, cost: 8.4036226272583, perplexity: 4463.2060546875\n",
      "train: step 2182000, cost: 10.325758934020996, perplexity: 30508.44921875\n",
      "train: step 2183000, cost: 9.967516899108887, perplexity: 21322.47265625\n",
      "train: step 2184000, cost: 8.180624008178711, perplexity: 3571.082275390625\n",
      "train: step 2185000, cost: 9.784931182861328, perplexity: 17764.03515625\n",
      "train: step 2186000, cost: 7.410696029663086, perplexity: 1653.576904296875\n",
      "train: step 2187000, cost: 8.029156684875488, perplexity: 3069.15234375\n",
      "train: step 2188000, cost: 8.220247268676758, perplexity: 3715.4208984375\n",
      "train: step 2189000, cost: 8.332697868347168, perplexity: 4157.619140625\n",
      "train: step 2190000, cost: 7.754062175750732, perplexity: 2331.022216796875\n",
      "train: step 2191000, cost: 8.678350448608398, perplexity: 5874.3486328125\n",
      "train: step 2192000, cost: 7.050456523895264, perplexity: 1153.38525390625\n",
      "train: step 2193000, cost: 7.880178928375244, perplexity: 2644.345703125\n",
      "train: step 2194000, cost: 7.9262824058532715, perplexity: 2769.11328125\n",
      "train: step 2195000, cost: 9.743660926818848, perplexity: 17045.83203125\n",
      "train: step 2196000, cost: 9.321895599365234, perplexity: 11180.1552734375\n",
      "train: step 2197000, cost: 11.444467544555664, perplexity: 93383.28125\n",
      "train: step 2198000, cost: 9.155324935913086, perplexity: 9464.7060546875\n",
      "train: step 2199000, cost: 8.890356063842773, perplexity: 7261.60400390625\n",
      "train: step 2200000, cost: 8.985737800598145, perplexity: 7988.33642578125\n",
      "train: step 2201000, cost: 7.66430139541626, perplexity: 2130.903564453125\n",
      "train: step 2202000, cost: 10.29242992401123, perplexity: 29508.388671875\n",
      "train: step 2203000, cost: 9.400568008422852, perplexity: 12095.2490234375\n",
      "train: step 2204000, cost: 7.975398540496826, perplexity: 2908.516845703125\n",
      "train: step 2205000, cost: 9.325053215026855, perplexity: 11215.5126953125\n",
      "train: step 2206000, cost: 9.859745025634766, perplexity: 19144.0078125\n",
      "train: step 2207000, cost: 9.180281639099121, perplexity: 9703.8857421875\n",
      "train: step 2208000, cost: 7.689520835876465, perplexity: 2185.3271484375\n",
      "train: step 2209000, cost: 8.797298431396484, perplexity: 6616.345703125\n",
      "train: step 2210000, cost: 7.420786380767822, perplexity: 1670.346435546875\n",
      "train: step 2211000, cost: 8.353189468383789, perplexity: 4243.69384765625\n",
      "train: step 2212000, cost: 9.11220932006836, perplexity: 9065.30078125\n",
      "train: step 2213000, cost: 8.314146995544434, perplexity: 4081.202392578125\n",
      "train: step 2214000, cost: 8.311482429504395, perplexity: 4070.34228515625\n",
      "train: step 2215000, cost: 10.443774223327637, perplexity: 34329.9765625\n",
      "train: step 2216000, cost: 9.428038597106934, perplexity: 12432.1181640625\n",
      "train: step 2217000, cost: 8.271498680114746, perplexity: 3910.8056640625\n",
      "train: step 2218000, cost: 10.346593856811523, perplexity: 31150.755859375\n",
      "train: step 2219000, cost: 9.031893730163574, perplexity: 8365.6865234375\n",
      "train: step 2220000, cost: 9.65225887298584, perplexity: 15556.888671875\n",
      "train: step 2221000, cost: 9.727768898010254, perplexity: 16777.080078125\n",
      "train: step 2222000, cost: 11.014242172241211, perplexity: 60732.98046875\n",
      "train: step 2223000, cost: 6.6322712898254395, perplexity: 759.20458984375\n",
      "train: step 2224000, cost: 9.216577529907227, perplexity: 10062.56640625\n",
      "train: step 2225000, cost: 8.605820655822754, perplexity: 5463.36767578125\n",
      "train: step 2226000, cost: 10.071904182434082, perplexity: 23668.58984375\n",
      "train: step 2227000, cost: 7.551049709320068, perplexity: 1902.7388916015625\n",
      "train: step 2228000, cost: 8.778011322021484, perplexity: 6489.9580078125\n",
      "train: step 2229000, cost: 8.758481979370117, perplexity: 6364.44287109375\n",
      "train: step 2230000, cost: 8.336843490600586, perplexity: 4174.890625\n",
      "train: step 2231000, cost: 9.41934871673584, perplexity: 12324.5537109375\n",
      "train: step 2232000, cost: 8.539373397827148, perplexity: 5112.1396484375\n",
      "train: step 2233000, cost: 7.02829122543335, perplexity: 1128.101318359375\n",
      "train: step 2234000, cost: 7.4477057456970215, perplexity: 1715.9217529296875\n",
      "train: step 2235000, cost: 8.618517875671387, perplexity: 5533.1796875\n",
      "train: step 2236000, cost: 9.284677505493164, perplexity: 10771.69921875\n",
      "train: step 2237000, cost: 8.457460403442383, perplexity: 4710.08154296875\n",
      "train: step 2238000, cost: 7.737278461456299, perplexity: 2292.225341796875\n",
      "train: step 2239000, cost: 7.669802665710449, perplexity: 2142.65869140625\n",
      "train: step 2240000, cost: 8.110472679138184, perplexity: 3329.1513671875\n",
      "train: step 2241000, cost: 7.502092361450195, perplexity: 1811.829345703125\n",
      "train: step 2242000, cost: 10.129230499267578, perplexity: 25065.0703125\n",
      "train: step 2243000, cost: 7.930581092834473, perplexity: 2781.042236328125\n",
      "train: step 2244000, cost: 7.4691548347473145, perplexity: 1753.1243896484375\n",
      "train: step 2245000, cost: 8.454581260681152, perplexity: 4696.5400390625\n",
      "train: step 2246000, cost: 9.790460586547852, perplexity: 17862.53125\n",
      "train: step 2247000, cost: 7.4102091789245605, perplexity: 1652.7720947265625\n",
      "train: step 2248000, cost: 11.709940910339355, perplexity: 121776.2890625\n",
      "train: step 2249000, cost: 10.397074699401855, perplexity: 32763.642578125\n",
      "train: step 2250000, cost: 7.898247718811035, perplexity: 2692.56005859375\n",
      "train: step 2251000, cost: 7.18578577041626, perplexity: 1320.5264892578125\n",
      "train: step 2252000, cost: 8.103455543518066, perplexity: 3305.871826171875\n",
      "train: step 2253000, cost: 8.094252586364746, perplexity: 3275.587890625\n",
      "train: step 2254000, cost: 9.093310356140137, perplexity: 8895.5849609375\n",
      "train: step 2255000, cost: 8.37380599975586, perplexity: 4332.0927734375\n",
      "train: step 2256000, cost: 8.149337768554688, perplexity: 3461.086181640625\n",
      "train: step 2257000, cost: 8.30157470703125, perplexity: 4030.213623046875\n",
      "train: step 2258000, cost: 6.720547199249268, perplexity: 829.2711791992188\n",
      "train: step 2259000, cost: 10.743014335632324, perplexity: 46305.421875\n",
      "train: step 2260000, cost: 8.212297439575195, perplexity: 3686.0009765625\n",
      "train: step 2261000, cost: 8.478379249572754, perplexity: 4809.6484375\n",
      "train: step 2262000, cost: 7.538354873657227, perplexity: 1878.73681640625\n",
      "train: step 2263000, cost: 8.15872573852539, perplexity: 3493.731689453125\n",
      "train: step 2264000, cost: 13.267416954040527, perplexity: 578050.75\n",
      "train: step 2265000, cost: 11.202543258666992, perplexity: 73316.6640625\n",
      "train: step 2266000, cost: 7.570230007171631, perplexity: 1939.5863037109375\n",
      "train: step 2267000, cost: 8.209579467773438, perplexity: 3675.99609375\n",
      "train: step 2268000, cost: 10.492254257202148, perplexity: 36035.296875\n",
      "train: step 2269000, cost: 9.840598106384277, perplexity: 18780.9453125\n",
      "train: step 2270000, cost: 8.225363731384277, perplexity: 3734.479248046875\n",
      "train: step 2271000, cost: 7.315060615539551, perplexity: 1502.762939453125\n",
      "train: step 2272000, cost: 8.01744556427002, perplexity: 3033.418701171875\n",
      "train: step 2273000, cost: 9.92350959777832, perplexity: 20404.4765625\n",
      "train: step 2274000, cost: 8.978240966796875, perplexity: 7928.6728515625\n",
      "train: step 2275000, cost: 8.87632942199707, perplexity: 7160.458984375\n",
      "train: step 2276000, cost: 7.349751949310303, perplexity: 1555.810546875\n",
      "train: step 2277000, cost: 8.275456428527832, perplexity: 3926.314208984375\n",
      "train: step 2278000, cost: 10.08707046508789, perplexity: 24030.29296875\n",
      "train: step 2279000, cost: 9.008378028869629, perplexity: 8171.25634765625\n",
      "train: step 2280000, cost: 7.7177958488464355, perplexity: 2247.999267578125\n",
      "train: step 2281000, cost: 9.489465713500977, perplexity: 13219.73046875\n",
      "train: step 2282000, cost: 8.441948890686035, perplexity: 4637.583984375\n",
      "train: step 2283000, cost: 9.23543643951416, perplexity: 10254.13671875\n",
      "train: step 2284000, cost: 8.063273429870605, perplexity: 3175.66845703125\n",
      "train: step 2285000, cost: 7.961767673492432, perplexity: 2869.140380859375\n",
      "train: step 2286000, cost: 10.68061351776123, perplexity: 43504.23046875\n",
      "train: step 2287000, cost: 8.808592796325684, perplexity: 6691.49609375\n",
      "train: step 2288000, cost: 10.680222511291504, perplexity: 43487.22265625\n",
      "train: step 2289000, cost: 8.261198043823242, perplexity: 3870.728515625\n",
      "train: step 2290000, cost: 7.131444931030273, perplexity: 1250.682861328125\n",
      "train: step 2291000, cost: 9.132417678833008, perplexity: 9250.359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 2292000, cost: 8.423552513122559, perplexity: 4553.04931640625\n",
      "train: step 2293000, cost: 7.189297199249268, perplexity: 1325.171630859375\n",
      "train: step 2294000, cost: 8.161578178405762, perplexity: 3503.711669921875\n",
      "train: step 2295000, cost: 9.60157299041748, perplexity: 14788.0244140625\n",
      "train: step 2296000, cost: 8.506857872009277, perplexity: 4948.58935546875\n",
      "train: step 2297000, cost: 8.593206405639648, perplexity: 5394.88427734375\n",
      "train: step 2298000, cost: 7.370377540588379, perplexity: 1588.2332763671875\n",
      "train: step 2299000, cost: 8.721024513244629, perplexity: 6130.45654296875\n",
      "train: step 2300000, cost: 7.764950275421143, perplexity: 2356.541259765625\n",
      "train: step 2301000, cost: 10.699227333068848, perplexity: 44321.59375\n",
      "train: step 2302000, cost: 8.93954849243164, perplexity: 7627.751953125\n",
      "train: step 2303000, cost: 10.105734825134277, perplexity: 24483.013671875\n",
      "train: step 2304000, cost: 8.296085357666016, perplexity: 4008.151123046875\n",
      "train: step 2305000, cost: 10.342507362365723, perplexity: 31023.71875\n",
      "train: step 2306000, cost: 9.83010196685791, perplexity: 18584.849609375\n",
      "train: step 2307000, cost: 9.63907527923584, perplexity: 15353.1396484375\n",
      "train: step 2308000, cost: 8.66668701171875, perplexity: 5806.2314453125\n",
      "train: step 2309000, cost: 8.984675407409668, perplexity: 7979.853515625\n",
      "train: step 2310000, cost: 8.887600898742676, perplexity: 7241.62451171875\n",
      "train: step 2311000, cost: 8.128993034362793, perplexity: 3391.3828125\n",
      "train: step 2312000, cost: 7.185969829559326, perplexity: 1320.7696533203125\n",
      "train: step 2313000, cost: 8.512950897216797, perplexity: 4978.83349609375\n",
      "train: step 2314000, cost: 7.178586959838867, perplexity: 1311.0543212890625\n",
      "Model saved in path: /tmp/p2_run02_15.ckpt\n",
      "validation: epoch 15, cost: 8.183331489562988, perplexity: 3580.76416015625\n",
      "test: epoch 15, cost: 9.11213207244873, perplexity: [19173.516, 17592.662, 17449.03, 11225.486, 21339.318, 24617.826, 22408.908, 66997.37, 14599.063, 22131.621, 45416.027, 64620.516, 16979.926, 27348.324, 9064.601]\n",
      "train: step 2315000, cost: 8.238962173461914, perplexity: 3785.609130859375\n",
      "train: step 2316000, cost: 8.944073677062988, perplexity: 7662.34716796875\n",
      "train: step 2317000, cost: 8.815673828125, perplexity: 6739.046875\n",
      "train: step 2318000, cost: 8.417367935180664, perplexity: 4524.9775390625\n",
      "train: step 2319000, cost: 9.998087882995605, perplexity: 21984.388671875\n",
      "train: step 2320000, cost: 9.561651229858398, perplexity: 14209.2890625\n",
      "train: step 2321000, cost: 9.579986572265625, perplexity: 14472.224609375\n",
      "train: step 2322000, cost: 7.284036159515381, perplexity: 1456.8563232421875\n",
      "train: step 2323000, cost: 7.1086201667785645, perplexity: 1222.4595947265625\n",
      "train: step 2324000, cost: 8.8419189453125, perplexity: 6918.25537109375\n",
      "train: step 2325000, cost: 11.245349884033203, perplexity: 76523.2421875\n",
      "train: step 2326000, cost: 8.656922340393066, perplexity: 5749.8115234375\n",
      "train: step 2327000, cost: 8.950055122375488, perplexity: 7708.31689453125\n",
      "train: step 2328000, cost: 7.172852993011475, perplexity: 1303.558349609375\n",
      "train: step 2329000, cost: 8.205517768859863, perplexity: 3661.095703125\n",
      "train: step 2330000, cost: 8.125565528869629, perplexity: 3379.778564453125\n",
      "train: step 2331000, cost: 9.153338432312012, perplexity: 9445.9228515625\n",
      "train: step 2332000, cost: 9.311264991760254, perplexity: 11061.9326171875\n",
      "train: step 2333000, cost: 12.900823593139648, perplexity: 400642.03125\n",
      "train: step 2334000, cost: 8.63241958618164, perplexity: 5610.63720703125\n",
      "train: step 2335000, cost: 7.13257360458374, perplexity: 1252.09521484375\n",
      "train: step 2336000, cost: 7.35517692565918, perplexity: 1564.273681640625\n",
      "train: step 2337000, cost: 8.401622772216797, perplexity: 4454.2890625\n",
      "train: step 2338000, cost: 8.666274070739746, perplexity: 5803.833984375\n",
      "train: step 2339000, cost: 9.642228126525879, perplexity: 15401.6220703125\n",
      "train: step 2340000, cost: 8.563642501831055, perplexity: 5237.72509765625\n",
      "train: step 2341000, cost: 9.22594165802002, perplexity: 10157.236328125\n",
      "train: step 2342000, cost: 8.368165016174316, perplexity: 4307.72412109375\n",
      "train: step 2343000, cost: 7.4244794845581055, perplexity: 1676.5267333984375\n",
      "train: step 2344000, cost: 10.394539833068848, perplexity: 32680.6953125\n",
      "train: step 2345000, cost: 7.549353122711182, perplexity: 1899.5135498046875\n",
      "train: step 2346000, cost: 15.04595947265625, perplexity: 3422765.75\n",
      "train: step 2347000, cost: 10.147320747375488, perplexity: 25522.62890625\n",
      "train: step 2348000, cost: 8.34051513671875, perplexity: 4190.24755859375\n",
      "train: step 2349000, cost: 7.745919227600098, perplexity: 2312.117919921875\n",
      "train: step 2350000, cost: 8.231057167053223, perplexity: 3755.8017578125\n",
      "train: step 2351000, cost: 8.683837890625, perplexity: 5906.67236328125\n",
      "train: step 2352000, cost: 9.649788856506348, perplexity: 15518.5107421875\n",
      "train: step 2353000, cost: 8.090123176574707, perplexity: 3262.08935546875\n",
      "train: step 2354000, cost: 8.575699806213379, perplexity: 5301.26025390625\n",
      "train: step 2355000, cost: 9.263129234313965, perplexity: 10542.0712890625\n",
      "train: step 2356000, cost: 7.941812992095947, perplexity: 2812.454833984375\n",
      "train: step 2357000, cost: 10.159528732299805, perplexity: 25836.1171875\n",
      "train: step 2358000, cost: 7.156927108764648, perplexity: 1282.96240234375\n",
      "train: step 2359000, cost: 8.553512573242188, perplexity: 5184.93505859375\n",
      "train: step 2360000, cost: 9.285791397094727, perplexity: 10783.705078125\n",
      "train: step 2361000, cost: 8.427474975585938, perplexity: 4570.94384765625\n",
      "train: step 2362000, cost: 7.9896745681762695, perplexity: 2950.3369140625\n",
      "train: step 2363000, cost: 9.139107704162598, perplexity: 9312.4521484375\n",
      "train: step 2364000, cost: 9.203332901000977, perplexity: 9930.169921875\n",
      "train: step 2365000, cost: 9.306611061096191, perplexity: 11010.5703125\n",
      "train: step 2366000, cost: 7.6417670249938965, perplexity: 2083.422119140625\n",
      "train: step 2367000, cost: 7.370048522949219, perplexity: 1587.7108154296875\n",
      "train: step 2368000, cost: 9.016642570495605, perplexity: 8239.0693359375\n",
      "train: step 2369000, cost: 7.878357887268066, perplexity: 2639.53466796875\n",
      "train: step 2370000, cost: 11.478463172912598, perplexity: 96612.4765625\n",
      "train: step 2371000, cost: 9.281628608703613, perplexity: 10738.9072265625\n",
      "train: step 2372000, cost: 9.478006362915039, perplexity: 13069.10546875\n",
      "train: step 2373000, cost: 8.393616676330566, perplexity: 4418.77001953125\n",
      "train: step 2374000, cost: 12.160626411437988, perplexity: 191114.203125\n",
      "train: step 2375000, cost: 13.067179679870605, perplexity: 473155.65625\n",
      "train: step 2376000, cost: 11.810359954833984, perplexity: 134640.015625\n",
      "train: step 2377000, cost: 8.681066513061523, perplexity: 5890.32568359375\n",
      "train: step 2378000, cost: 9.241357803344727, perplexity: 10315.0341796875\n",
      "train: step 2379000, cost: 9.92271900177002, perplexity: 20388.3515625\n",
      "train: step 2380000, cost: 8.738354682922363, perplexity: 6237.6240234375\n",
      "train: step 2381000, cost: 9.360726356506348, perplexity: 11622.828125\n",
      "train: step 2382000, cost: 7.719683647155762, perplexity: 2252.246826171875\n",
      "train: step 2383000, cost: 9.868130683898926, perplexity: 19305.21875\n",
      "train: step 2384000, cost: 7.482843399047852, perplexity: 1777.287109375\n",
      "train: step 2385000, cost: 6.611307144165039, perplexity: 743.4542236328125\n",
      "train: step 2386000, cost: 8.478076934814453, perplexity: 4808.1943359375\n",
      "train: step 2387000, cost: 8.772951126098633, perplexity: 6457.20068359375\n",
      "train: step 2388000, cost: 7.770410060882568, perplexity: 2369.44287109375\n",
      "train: step 2389000, cost: 9.461421966552734, perplexity: 12854.150390625\n",
      "train: step 2390000, cost: 7.028360843658447, perplexity: 1128.1798095703125\n",
      "train: step 2391000, cost: 9.045760154724121, perplexity: 8482.4970703125\n",
      "train: step 2392000, cost: 7.9410223960876465, perplexity: 2810.232177734375\n",
      "train: step 2393000, cost: 6.8445940017700195, perplexity: 938.7920532226562\n",
      "train: step 2394000, cost: 6.7178239822387695, perplexity: 827.0159301757812\n",
      "train: step 2395000, cost: 10.743264198303223, perplexity: 46316.99609375\n",
      "train: step 2396000, cost: 10.383489608764648, perplexity: 32321.552734375\n",
      "train: step 2397000, cost: 6.505959987640381, perplexity: 669.11767578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 2398000, cost: 11.172816276550293, perplexity: 71169.265625\n",
      "train: step 2399000, cost: 9.919569969177246, perplexity: 20324.25\n",
      "train: step 2400000, cost: 7.31467342376709, perplexity: 1502.1812744140625\n",
      "train: step 2401000, cost: 8.370774269104004, perplexity: 4318.97900390625\n",
      "train: step 2402000, cost: 8.712007522583008, perplexity: 6075.4267578125\n",
      "train: step 2403000, cost: 9.25961685180664, perplexity: 10505.107421875\n",
      "train: step 2404000, cost: 8.081275939941406, perplexity: 3233.356201171875\n",
      "train: step 2405000, cost: 8.559816360473633, perplexity: 5217.72265625\n",
      "train: step 2406000, cost: 7.60544490814209, perplexity: 2009.10546875\n",
      "train: step 2407000, cost: 9.076019287109375, perplexity: 8743.0927734375\n",
      "train: step 2408000, cost: 6.890635013580322, perplexity: 983.025390625\n",
      "train: step 2409000, cost: 10.521198272705078, perplexity: 37093.546875\n",
      "train: step 2410000, cost: 8.5380859375, perplexity: 5105.5625\n",
      "train: step 2411000, cost: 8.647451400756836, perplexity: 5695.61181640625\n",
      "train: step 2412000, cost: 15.96912670135498, perplexity: 8615959.0\n",
      "train: step 2413000, cost: 8.282571792602539, perplexity: 3954.35107421875\n",
      "train: step 2414000, cost: 9.918417930603027, perplexity: 20300.84765625\n",
      "train: step 2415000, cost: 7.692069053649902, perplexity: 2190.90283203125\n",
      "train: step 2416000, cost: 10.34207534790039, perplexity: 31010.318359375\n",
      "train: step 2417000, cost: 7.413175106048584, perplexity: 1657.681396484375\n",
      "train: step 2418000, cost: 13.34469985961914, perplexity: 624495.75\n",
      "train: step 2419000, cost: 7.064419746398926, perplexity: 1169.60302734375\n",
      "train: step 2420000, cost: 9.448806762695312, perplexity: 12693.0107421875\n",
      "train: step 2421000, cost: 10.70749568939209, perplexity: 44689.58203125\n",
      "train: step 2422000, cost: 8.897588729858398, perplexity: 7314.3154296875\n",
      "train: step 2423000, cost: 8.153441429138184, perplexity: 3475.318603515625\n",
      "train: step 2424000, cost: 8.790268898010254, perplexity: 6569.9990234375\n",
      "train: step 2425000, cost: 10.438116073608398, perplexity: 34136.28125\n",
      "train: step 2426000, cost: 6.828940391540527, perplexity: 924.2109375\n",
      "train: step 2427000, cost: 8.084748268127441, perplexity: 3244.60302734375\n",
      "train: step 2428000, cost: 12.784713745117188, perplexity: 356722.625\n",
      "train: step 2429000, cost: 7.843576908111572, perplexity: 2549.30712890625\n",
      "train: step 2430000, cost: 6.925630569458008, perplexity: 1018.0360107421875\n",
      "train: step 2431000, cost: 7.856639385223389, perplexity: 2582.825927734375\n",
      "train: step 2432000, cost: 11.393377304077148, perplexity: 88732.125\n",
      "train: step 2433000, cost: 7.73520565032959, perplexity: 2287.47900390625\n",
      "train: step 2434000, cost: 8.578751564025879, perplexity: 5317.462890625\n",
      "train: step 2435000, cost: 7.815638065338135, perplexity: 2479.068115234375\n",
      "train: step 2436000, cost: 7.28076171875, perplexity: 1452.0936279296875\n",
      "train: step 2437000, cost: 9.823494911193848, perplexity: 18462.462890625\n",
      "train: step 2438000, cost: 7.988250255584717, perplexity: 2946.137451171875\n",
      "train: step 2439000, cost: 7.479755878448486, perplexity: 1771.8082275390625\n",
      "train: step 2440000, cost: 6.828322410583496, perplexity: 923.6400146484375\n",
      "train: step 2441000, cost: 6.662596225738525, perplexity: 782.580078125\n",
      "train: step 2442000, cost: 9.950250625610352, perplexity: 20957.474609375\n",
      "train: step 2443000, cost: 6.979722023010254, perplexity: 1074.6195068359375\n",
      "train: step 2444000, cost: 8.65837287902832, perplexity: 5758.15771484375\n",
      "train: step 2445000, cost: 8.242890357971191, perplexity: 3800.509033203125\n",
      "train: step 2446000, cost: 7.333450794219971, perplexity: 1530.6546630859375\n",
      "train: step 2447000, cost: 8.256705284118652, perplexity: 3853.377197265625\n",
      "train: step 2448000, cost: 8.178413391113281, perplexity: 3563.19677734375\n",
      "train: step 2449000, cost: 9.54562759399414, perplexity: 13983.4189453125\n",
      "train: step 2450000, cost: 9.743983268737793, perplexity: 17051.326171875\n",
      "train: step 2451000, cost: 7.575103282928467, perplexity: 1949.0614013671875\n",
      "train: step 2452000, cost: 7.245358467102051, perplexity: 1401.584228515625\n",
      "train: step 2453000, cost: 8.369873046875, perplexity: 4315.08837890625\n",
      "train: step 2454000, cost: 9.652159690856934, perplexity: 15555.345703125\n",
      "train: step 2455000, cost: 9.061616897583008, perplexity: 8618.07421875\n",
      "train: step 2456000, cost: 10.09571361541748, perplexity: 24238.888671875\n",
      "train: step 2457000, cost: 9.633927345275879, perplexity: 15274.3046875\n",
      "train: step 2458000, cost: 8.663411140441895, perplexity: 5787.2421875\n",
      "train: step 2459000, cost: 12.369988441467285, perplexity: 235623.015625\n",
      "train: step 2460000, cost: 8.87900161743164, perplexity: 7179.619140625\n",
      "train: step 2461000, cost: 7.179238319396973, perplexity: 1311.9085693359375\n",
      "train: step 2462000, cost: 10.074750900268555, perplexity: 23736.064453125\n",
      "train: step 2463000, cost: 8.49057388305664, perplexity: 4868.65966796875\n",
      "train: step 2464000, cost: 8.675872802734375, perplexity: 5859.81201171875\n",
      "train: step 2465000, cost: 9.8131103515625, perplexity: 18271.73046875\n",
      "train: step 2466000, cost: 8.346744537353516, perplexity: 4216.43212890625\n",
      "train: step 2467000, cost: 7.4717230796813965, perplexity: 1757.632568359375\n",
      "train: step 2468000, cost: 7.261026382446289, perplexity: 1423.717041015625\n",
      "Model saved in path: /tmp/p2_run02_16.ckpt\n",
      "validation: epoch 16, cost: 8.638541221618652, perplexity: 5645.08935546875\n",
      "test: epoch 16, cost: 9.232584953308105, perplexity: [19173.516, 17592.662, 17449.03, 11225.486, 21339.318, 24617.826, 22408.908, 66997.37, 14599.063, 22131.621, 45416.027, 64620.516, 16979.926, 27348.324, 9064.601, 10224.9375]\n",
      "train: step 2469000, cost: 9.55681324005127, perplexity: 14140.7109375\n",
      "train: step 2470000, cost: 8.682177543640137, perplexity: 5896.87353515625\n",
      "train: step 2471000, cost: 8.75094985961914, perplexity: 6316.68505859375\n",
      "train: step 2472000, cost: 7.8347954750061035, perplexity: 2527.0185546875\n",
      "train: step 2473000, cost: 7.870682239532471, perplexity: 2619.35205078125\n",
      "train: step 2474000, cost: 7.456647872924805, perplexity: 1731.3345947265625\n",
      "train: step 2475000, cost: 8.237136840820312, perplexity: 3778.70556640625\n",
      "train: step 2476000, cost: 7.323918342590332, perplexity: 1516.1331787109375\n",
      "train: step 2477000, cost: 11.018193244934082, perplexity: 60973.41015625\n",
      "train: step 2478000, cost: 7.43501091003418, perplexity: 1694.2762451171875\n",
      "train: step 2479000, cost: 7.075803756713867, perplexity: 1182.9940185546875\n",
      "train: step 2480000, cost: 7.447363376617432, perplexity: 1715.33447265625\n",
      "train: step 2481000, cost: 10.349278450012207, perplexity: 31234.498046875\n",
      "train: step 2482000, cost: 8.902639389038086, perplexity: 7351.35107421875\n",
      "train: step 2483000, cost: 8.43453311920166, perplexity: 4603.3203125\n",
      "train: step 2484000, cost: 9.566971778869629, perplexity: 14285.091796875\n",
      "train: step 2485000, cost: 7.76841926574707, perplexity: 2364.73046875\n",
      "train: step 2486000, cost: 10.501766204833984, perplexity: 36379.69921875\n",
      "train: step 2487000, cost: 8.546439170837402, perplexity: 5148.38916015625\n",
      "train: step 2488000, cost: 8.857922554016113, perplexity: 7029.86328125\n",
      "train: step 2489000, cost: 9.179597854614258, perplexity: 9697.2529296875\n",
      "train: step 2490000, cost: 9.486475944519043, perplexity: 13180.265625\n",
      "train: step 2491000, cost: 8.636881828308105, perplexity: 5635.72900390625\n",
      "train: step 2492000, cost: 7.0470075607299805, perplexity: 1149.4140625\n",
      "train: step 2493000, cost: 8.18075942993164, perplexity: 3571.56591796875\n",
      "train: step 2494000, cost: 10.954706192016602, perplexity: 57222.7109375\n",
      "train: step 2495000, cost: 7.684832572937012, perplexity: 2175.10595703125\n",
      "train: step 2496000, cost: 13.71134090423584, perplexity: 901072.4375\n",
      "train: step 2497000, cost: 8.576315879821777, perplexity: 5304.52734375\n",
      "train: step 2498000, cost: 8.67248821258545, perplexity: 5840.0126953125\n",
      "train: step 2499000, cost: 10.972947120666504, perplexity: 58276.08984375\n",
      "train: step 2500000, cost: 6.621467113494873, perplexity: 751.0462036132812\n",
      "train: step 2501000, cost: 10.50115966796875, perplexity: 36357.640625\n",
      "train: step 2502000, cost: 7.959741115570068, perplexity: 2863.33154296875\n",
      "train: step 2503000, cost: 8.574206352233887, perplexity: 5293.34912109375\n",
      "train: step 2504000, cost: 8.353543281555176, perplexity: 4245.19580078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 2505000, cost: 11.396662712097168, perplexity: 89024.125\n",
      "train: step 2506000, cost: 7.355836391448975, perplexity: 1565.3056640625\n",
      "train: step 2507000, cost: 7.738943099975586, perplexity: 2296.04443359375\n",
      "train: step 2508000, cost: 8.002766609191895, perplexity: 2989.216552734375\n",
      "train: step 2509000, cost: 8.285907745361328, perplexity: 3967.564453125\n",
      "train: step 2510000, cost: 8.98199462890625, perplexity: 7958.490234375\n",
      "train: step 2511000, cost: 7.700177192687988, perplexity: 2208.7392578125\n",
      "train: step 2512000, cost: 11.46164321899414, perplexity: 95001.046875\n",
      "train: step 2513000, cost: 8.683560371398926, perplexity: 5905.03369140625\n",
      "train: step 2514000, cost: 8.80453109741211, perplexity: 6664.373046875\n",
      "train: step 2515000, cost: 10.998446464538574, perplexity: 59781.1953125\n",
      "train: step 2516000, cost: 8.24028491973877, perplexity: 3790.6201171875\n",
      "train: step 2517000, cost: 6.971434116363525, perplexity: 1065.7501220703125\n",
      "train: step 2518000, cost: 7.974997520446777, perplexity: 2907.3505859375\n",
      "train: step 2519000, cost: 9.176721572875977, perplexity: 9669.400390625\n",
      "train: step 2520000, cost: 12.07046890258789, perplexity: 174637.703125\n",
      "train: step 2521000, cost: 10.051323890686035, perplexity: 23186.4609375\n",
      "train: step 2522000, cost: 7.8805766105651855, perplexity: 2645.397705078125\n",
      "train: step 2523000, cost: 7.939988136291504, perplexity: 2807.3271484375\n",
      "train: step 2524000, cost: 9.53132152557373, perplexity: 13784.7958984375\n",
      "train: step 2525000, cost: 10.95501708984375, perplexity: 57240.5078125\n",
      "train: step 2526000, cost: 8.511795043945312, perplexity: 4973.08203125\n",
      "train: step 2527000, cost: 9.293498039245605, perplexity: 10867.130859375\n",
      "train: step 2528000, cost: 10.815497398376465, perplexity: 49786.4140625\n",
      "train: step 2529000, cost: 7.724865436553955, perplexity: 2263.94775390625\n",
      "train: step 2530000, cost: 8.800235748291016, perplexity: 6635.80859375\n",
      "train: step 2531000, cost: 7.812963485717773, perplexity: 2472.446533203125\n",
      "train: step 2532000, cost: 7.58556604385376, perplexity: 1969.5611572265625\n",
      "train: step 2533000, cost: 9.943427085876465, perplexity: 20814.955078125\n",
      "train: step 2534000, cost: 10.48965072631836, perplexity: 35941.6015625\n",
      "train: step 2535000, cost: 7.423462867736816, perplexity: 1674.8232421875\n",
      "train: step 2536000, cost: 7.640185356140137, perplexity: 2080.12939453125\n",
      "train: step 2537000, cost: 9.659958839416504, perplexity: 15677.1396484375\n",
      "train: step 2538000, cost: 8.605586051940918, perplexity: 5462.0859375\n",
      "train: step 2539000, cost: 8.147629737854004, perplexity: 3455.1796875\n",
      "train: step 2540000, cost: 7.787214756011963, perplexity: 2409.59716796875\n",
      "train: step 2541000, cost: 9.019095420837402, perplexity: 8259.302734375\n",
      "train: step 2542000, cost: 8.419255256652832, perplexity: 4533.52587890625\n",
      "train: step 2543000, cost: 8.346983909606934, perplexity: 4217.44140625\n",
      "train: step 2544000, cost: 8.073467254638672, perplexity: 3208.206298828125\n",
      "train: step 2545000, cost: 8.185359001159668, perplexity: 3588.031494140625\n",
      "train: step 2546000, cost: 8.525266647338867, perplexity: 5040.53076171875\n",
      "train: step 2547000, cost: 8.422308921813965, perplexity: 4547.390625\n",
      "train: step 2548000, cost: 8.924208641052246, perplexity: 7511.6357421875\n",
      "train: step 2549000, cost: 7.127051830291748, perplexity: 1245.200439453125\n",
      "train: step 2550000, cost: 9.833276748657227, perplexity: 18643.947265625\n",
      "train: step 2551000, cost: 10.201605796813965, perplexity: 26946.423828125\n",
      "train: step 2552000, cost: 7.330888748168945, perplexity: 1526.7381591796875\n",
      "train: step 2553000, cost: 10.162983894348145, perplexity: 25925.54296875\n",
      "train: step 2554000, cost: 12.623470306396484, perplexity: 303601.21875\n",
      "train: step 2555000, cost: 8.304315567016602, perplexity: 4041.27490234375\n",
      "train: step 2556000, cost: 9.504464149475098, perplexity: 13419.5\n",
      "train: step 2557000, cost: 8.572610855102539, perplexity: 5284.91015625\n",
      "train: step 2558000, cost: 9.984000205993652, perplexity: 21676.8515625\n",
      "train: step 2559000, cost: 9.0867919921875, perplexity: 8837.7890625\n",
      "train: step 2560000, cost: 6.634776592254639, perplexity: 761.1090087890625\n",
      "train: step 2561000, cost: 9.7821044921875, perplexity: 17713.892578125\n",
      "train: step 2562000, cost: 7.529085636138916, perplexity: 1861.402587890625\n",
      "train: step 2563000, cost: 10.073217391967773, perplexity: 23699.693359375\n",
      "train: step 2564000, cost: 9.670870780944824, perplexity: 15849.1435546875\n",
      "train: step 2565000, cost: 8.357575416564941, perplexity: 4262.34765625\n",
      "train: step 2566000, cost: 9.72017765045166, perplexity: 16650.201171875\n",
      "train: step 2567000, cost: 6.685849666595459, perplexity: 800.990966796875\n",
      "train: step 2568000, cost: 8.685595512390137, perplexity: 5917.06298828125\n",
      "train: step 2569000, cost: 9.645946502685547, perplexity: 15458.998046875\n",
      "train: step 2570000, cost: 7.097137451171875, perplexity: 1208.502685546875\n",
      "train: step 2571000, cost: 8.360437393188477, perplexity: 4274.56396484375\n",
      "train: step 2572000, cost: 8.442535400390625, perplexity: 4640.30517578125\n",
      "train: step 2573000, cost: 7.096426486968994, perplexity: 1207.6439208984375\n",
      "train: step 2574000, cost: 8.12028980255127, perplexity: 3361.9951171875\n",
      "train: step 2575000, cost: 10.146828651428223, perplexity: 25510.07421875\n",
      "train: step 2576000, cost: 8.080999374389648, perplexity: 3232.462158203125\n",
      "train: step 2577000, cost: 7.882504463195801, perplexity: 2650.50244140625\n",
      "train: step 2578000, cost: 8.111132621765137, perplexity: 3331.34912109375\n",
      "train: step 2579000, cost: 8.998827934265137, perplexity: 8093.591796875\n",
      "train: step 2580000, cost: 7.8397979736328125, perplexity: 2539.691650390625\n",
      "train: step 2581000, cost: 9.28986930847168, perplexity: 10827.7685546875\n",
      "train: step 2582000, cost: 9.557414054870605, perplexity: 14149.2099609375\n",
      "train: step 2583000, cost: 11.25497055053711, perplexity: 77263.0078125\n",
      "train: step 2584000, cost: 7.126335620880127, perplexity: 1244.3089599609375\n",
      "train: step 2585000, cost: 8.201318740844727, perplexity: 3645.7548828125\n",
      "train: step 2586000, cost: 9.973977088928223, perplexity: 21460.66796875\n",
      "train: step 2587000, cost: 8.543170928955078, perplexity: 5131.5908203125\n",
      "train: step 2588000, cost: 7.766254901885986, perplexity: 2359.61767578125\n",
      "train: step 2589000, cost: 7.2358717918396, perplexity: 1388.3507080078125\n",
      "train: step 2590000, cost: 9.16791820526123, perplexity: 9584.650390625\n",
      "train: step 2591000, cost: 7.613798141479492, perplexity: 2025.958251953125\n",
      "train: step 2592000, cost: 8.073747634887695, perplexity: 3209.105712890625\n",
      "train: step 2593000, cost: 9.889552116394043, perplexity: 19723.224609375\n",
      "train: step 2594000, cost: 9.78261947631836, perplexity: 17723.017578125\n",
      "train: step 2595000, cost: 8.45065975189209, perplexity: 4678.158203125\n",
      "train: step 2596000, cost: 10.274917602539062, perplexity: 28996.12890625\n",
      "train: step 2597000, cost: 8.417704582214355, perplexity: 4526.50146484375\n",
      "train: step 2598000, cost: 8.177393913269043, perplexity: 3559.566162109375\n",
      "train: step 2599000, cost: 8.778749465942383, perplexity: 6494.75\n",
      "train: step 2600000, cost: 6.799302101135254, perplexity: 897.2208862304688\n",
      "train: step 2601000, cost: 7.880820274353027, perplexity: 2646.042236328125\n",
      "train: step 2602000, cost: 9.0232572555542, perplexity: 8293.748046875\n",
      "train: step 2603000, cost: 9.103875160217285, perplexity: 8990.0625\n",
      "train: step 2604000, cost: 8.003107070922852, perplexity: 2990.234375\n",
      "train: step 2605000, cost: 8.1290864944458, perplexity: 3391.699951171875\n",
      "train: step 2606000, cost: 10.043103218078613, perplexity: 22996.634765625\n",
      "train: step 2607000, cost: 10.84588623046875, perplexity: 51322.5859375\n",
      "train: step 2608000, cost: 8.124360084533691, perplexity: 3375.70703125\n",
      "train: step 2609000, cost: 8.24975872039795, perplexity: 3826.7021484375\n",
      "train: step 2610000, cost: 7.418528079986572, perplexity: 1666.5787353515625\n",
      "train: step 2611000, cost: 12.366829872131348, perplexity: 234879.984375\n",
      "train: step 2612000, cost: 9.820436477661133, perplexity: 18406.083984375\n",
      "train: step 2613000, cost: 7.465073585510254, perplexity: 1745.9840087890625\n",
      "train: step 2614000, cost: 8.943684577941895, perplexity: 7659.3662109375\n",
      "train: step 2615000, cost: 9.60942268371582, perplexity: 14904.5625\n",
      "train: step 2616000, cost: 10.038904190063477, perplexity: 22900.275390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 2617000, cost: 7.769913673400879, perplexity: 2368.266845703125\n",
      "train: step 2618000, cost: 9.075132369995117, perplexity: 8735.341796875\n",
      "train: step 2619000, cost: 12.180275917053223, perplexity: 194906.625\n",
      "train: step 2620000, cost: 8.492648124694824, perplexity: 4878.7685546875\n",
      "train: step 2621000, cost: 13.250543594360352, perplexity: 568378.9375\n",
      "train: step 2622000, cost: 8.938643455505371, perplexity: 7620.8515625\n",
      "Model saved in path: /tmp/p2_run02_17.ckpt\n",
      "validation: epoch 17, cost: 8.481911659240723, perplexity: 4826.66796875\n",
      "test: epoch 17, cost: 8.686893463134766, perplexity: [19173.516, 17592.662, 17449.03, 11225.486, 21339.318, 24617.826, 22408.908, 66997.37, 14599.063, 22131.621, 45416.027, 64620.516, 16979.926, 27348.324, 9064.601, 10224.9375, 5924.748]\n",
      "train: step 2623000, cost: 7.589444637298584, perplexity: 1977.215087890625\n",
      "train: step 2624000, cost: 7.176100730895996, perplexity: 1307.798828125\n",
      "train: step 2625000, cost: 8.97564697265625, perplexity: 7908.1328125\n",
      "train: step 2626000, cost: 9.854703903198242, perplexity: 19047.7421875\n",
      "train: step 2627000, cost: 9.12987232208252, perplexity: 9226.84375\n",
      "train: step 2628000, cost: 8.98978328704834, perplexity: 8020.71826171875\n",
      "train: step 2629000, cost: 7.703690528869629, perplexity: 2216.512939453125\n",
      "train: step 2630000, cost: 10.863200187683105, perplexity: 52218.921875\n",
      "train: step 2631000, cost: 7.577293395996094, perplexity: 1953.3349609375\n",
      "train: step 2632000, cost: 8.64449691772461, perplexity: 5678.8095703125\n",
      "train: step 2633000, cost: 9.769196510314941, perplexity: 17486.7109375\n",
      "train: step 2634000, cost: 9.321493148803711, perplexity: 11175.65625\n",
      "train: step 2635000, cost: 10.556971549987793, perplexity: 38444.5234375\n",
      "train: step 2636000, cost: 8.884286880493164, perplexity: 7217.66552734375\n",
      "train: step 2637000, cost: 8.738462448120117, perplexity: 6238.296875\n",
      "train: step 2638000, cost: 9.825960159301758, perplexity: 18508.033203125\n",
      "train: step 2639000, cost: 9.144640922546387, perplexity: 9364.123046875\n",
      "train: step 2640000, cost: 11.673807144165039, perplexity: 117454.609375\n",
      "train: step 2641000, cost: 9.081968307495117, perplexity: 8795.2607421875\n",
      "train: step 2642000, cost: 8.645655632019043, perplexity: 5685.3935546875\n",
      "train: step 2643000, cost: 7.743194580078125, perplexity: 2305.82666015625\n",
      "train: step 2644000, cost: 7.831786155700684, perplexity: 2519.425537109375\n",
      "train: step 2645000, cost: 9.74152660369873, perplexity: 17009.48828125\n",
      "train: step 2646000, cost: 8.134906768798828, perplexity: 3411.497802734375\n",
      "train: step 2647000, cost: 7.981980800628662, perplexity: 2927.724609375\n",
      "train: step 2648000, cost: 6.957489490509033, perplexity: 1050.99169921875\n",
      "train: step 2649000, cost: 7.326963901519775, perplexity: 1520.7576904296875\n",
      "train: step 2650000, cost: 8.28829574584961, perplexity: 3977.05029296875\n",
      "train: step 2651000, cost: 6.899892330169678, perplexity: 992.1678466796875\n",
      "train: step 2652000, cost: 7.752815246582031, perplexity: 2328.117431640625\n",
      "train: step 2653000, cost: 8.657571792602539, perplexity: 5753.546875\n",
      "train: step 2654000, cost: 8.407649040222168, perplexity: 4481.212890625\n",
      "train: step 2655000, cost: 8.874982833862305, perplexity: 7150.82373046875\n",
      "train: step 2656000, cost: 7.781256198883057, perplexity: 2395.28173828125\n",
      "train: step 2657000, cost: 7.612968444824219, perplexity: 2024.278076171875\n",
      "train: step 2658000, cost: 13.075929641723633, perplexity: 477313.9375\n",
      "train: step 2659000, cost: 8.862272262573242, perplexity: 7060.5078125\n",
      "train: step 2660000, cost: 14.73349380493164, perplexity: 2504234.75\n",
      "train: step 2661000, cost: 8.021875381469727, perplexity: 3046.885986328125\n",
      "train: step 2662000, cost: 8.25278377532959, perplexity: 3838.295654296875\n",
      "train: step 2663000, cost: 8.879120826721191, perplexity: 7180.47509765625\n",
      "train: step 2664000, cost: 7.513438701629639, perplexity: 1832.504150390625\n",
      "train: step 2665000, cost: 6.550755977630615, perplexity: 699.77294921875\n",
      "train: step 2666000, cost: 6.5063862800598145, perplexity: 669.4030151367188\n",
      "train: step 2667000, cost: 8.760286331176758, perplexity: 6375.9375\n",
      "train: step 2668000, cost: 10.470908164978027, perplexity: 35274.23828125\n",
      "train: step 2669000, cost: 8.045247077941895, perplexity: 3118.935546875\n",
      "train: step 2670000, cost: 7.855275630950928, perplexity: 2579.305908203125\n",
      "train: step 2671000, cost: 9.329374313354492, perplexity: 11264.0810546875\n",
      "train: step 2672000, cost: 7.825827121734619, perplexity: 2504.456787109375\n",
      "train: step 2673000, cost: 7.37891960144043, perplexity: 1601.858154296875\n",
      "train: step 2674000, cost: 10.435439109802246, perplexity: 34045.0234375\n",
      "train: step 2675000, cost: 8.223191261291504, perplexity: 3726.375244140625\n",
      "train: step 2676000, cost: 9.706772804260254, perplexity: 16428.498046875\n",
      "train: step 2677000, cost: 6.320216655731201, perplexity: 555.693359375\n",
      "train: step 2678000, cost: 9.954158782958984, perplexity: 21039.541015625\n",
      "train: step 2679000, cost: 9.800564765930176, perplexity: 18043.931640625\n",
      "train: step 2680000, cost: 10.418882369995117, perplexity: 33485.98828125\n",
      "train: step 2681000, cost: 9.181406021118164, perplexity: 9714.802734375\n",
      "train: step 2682000, cost: 8.31729507446289, perplexity: 4094.07080078125\n",
      "train: step 2683000, cost: 7.72297477722168, perplexity: 2259.671630859375\n",
      "train: step 2684000, cost: 11.724847793579102, perplexity: 123605.1953125\n",
      "train: step 2685000, cost: 7.199490547180176, perplexity: 1338.74853515625\n",
      "train: step 2686000, cost: 7.326396465301514, perplexity: 1519.8948974609375\n",
      "train: step 2687000, cost: 7.970519065856934, perplexity: 2894.359375\n",
      "train: step 2688000, cost: 9.490464210510254, perplexity: 13232.9375\n",
      "train: step 2689000, cost: 9.474532127380371, perplexity: 13023.779296875\n",
      "train: step 2690000, cost: 8.931422233581543, perplexity: 7566.01806640625\n",
      "train: step 2691000, cost: 9.056402206420898, perplexity: 8573.25\n",
      "train: step 2692000, cost: 11.292405128479004, perplexity: 80210.1328125\n",
      "train: step 2693000, cost: 8.81087875366211, perplexity: 6706.81005859375\n",
      "train: step 2694000, cost: 7.608199119567871, perplexity: 2014.6466064453125\n",
      "train: step 2695000, cost: 8.693649291992188, perplexity: 5964.91064453125\n",
      "train: step 2696000, cost: 6.872156143188477, perplexity: 965.0270385742188\n",
      "train: step 2697000, cost: 11.797650337219238, perplexity: 132939.625\n",
      "train: step 2698000, cost: 7.695464134216309, perplexity: 2198.35400390625\n",
      "train: step 2699000, cost: 6.488020896911621, perplexity: 657.2213745117188\n",
      "train: step 2700000, cost: 9.800994873046875, perplexity: 18051.6953125\n",
      "train: step 2701000, cost: 10.8626070022583, perplexity: 52187.953125\n",
      "train: step 2702000, cost: 11.503432273864746, perplexity: 99055.171875\n",
      "train: step 2703000, cost: 7.961002826690674, perplexity: 2866.946533203125\n",
      "train: step 2704000, cost: 7.588106155395508, perplexity: 1974.5704345703125\n",
      "train: step 2705000, cost: 8.369566917419434, perplexity: 4313.767578125\n",
      "train: step 2706000, cost: 9.830893516540527, perplexity: 18599.564453125\n",
      "train: step 2707000, cost: 10.979618072509766, perplexity: 58666.14453125\n",
      "train: step 2708000, cost: 7.668292045593262, perplexity: 2139.42431640625\n",
      "train: step 2709000, cost: 7.488249778747559, perplexity: 1786.921875\n",
      "train: step 2710000, cost: 6.588376998901367, perplexity: 726.6006469726562\n",
      "train: step 2711000, cost: 11.967940330505371, perplexity: 157619.6875\n",
      "train: step 2712000, cost: 8.616143226623535, perplexity: 5520.0556640625\n",
      "train: step 2713000, cost: 7.8082356452941895, perplexity: 2460.784912109375\n",
      "train: step 2714000, cost: 8.45450496673584, perplexity: 4696.18115234375\n",
      "train: step 2715000, cost: 7.752994060516357, perplexity: 2328.53369140625\n",
      "train: step 2716000, cost: 7.342171669006348, perplexity: 1544.0616455078125\n",
      "train: step 2717000, cost: 6.514055252075195, perplexity: 674.556396484375\n",
      "train: step 2718000, cost: 8.54338550567627, perplexity: 5132.69189453125\n",
      "train: step 2719000, cost: 9.26537799835205, perplexity: 10565.8046875\n",
      "train: step 2720000, cost: 9.810293197631836, perplexity: 18220.328125\n",
      "train: step 2721000, cost: 9.114153861999512, perplexity: 9082.9453125\n",
      "train: step 2722000, cost: 10.768682479858398, perplexity: 47509.3828125\n",
      "train: step 2723000, cost: 9.695935249328613, perplexity: 16251.4150390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 2724000, cost: 8.249105453491211, perplexity: 3824.203125\n",
      "train: step 2725000, cost: 8.903288841247559, perplexity: 7356.126953125\n",
      "train: step 2726000, cost: 7.610358238220215, perplexity: 2019.001220703125\n",
      "train: step 2727000, cost: 7.345581531524658, perplexity: 1549.335693359375\n",
      "train: step 2728000, cost: 8.038165092468262, perplexity: 3096.925537109375\n",
      "train: step 2729000, cost: 7.7507476806640625, perplexity: 2323.308837890625\n",
      "train: step 2730000, cost: 8.422337532043457, perplexity: 4547.52099609375\n",
      "train: step 2731000, cost: 9.05941390991211, perplexity: 8599.109375\n",
      "train: step 2732000, cost: 8.39813232421875, perplexity: 4438.76904296875\n",
      "train: step 2733000, cost: 7.231152534484863, perplexity: 1381.814208984375\n",
      "train: step 2734000, cost: 6.095449924468994, perplexity: 443.8337097167969\n",
      "train: step 2735000, cost: 8.740519523620605, perplexity: 6251.142578125\n",
      "train: step 2736000, cost: 6.475783348083496, perplexity: 649.2276000976562\n",
      "train: step 2737000, cost: 10.189388275146484, perplexity: 26619.20703125\n",
      "train: step 2738000, cost: 7.18828010559082, perplexity: 1323.824462890625\n",
      "train: step 2739000, cost: 9.325943946838379, perplexity: 11225.5078125\n",
      "train: step 2740000, cost: 9.172086715698242, perplexity: 9624.6875\n",
      "train: step 2741000, cost: 7.8150248527526855, perplexity: 2477.548583984375\n",
      "train: step 2742000, cost: 11.898332595825195, perplexity: 147021.28125\n",
      "train: step 2743000, cost: 8.327631950378418, perplexity: 4136.6103515625\n",
      "train: step 2744000, cost: 10.887347221374512, perplexity: 53495.203125\n",
      "train: step 2745000, cost: 7.52543830871582, perplexity: 1854.6259765625\n",
      "train: step 2746000, cost: 12.173372268676758, perplexity: 193565.703125\n",
      "train: step 2747000, cost: 9.404585838317871, perplexity: 12143.943359375\n",
      "train: step 2748000, cost: 8.7891263961792, perplexity: 6562.49658203125\n",
      "train: step 2749000, cost: 10.044126510620117, perplexity: 23020.1796875\n",
      "train: step 2750000, cost: 8.689289093017578, perplexity: 5938.958984375\n",
      "train: step 2751000, cost: 8.716168403625488, perplexity: 6100.7587890625\n",
      "train: step 2752000, cost: 8.969286918640137, perplexity: 7857.99609375\n",
      "train: step 2753000, cost: 9.064360618591309, perplexity: 8641.751953125\n",
      "train: step 2754000, cost: 9.114324569702148, perplexity: 9084.49609375\n",
      "train: step 2755000, cost: 10.830246925354004, perplexity: 50526.1796875\n",
      "train: step 2756000, cost: 10.717812538146973, perplexity: 45153.0234375\n",
      "train: step 2757000, cost: 7.694071292877197, perplexity: 2195.2939453125\n",
      "train: step 2758000, cost: 8.7440824508667, perplexity: 6273.45458984375\n",
      "train: step 2759000, cost: 9.839705467224121, perplexity: 18764.1875\n",
      "train: step 2760000, cost: 7.3358612060546875, perplexity: 1534.3485107421875\n",
      "train: step 2761000, cost: 7.107086658477783, perplexity: 1220.5863037109375\n",
      "train: step 2762000, cost: 8.242761611938477, perplexity: 3800.02001953125\n",
      "train: step 2763000, cost: 8.364327430725098, perplexity: 4291.224609375\n",
      "train: step 2764000, cost: 8.04464340209961, perplexity: 3117.053466796875\n",
      "train: step 2765000, cost: 9.583849906921387, perplexity: 14528.2431640625\n",
      "train: step 2766000, cost: 7.20741081237793, perplexity: 1349.3939208984375\n",
      "train: step 2767000, cost: 9.416131973266602, perplexity: 12284.9716796875\n",
      "train: step 2768000, cost: 7.951791286468506, perplexity: 2840.65869140625\n",
      "train: step 2769000, cost: 10.348807334899902, perplexity: 31219.783203125\n",
      "train: step 2770000, cost: 8.655227661132812, perplexity: 5740.07568359375\n",
      "train: step 2771000, cost: 8.36130142211914, perplexity: 4278.25927734375\n",
      "train: step 2772000, cost: 10.281451225280762, perplexity: 29186.19921875\n",
      "train: step 2773000, cost: 12.596816062927246, perplexity: 295615.84375\n",
      "train: step 2774000, cost: 9.744765281677246, perplexity: 17064.666015625\n",
      "train: step 2775000, cost: 8.9642972946167, perplexity: 7818.884765625\n",
      "train: step 2776000, cost: 11.256213188171387, perplexity: 77359.0703125\n",
      "Model saved in path: /tmp/p2_run02_18.ckpt\n",
      "validation: epoch 18, cost: 9.001824378967285, perplexity: 8117.88037109375\n",
      "test: epoch 18, cost: 9.885091781616211, perplexity: [19173.516, 17592.662, 17449.03, 11225.486, 21339.318, 24617.826, 22408.908, 66997.37, 14599.063, 22131.621, 45416.027, 64620.516, 16979.926, 27348.324, 9064.601, 10224.9375, 5924.748, 19635.45]\n",
      "train: step 2777000, cost: 9.079030990600586, perplexity: 8769.4638671875\n",
      "train: step 2778000, cost: 9.178078651428223, perplexity: 9682.53125\n",
      "train: step 2779000, cost: 8.822185516357422, perplexity: 6783.07275390625\n",
      "train: step 2780000, cost: 15.616280555725098, perplexity: 6054307.0\n",
      "train: step 2781000, cost: 7.031593322753906, perplexity: 1131.8326416015625\n",
      "train: step 2782000, cost: 7.688146114349365, perplexity: 2182.3251953125\n",
      "train: step 2783000, cost: 9.331157684326172, perplexity: 11284.1875\n",
      "train: step 2784000, cost: 10.875752449035645, perplexity: 52878.515625\n",
      "train: step 2785000, cost: 8.651795387268066, perplexity: 5720.40771484375\n",
      "train: step 2786000, cost: 8.080795288085938, perplexity: 3231.802490234375\n",
      "train: step 2787000, cost: 8.803877830505371, perplexity: 6660.0205078125\n",
      "train: step 2788000, cost: 8.056964874267578, perplexity: 3155.69775390625\n",
      "train: step 2789000, cost: 9.265175819396973, perplexity: 10563.66796875\n",
      "train: step 2790000, cost: 7.397344589233398, perplexity: 1631.64599609375\n",
      "train: step 2791000, cost: 9.613638877868652, perplexity: 14967.5361328125\n",
      "train: step 2792000, cost: 8.955594062805176, perplexity: 7751.130859375\n",
      "train: step 2793000, cost: 9.31580924987793, perplexity: 11112.3154296875\n",
      "train: step 2794000, cost: 7.956915378570557, perplexity: 2855.251953125\n",
      "train: step 2795000, cost: 10.292242050170898, perplexity: 29502.84765625\n",
      "train: step 2796000, cost: 6.823977470397949, perplexity: 919.6355590820312\n",
      "train: step 2797000, cost: 9.164196968078613, perplexity: 9549.0498046875\n",
      "train: step 2798000, cost: 8.98934555053711, perplexity: 8017.20849609375\n",
      "train: step 2799000, cost: 6.526078224182129, perplexity: 682.7155151367188\n",
      "train: step 2800000, cost: 8.906109809875488, perplexity: 7376.90771484375\n",
      "train: step 2801000, cost: 8.035017967224121, perplexity: 3087.1943359375\n",
      "train: step 2802000, cost: 13.342902183532715, perplexity: 623374.125\n",
      "train: step 2803000, cost: 8.14650821685791, perplexity: 3451.306640625\n",
      "train: step 2804000, cost: 7.550058364868164, perplexity: 1900.8536376953125\n",
      "train: step 2805000, cost: 9.312678337097168, perplexity: 11077.578125\n",
      "train: step 2806000, cost: 7.028176784515381, perplexity: 1127.97216796875\n",
      "train: step 2807000, cost: 8.159079551696777, perplexity: 3494.968017578125\n",
      "train: step 2808000, cost: 10.721787452697754, perplexity: 45332.86328125\n",
      "train: step 2809000, cost: 8.270463943481445, perplexity: 3906.760986328125\n",
      "train: step 2810000, cost: 7.331599712371826, perplexity: 1527.8238525390625\n",
      "train: step 2811000, cost: 8.720789909362793, perplexity: 6129.0185546875\n",
      "train: step 2812000, cost: 9.625081062316895, perplexity: 15139.7802734375\n",
      "train: step 2813000, cost: 8.107707977294922, perplexity: 3319.9599609375\n",
      "train: step 2814000, cost: 9.42226791381836, perplexity: 12360.5830078125\n",
      "train: step 2815000, cost: 11.47323989868164, perplexity: 96109.1640625\n",
      "train: step 2816000, cost: 8.172141075134277, perplexity: 3540.917236328125\n",
      "train: step 2817000, cost: 8.462417602539062, perplexity: 4733.48828125\n",
      "train: step 2818000, cost: 7.839105129241943, perplexity: 2537.9326171875\n",
      "train: step 2819000, cost: 9.329320907592773, perplexity: 11263.48046875\n",
      "train: step 2820000, cost: 6.961130619049072, perplexity: 1054.825439453125\n",
      "train: step 2821000, cost: 7.454583644866943, perplexity: 1727.764404296875\n",
      "train: step 2822000, cost: 8.938427925109863, perplexity: 7619.20947265625\n",
      "train: step 2823000, cost: 8.96572494506836, perplexity: 7830.0556640625\n",
      "train: step 2824000, cost: 9.66401195526123, perplexity: 15740.80859375\n",
      "train: step 2825000, cost: 7.72369909286499, perplexity: 2261.308837890625\n",
      "train: step 2826000, cost: 7.330699443817139, perplexity: 1526.4490966796875\n",
      "train: step 2827000, cost: 9.12546157836914, perplexity: 9186.2353515625\n",
      "train: step 2828000, cost: 8.420159339904785, perplexity: 4537.62646484375\n",
      "train: step 2829000, cost: 10.234294891357422, perplexity: 27841.830078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 2830000, cost: 7.727166652679443, perplexity: 2269.16357421875\n",
      "train: step 2831000, cost: 7.215689182281494, perplexity: 1360.611083984375\n",
      "train: step 2832000, cost: 8.08340835571289, perplexity: 3240.258544921875\n",
      "train: step 2833000, cost: 9.800416946411133, perplexity: 18041.265625\n",
      "train: step 2834000, cost: 8.41364860534668, perplexity: 4508.1787109375\n",
      "train: step 2835000, cost: 8.979598999023438, perplexity: 7939.44775390625\n",
      "train: step 2836000, cost: 8.88962173461914, perplexity: 7256.27392578125\n",
      "train: step 2837000, cost: 7.490929126739502, perplexity: 1791.716064453125\n",
      "train: step 2838000, cost: 7.443770408630371, perplexity: 1709.182373046875\n",
      "train: step 2839000, cost: 8.157320976257324, perplexity: 3488.8271484375\n",
      "train: step 2840000, cost: 9.468786239624023, perplexity: 12949.1611328125\n",
      "train: step 2841000, cost: 14.149883270263672, perplexity: 1397063.75\n",
      "train: step 2842000, cost: 11.451373100280762, perplexity: 94030.3671875\n",
      "train: step 2843000, cost: 7.470666408538818, perplexity: 1755.7763671875\n",
      "train: step 2844000, cost: 8.638745307922363, perplexity: 5646.24072265625\n",
      "train: step 2845000, cost: 8.246066093444824, perplexity: 3812.597900390625\n",
      "train: step 2846000, cost: 10.629796981811523, perplexity: 41348.73046875\n",
      "train: step 2847000, cost: 9.161176681518555, perplexity: 9520.2529296875\n",
      "train: step 2848000, cost: 8.985451698303223, perplexity: 7986.05078125\n",
      "train: step 2849000, cost: 7.477575778961182, perplexity: 1767.94970703125\n",
      "train: step 2850000, cost: 7.628361701965332, perplexity: 2055.679443359375\n",
      "train: step 2851000, cost: 10.966496467590332, perplexity: 57901.37890625\n",
      "train: step 2852000, cost: 7.698204517364502, perplexity: 2204.386474609375\n",
      "train: step 2853000, cost: 9.365509033203125, perplexity: 11678.5498046875\n",
      "train: step 2854000, cost: 11.256966590881348, perplexity: 77417.3828125\n",
      "train: step 2855000, cost: 7.397871017456055, perplexity: 1632.5052490234375\n",
      "train: step 2856000, cost: 8.352185249328613, perplexity: 4239.4345703125\n",
      "train: step 2857000, cost: 7.486236572265625, perplexity: 1783.3280029296875\n",
      "train: step 2858000, cost: 8.010587692260742, perplexity: 3012.68701171875\n",
      "train: step 2859000, cost: 7.762347221374512, perplexity: 2350.415283203125\n",
      "train: step 2860000, cost: 11.40177059173584, perplexity: 89480.015625\n",
      "train: step 2861000, cost: 12.51502513885498, perplexity: 272399.53125\n",
      "train: step 2862000, cost: 7.915968894958496, perplexity: 2740.70068359375\n",
      "train: step 2863000, cost: 7.917614936828613, perplexity: 2745.2158203125\n",
      "train: step 2864000, cost: 7.798069477081299, perplexity: 2435.89501953125\n",
      "train: step 2865000, cost: 10.853697776794434, perplexity: 51725.06640625\n",
      "train: step 2866000, cost: 8.970300674438477, perplexity: 7865.96630859375\n",
      "train: step 2867000, cost: 8.242117881774902, perplexity: 3797.574462890625\n",
      "train: step 2868000, cost: 8.576668739318848, perplexity: 5306.39892578125\n",
      "train: step 2869000, cost: 6.906189918518066, perplexity: 998.4358520507812\n",
      "train: step 2870000, cost: 8.471766471862793, perplexity: 4777.9482421875\n",
      "train: step 2871000, cost: 9.112015724182129, perplexity: 9063.5458984375\n",
      "train: step 2872000, cost: 9.820039749145508, perplexity: 18398.783203125\n",
      "train: step 2873000, cost: 9.238205909729004, perplexity: 10282.57421875\n",
      "train: step 2874000, cost: 7.734448432922363, perplexity: 2285.74755859375\n",
      "train: step 2875000, cost: 9.978472709655762, perplexity: 21557.36328125\n",
      "train: step 2876000, cost: 9.247522354125977, perplexity: 10378.8193359375\n",
      "train: step 2877000, cost: 8.289098739624023, perplexity: 3980.2451171875\n",
      "train: step 2878000, cost: 10.051283836364746, perplexity: 23185.53515625\n",
      "train: step 2879000, cost: 7.076671123504639, perplexity: 1184.0205078125\n",
      "train: step 2880000, cost: 7.282532691955566, perplexity: 1454.6676025390625\n",
      "train: step 2881000, cost: 9.650382041931152, perplexity: 15527.7177734375\n",
      "train: step 2882000, cost: 9.432604789733887, perplexity: 12489.015625\n",
      "train: step 2883000, cost: 8.262612342834473, perplexity: 3876.206787109375\n",
      "train: step 2884000, cost: 9.346309661865234, perplexity: 11456.466796875\n",
      "train: step 2885000, cost: 9.486838340759277, perplexity: 13185.04296875\n",
      "train: step 2886000, cost: 7.781510353088379, perplexity: 2395.890625\n",
      "train: step 2887000, cost: 7.603538990020752, perplexity: 2005.2799072265625\n",
      "train: step 2888000, cost: 10.850732803344727, perplexity: 51571.93359375\n",
      "train: step 2889000, cost: 8.559261322021484, perplexity: 5214.82763671875\n",
      "train: step 2890000, cost: 8.651912689208984, perplexity: 5721.0791015625\n",
      "train: step 2891000, cost: 7.729577541351318, perplexity: 2274.64111328125\n",
      "train: step 2892000, cost: 12.132224082946777, perplexity: 185762.46875\n",
      "train: step 2893000, cost: 9.593894004821777, perplexity: 14674.90234375\n",
      "train: step 2894000, cost: 7.365907669067383, perplexity: 1581.14990234375\n",
      "train: step 2895000, cost: 9.698784828186035, perplexity: 16297.7900390625\n",
      "train: step 2896000, cost: 6.811607837677002, perplexity: 908.3300170898438\n",
      "train: step 2897000, cost: 8.40173053741455, perplexity: 4454.76904296875\n",
      "train: step 2898000, cost: 8.366786003112793, perplexity: 4301.7880859375\n",
      "train: step 2899000, cost: 8.708487510681152, perplexity: 6054.0791015625\n",
      "train: step 2900000, cost: 7.7823662757873535, perplexity: 2397.942138671875\n",
      "train: step 2901000, cost: 8.478547096252441, perplexity: 4810.45556640625\n",
      "train: step 2902000, cost: 10.246532440185547, perplexity: 28184.640625\n",
      "train: step 2903000, cost: 8.185460090637207, perplexity: 3588.39404296875\n",
      "train: step 2904000, cost: 9.097245216369629, perplexity: 8930.65625\n",
      "train: step 2905000, cost: 10.581881523132324, perplexity: 39414.20703125\n",
      "train: step 2906000, cost: 10.51205825805664, perplexity: 36756.0546875\n",
      "train: step 2907000, cost: 9.36820125579834, perplexity: 11710.033203125\n",
      "train: step 2908000, cost: 7.064629077911377, perplexity: 1169.8480224609375\n",
      "train: step 2909000, cost: 8.74637222290039, perplexity: 6287.8359375\n",
      "train: step 2910000, cost: 6.928098678588867, perplexity: 1020.5516967773438\n",
      "train: step 2911000, cost: 7.498561382293701, perplexity: 1805.4432373046875\n",
      "train: step 2912000, cost: 9.016691207885742, perplexity: 8239.4697265625\n",
      "train: step 2913000, cost: 9.472088813781738, perplexity: 12991.9970703125\n",
      "train: step 2914000, cost: 8.568658828735352, perplexity: 5264.0654296875\n",
      "train: step 2915000, cost: 9.098904609680176, perplexity: 8945.4892578125\n",
      "train: step 2916000, cost: 10.709714889526367, perplexity: 44788.8671875\n",
      "train: step 2917000, cost: 6.946518898010254, perplexity: 1039.524658203125\n",
      "train: step 2918000, cost: 7.02825927734375, perplexity: 1128.065185546875\n",
      "train: step 2919000, cost: 8.637785911560059, perplexity: 5640.8271484375\n",
      "train: step 2920000, cost: 8.756613731384277, perplexity: 6352.5634765625\n",
      "train: step 2921000, cost: 9.22040843963623, perplexity: 10101.189453125\n",
      "train: step 2922000, cost: 8.8123779296875, perplexity: 6716.87255859375\n",
      "train: step 2923000, cost: 11.207676887512207, perplexity: 73694.015625\n",
      "train: step 2924000, cost: 7.009391784667969, perplexity: 1106.9810791015625\n",
      "train: step 2925000, cost: 6.858279228210449, perplexity: 951.7279052734375\n",
      "train: step 2926000, cost: 7.281548023223877, perplexity: 1453.2359619140625\n",
      "train: step 2927000, cost: 8.003543853759766, perplexity: 2991.541015625\n",
      "train: step 2928000, cost: 7.625046730041504, perplexity: 2048.876220703125\n",
      "train: step 2929000, cost: 7.510020732879639, perplexity: 1826.2513427734375\n",
      "train: step 2930000, cost: 8.624446868896484, perplexity: 5566.0830078125\n",
      "train: step 2931000, cost: 8.738874435424805, perplexity: 6240.86767578125\n",
      "Model saved in path: /tmp/p2_run02_19.ckpt\n",
      "validation: epoch 19, cost: 9.074460983276367, perplexity: 8729.4794921875\n",
      "test: epoch 19, cost: 9.99982738494873, perplexity: [19173.516, 17592.662, 17449.03, 11225.486, 21339.318, 24617.826, 22408.908, 66997.37, 14599.063, 22131.621, 45416.027, 64620.516, 16979.926, 27348.324, 9064.601, 10224.9375, 5924.748, 19635.45, 22022.664]\n",
      "train: step 2932000, cost: 10.08057689666748, perplexity: 23874.75390625\n",
      "train: step 2933000, cost: 6.831789016723633, perplexity: 926.8474731445312\n",
      "train: step 2934000, cost: 8.918082237243652, perplexity: 7465.75732421875\n",
      "train: step 2935000, cost: 8.767988204956055, perplexity: 6425.23291015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 2936000, cost: 8.866436004638672, perplexity: 7089.96728515625\n",
      "train: step 2937000, cost: 8.4152250289917, perplexity: 4515.29150390625\n",
      "train: step 2938000, cost: 7.755971431732178, perplexity: 2335.476806640625\n",
      "train: step 2939000, cost: 9.866782188415527, perplexity: 19279.203125\n",
      "train: step 2940000, cost: 8.46503734588623, perplexity: 4745.90478515625\n",
      "train: step 2941000, cost: 10.166437149047852, perplexity: 26015.224609375\n",
      "train: step 2942000, cost: 10.450687408447266, perplexity: 34568.12890625\n",
      "train: step 2943000, cost: 8.279313087463379, perplexity: 3941.48583984375\n",
      "train: step 2944000, cost: 9.811365127563477, perplexity: 18239.87109375\n",
      "train: step 2945000, cost: 7.729816913604736, perplexity: 2275.185546875\n",
      "train: step 2946000, cost: 7.79551887512207, perplexity: 2429.68994140625\n",
      "train: step 2947000, cost: 9.298680305480957, perplexity: 10923.59375\n",
      "train: step 2948000, cost: 10.87765121459961, perplexity: 52979.01953125\n",
      "train: step 2949000, cost: 8.102804183959961, perplexity: 3303.71923828125\n",
      "train: step 2950000, cost: 9.805541038513184, perplexity: 18133.947265625\n",
      "train: step 2951000, cost: 6.596794605255127, perplexity: 732.74267578125\n",
      "train: step 2952000, cost: 9.218249320983887, perplexity: 10079.4033203125\n",
      "train: step 2953000, cost: 9.652069091796875, perplexity: 15553.9365234375\n",
      "train: step 2954000, cost: 7.23797607421875, perplexity: 1391.2752685546875\n",
      "train: step 2955000, cost: 7.417464256286621, perplexity: 1664.806640625\n",
      "train: step 2956000, cost: 8.655109405517578, perplexity: 5739.39697265625\n",
      "train: step 2957000, cost: 7.83213472366333, perplexity: 2520.3037109375\n",
      "train: step 2958000, cost: 8.587515830993652, perplexity: 5364.271484375\n",
      "train: step 2959000, cost: 7.729333400726318, perplexity: 2274.0859375\n",
      "train: step 2960000, cost: 8.381246566772461, perplexity: 4364.4462890625\n",
      "train: step 2961000, cost: 9.512552261352539, perplexity: 13528.4775390625\n",
      "train: step 2962000, cost: 10.060683250427246, perplexity: 23404.4921875\n",
      "train: step 2963000, cost: 7.923495769500732, perplexity: 2761.407470703125\n",
      "train: step 2964000, cost: 9.29883861541748, perplexity: 10925.3232421875\n",
      "train: step 2965000, cost: 8.810080528259277, perplexity: 6701.458984375\n",
      "train: step 2966000, cost: 8.819266319274902, perplexity: 6763.30029296875\n",
      "train: step 2967000, cost: 11.002360343933105, perplexity: 60015.62890625\n",
      "train: step 2968000, cost: 7.897563457489014, perplexity: 2690.71826171875\n",
      "train: step 2969000, cost: 7.102108955383301, perplexity: 1214.5257568359375\n",
      "train: step 2970000, cost: 7.596582412719727, perplexity: 1991.37841796875\n",
      "train: step 2971000, cost: 8.165456771850586, perplexity: 3517.327392578125\n",
      "train: step 2972000, cost: 8.054701805114746, perplexity: 3148.564208984375\n",
      "train: step 2973000, cost: 9.61863899230957, perplexity: 15042.5634765625\n",
      "train: step 2974000, cost: 7.523791313171387, perplexity: 1851.5738525390625\n",
      "train: step 2975000, cost: 8.665380477905273, perplexity: 5798.650390625\n",
      "train: step 2976000, cost: 10.987560272216797, perplexity: 59133.9375\n",
      "train: step 2977000, cost: 8.282729148864746, perplexity: 3954.97314453125\n",
      "train: step 2978000, cost: 7.562052249908447, perplexity: 1923.78955078125\n",
      "train: step 2979000, cost: 8.438461303710938, perplexity: 4621.4384765625\n",
      "train: step 2980000, cost: 7.514908790588379, perplexity: 1835.199951171875\n",
      "train: step 2981000, cost: 10.211793899536133, perplexity: 27222.357421875\n",
      "train: step 2982000, cost: 8.974051475524902, perplexity: 7895.52587890625\n",
      "train: step 2983000, cost: 9.11276626586914, perplexity: 9070.3505859375\n",
      "train: step 2984000, cost: 9.42696475982666, perplexity: 12418.775390625\n",
      "train: step 2985000, cost: 8.877429008483887, perplexity: 7168.33740234375\n",
      "train: step 2986000, cost: 10.361572265625, perplexity: 31620.857421875\n",
      "train: step 2987000, cost: 9.047758102416992, perplexity: 8499.4609375\n",
      "train: step 2988000, cost: 8.920804977416992, perplexity: 7486.11328125\n",
      "train: step 2989000, cost: 6.992835998535156, perplexity: 1088.804931640625\n",
      "train: step 2990000, cost: 9.012653350830078, perplexity: 8206.2666015625\n",
      "train: step 2991000, cost: 8.567551612854004, perplexity: 5258.23974609375\n",
      "train: step 2992000, cost: 7.776282787322998, perplexity: 2383.39892578125\n",
      "train: step 2993000, cost: 8.955984115600586, perplexity: 7754.15478515625\n",
      "train: step 2994000, cost: 8.387659072875977, perplexity: 4392.5234375\n",
      "train: step 2995000, cost: 10.026981353759766, perplexity: 22628.859375\n",
      "train: step 2996000, cost: 7.030806064605713, perplexity: 1130.94189453125\n",
      "train: step 2997000, cost: 8.763039588928223, perplexity: 6393.515625\n",
      "train: step 2998000, cost: 7.233278274536133, perplexity: 1384.7547607421875\n",
      "train: step 2999000, cost: 7.628416538238525, perplexity: 2055.792236328125\n",
      "train: step 3000000, cost: 8.34681224822998, perplexity: 4216.71728515625\n",
      "train: step 3001000, cost: 9.063206672668457, perplexity: 8631.7861328125\n",
      "train: step 3002000, cost: 8.019625663757324, perplexity: 3040.039306640625\n",
      "train: step 3003000, cost: 7.8535566329956055, perplexity: 2574.875732421875\n",
      "train: step 3004000, cost: 8.396483421325684, perplexity: 4431.4560546875\n",
      "train: step 3005000, cost: 8.715389251708984, perplexity: 6096.0068359375\n",
      "train: step 3006000, cost: 9.31772232055664, perplexity: 11133.59375\n",
      "train: step 3007000, cost: 8.306173324584961, perplexity: 4048.78955078125\n",
      "train: step 3008000, cost: 14.44753360748291, perplexity: 1881413.0\n",
      "train: step 3009000, cost: 10.744512557983398, perplexity: 46374.8515625\n",
      "train: step 3010000, cost: 9.925211906433105, perplexity: 20439.2421875\n",
      "train: step 3011000, cost: 9.686813354492188, perplexity: 16103.8447265625\n",
      "train: step 3012000, cost: 13.350313186645508, perplexity: 628011.125\n",
      "train: step 3013000, cost: 10.73869800567627, perplexity: 46105.984375\n",
      "train: step 3014000, cost: 8.529253005981445, perplexity: 5060.6640625\n",
      "train: step 3015000, cost: 8.929766654968262, perplexity: 7553.50244140625\n",
      "train: step 3016000, cost: 8.084480285644531, perplexity: 3243.733642578125\n",
      "train: step 3017000, cost: 9.9443359375, perplexity: 20833.8828125\n",
      "train: step 3018000, cost: 9.211150169372559, perplexity: 10008.1015625\n",
      "train: step 3019000, cost: 9.369802474975586, perplexity: 11728.798828125\n",
      "train: step 3020000, cost: 11.53553295135498, perplexity: 102286.4921875\n",
      "train: step 3021000, cost: 6.708278179168701, perplexity: 819.1589965820312\n",
      "train: step 3022000, cost: 7.55548095703125, perplexity: 1911.189208984375\n",
      "train: step 3023000, cost: 7.427526950836182, perplexity: 1681.6436767578125\n",
      "train: step 3024000, cost: 11.88769817352295, perplexity: 145466.078125\n",
      "train: step 3025000, cost: 8.668929100036621, perplexity: 5819.26416015625\n",
      "train: step 3026000, cost: 10.920756340026855, perplexity: 55312.61328125\n",
      "train: step 3027000, cost: 10.152740478515625, perplexity: 25661.330078125\n",
      "train: step 3028000, cost: 13.920713424682617, perplexity: 1110936.0\n",
      "train: step 3029000, cost: 7.4147491455078125, perplexity: 1660.2926025390625\n",
      "train: step 3030000, cost: 9.72455883026123, perplexity: 16723.310546875\n",
      "train: step 3031000, cost: 8.163814544677734, perplexity: 3511.55615234375\n",
      "train: step 3032000, cost: 8.047258377075195, perplexity: 3125.215087890625\n",
      "train: step 3033000, cost: 7.614783763885498, perplexity: 2027.9561767578125\n",
      "train: step 3034000, cost: 8.561124801635742, perplexity: 5224.55419921875\n",
      "train: step 3035000, cost: 9.487412452697754, perplexity: 13192.615234375\n",
      "train: step 3036000, cost: 7.834102153778076, perplexity: 2525.26708984375\n",
      "train: step 3037000, cost: 7.971327304840088, perplexity: 2896.699462890625\n",
      "train: step 3038000, cost: 9.250463485717773, perplexity: 10409.388671875\n",
      "train: step 3039000, cost: 7.301916122436523, perplexity: 1483.1390380859375\n",
      "train: step 3040000, cost: 10.32563591003418, perplexity: 30504.6953125\n",
      "train: step 3041000, cost: 9.604567527770996, perplexity: 14832.3740234375\n",
      "train: step 3042000, cost: 8.664137840270996, perplexity: 5791.44921875\n",
      "train: step 3043000, cost: 8.114374160766602, perplexity: 3342.1650390625\n",
      "train: step 3044000, cost: 8.07162857055664, perplexity: 3202.312744140625\n",
      "train: step 3045000, cost: 15.138983726501465, perplexity: 3756445.75\n",
      "train: step 3046000, cost: 7.392869472503662, perplexity: 1624.3604736328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: step 3047000, cost: 8.414143562316895, perplexity: 4510.41064453125\n",
      "train: step 3048000, cost: 7.418241024017334, perplexity: 1666.100341796875\n",
      "train: step 3049000, cost: 8.998927116394043, perplexity: 8094.39501953125\n",
      "train: step 3050000, cost: 9.956154823303223, perplexity: 21081.578125\n",
      "train: step 3051000, cost: 7.528724193572998, perplexity: 1860.72998046875\n",
      "train: step 3052000, cost: 8.035162925720215, perplexity: 3087.641845703125\n",
      "train: step 3053000, cost: 8.703815460205078, perplexity: 6025.8603515625\n",
      "train: step 3054000, cost: 7.663182735443115, perplexity: 2128.521240234375\n",
      "train: step 3055000, cost: 9.299700736999512, perplexity: 10934.74609375\n",
      "train: step 3056000, cost: 8.837141990661621, perplexity: 6885.2861328125\n",
      "train: step 3057000, cost: 8.000601768493652, perplexity: 2982.75244140625\n",
      "train: step 3058000, cost: 11.35775375366211, perplexity: 85626.8125\n",
      "train: step 3059000, cost: 11.904065132141113, perplexity: 147866.5\n",
      "train: step 3060000, cost: 8.251483917236328, perplexity: 3833.309814453125\n",
      "train: step 3061000, cost: 9.355480194091797, perplexity: 11562.0126953125\n",
      "train: step 3062000, cost: 7.812886714935303, perplexity: 2472.2568359375\n",
      "train: step 3063000, cost: 8.285613059997559, perplexity: 3966.3955078125\n",
      "train: step 3064000, cost: 8.662922859191895, perplexity: 5784.4169921875\n",
      "train: step 3065000, cost: 10.4295015335083, perplexity: 33843.4765625\n",
      "train: step 3066000, cost: 11.364513397216797, perplexity: 86207.5859375\n",
      "train: step 3067000, cost: 8.410170555114746, perplexity: 4492.5263671875\n",
      "train: step 3068000, cost: 12.682780265808105, perplexity: 322152.5\n",
      "train: step 3069000, cost: 7.056266784667969, perplexity: 1160.106201171875\n",
      "train: step 3070000, cost: 9.261124610900879, perplexity: 10520.9580078125\n",
      "train: step 3071000, cost: 6.984667778015137, perplexity: 1079.9476318359375\n",
      "train: step 3072000, cost: 10.398778915405273, perplexity: 32819.52734375\n",
      "train: step 3073000, cost: 9.387792587280273, perplexity: 11941.7099609375\n",
      "train: step 3074000, cost: 6.794561862945557, perplexity: 892.9779663085938\n",
      "train: step 3075000, cost: 10.105113983154297, perplexity: 24467.818359375\n",
      "train: step 3076000, cost: 7.652181625366211, perplexity: 2105.2333984375\n",
      "train: step 3077000, cost: 8.629148483276367, perplexity: 5592.314453125\n",
      "train: step 3078000, cost: 9.751346588134766, perplexity: 17177.34375\n",
      "train: step 3079000, cost: 9.589471817016602, perplexity: 14610.150390625\n",
      "train: step 3080000, cost: 8.81064224243164, perplexity: 6705.22412109375\n",
      "train: step 3081000, cost: 7.3407816886901855, perplexity: 1541.9169921875\n",
      "train: step 3082000, cost: 7.592960834503174, perplexity: 1984.1795654296875\n",
      "train: step 3083000, cost: 7.720383167266846, perplexity: 2253.822998046875\n",
      "train: step 3084000, cost: 9.588534355163574, perplexity: 14596.4599609375\n",
      "train: step 3085000, cost: 9.591367721557617, perplexity: 14637.8759765625\n",
      "Model saved in path: /tmp/p2_run02_20.ckpt\n",
      "validation: epoch 20, cost: 8.880328178405762, perplexity: 7189.1494140625\n",
      "test: epoch 20, cost: 9.747434616088867, perplexity: [19173.516, 17592.662, 17449.03, 11225.486, 21339.318, 24617.826, 22408.908, 66997.37, 14599.063, 22131.621, 45416.027, 64620.516, 16979.926, 27348.324, 9064.601, 10224.9375, 5924.748, 19635.45, 22022.664, 17110.28]\n"
     ]
    }
   ],
   "source": [
    "# train our model\n",
    "class BengioModel2():\n",
    "  \"\"\"\n",
    "  Class implements Bengio NN model with Tensorflow accoring to the function:\n",
    "    y = b + Utanh(d + Hx)\n",
    "  \n",
    "  and \n",
    "    cost = softmax_cross_entropy?\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, params):\n",
    "\n",
    "    self.Y = tf.placeholder(\n",
    "        dtype=params.tf_precision,\n",
    "        shape=(params.num_batches, params.vocab_len),\n",
    "        name=\"Y\"\n",
    "    )\n",
    "    \n",
    "    self.X = tf.placeholder(\n",
    "        tf.int32, \n",
    "        shape=(params.num_batches, params.context_window),\n",
    "        name=\"X\"\n",
    "    )\n",
    "\n",
    "    # embeddings\n",
    "    self.C = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            shape=(params.vocab_len, params.embeddings_dim),\n",
    "            mean=-1,\n",
    "            stddev=-1\n",
    "        ),\n",
    "        dtype=params.tf_precision,\n",
    "        name=\"C\"\n",
    "    )\n",
    "\n",
    "    # self.W = tf.Variable(\n",
    "    #     tf.random_normal(\n",
    "    #         shape=(params.vocab_len, params.context_window * params.embeddings_dim)\n",
    "    #     ),\n",
    "    #     name=\"W\",\n",
    "    #     dtype=params.tf_precision\n",
    "    # )\n",
    "    \n",
    "    self.H = tf.Variable(\n",
    "        tf.random_normal(\n",
    "            shape=(params.hidden_units, params.context_window * params.embeddings_dim)\n",
    "        ),\n",
    "        name=\"H\",\n",
    "        dtype=params.tf_precision\n",
    "    )\n",
    "\n",
    "    self.d = tf.Variable(\n",
    "        tf.random_normal(\n",
    "            shape=(params.hidden_units,)\n",
    "        ),\n",
    "        name=\"d\",\n",
    "        dtype=params.tf_precision\n",
    "    )\n",
    "\n",
    "    self.U = tf.Variable(\n",
    "        tf.random_normal(\n",
    "            (params.vocab_len, params.hidden_units)\n",
    "        ),\n",
    "        name=\"U\",\n",
    "        dtype=params.tf_precision\n",
    "    )\n",
    "\n",
    "    self.b = tf.Variable(\n",
    "        tf.random_normal(\n",
    "            shape=(params.vocab_len, )\n",
    "        ),\n",
    "        name=\"b\",\n",
    "        dtype=params.tf_precision\n",
    "    )\n",
    "\n",
    "    with tf.name_scope(\"Projection_Layer\"):\n",
    "      x = tf.nn.embedding_lookup(self.C, self.X)\n",
    "      x = tf.reshape(\n",
    "          x,\n",
    "          shape=(params.num_batches, params.context_window * params.embeddings_dim)\n",
    "      )\n",
    "\n",
    "    with tf.name_scope(\"Hidden_Layer\"):\n",
    "      Hx = tf.matmul(x, tf.transpose(self.H))\n",
    "      a = tf.nn.tanh(tf.add(Hx, self.d))\n",
    "\n",
    "    with tf.name_scope(\"Output_Layer\"):\n",
    "      Ua = tf.matmul(a, tf.transpose(self.U))\n",
    "      # Wx = tf.matmul(x, tf.transpose(self.W))\n",
    "      Y_hat = tf.add(self.b, Ua) \n",
    "\n",
    "    with tf.name_scope(\"Cost\"):\n",
    "     self.cost = tf.reduce_mean( \n",
    "        tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            labels=self.Y,\n",
    "            logits=Y_hat\n",
    "        )\n",
    "      )\n",
    "     self.perplexity = tf.exp(self.cost)\n",
    "\n",
    "    self.optimizer = tf.train.GradientDescentOptimizer(params.learning_rate).minimize(self.cost)\n",
    "\n",
    "int_train = pickle.load(open(os.path.join(data_path, 'group2.int_train.p'), 'rb'))\n",
    "int_validation = pickle.load(open(os.path.join(data_path, 'group2.int_valid.p'), 'rb'))\n",
    "int_test = pickle.load(open(os.path.join(data_path, 'group2.int_test.p'), 'rb'))\n",
    "vocab_dict = pickle.load(open(os.path.join(data_path, 'group2.vocab_dict.p'), 'rb'))\n",
    "\n",
    "train_batches_int = gen_batches(5, 30, int_train)\n",
    "val_batches_int = gen_batches(5, 30, int_validation)\n",
    "test_batches_int = gen_batches(5, 30, int_test)\n",
    "\n",
    "run01_params = BengioParams(name=\"p2_run02\", vocab_dict=vocab_dict)\n",
    "run01_params.embedding_dimensions = 100\n",
    "run01_params.hidden_units = 100\n",
    "run01_params.context_window = 5\n",
    "run01_params.gpu_mem = .9\n",
    "\n",
    "run01_model = BengioModel2(params=run01_params)\n",
    "\n",
    "run01_perplexity_history,  run01_cost_history, run01_val_perplexity_history, run01_val_cost_history, run01_test_perplexity_history, run01_test_cost_history = run(run01_model, run01_params, train_batches_int, val_batches_int, test_batches_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1SFcnpqwBpam"
   },
   "outputs": [],
   "source": [
    "pickle.dump(run01_perplexity_history, open(os.path.join(data_path, 'p2_run01_perplexity_history.p'), 'wb'))\n",
    "pickle.dump(run01_cost_history, open(os.path.join(data_path, 'p2_run01_cost_history.p'), 'wb'))\n",
    "pickle.dump(run01_val_perplexity_history, open(os.path.join(data_path, 'p2_run01_val_perplexity_history.p'), 'wb'))\n",
    "pickle.dump(run01_val_cost_history, open(os.path.join(data_path, 'p2_run01_val_cost_history.p'), 'wb'))\n",
    "pickle.dump(run01_test_perplexity_history, open(os.path.join(data_path, 'p2_run01_test_perplexity_history.p'), 'wb'))\n",
    "pickle.dump(run01_test_cost_history, open(os.path.join(data_path, 'p2_run01_test_cost_history.p'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "nlp_assignment_2.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
