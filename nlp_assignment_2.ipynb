{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_assignment_2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blainerothrock/nlp-group-2/blob/master/nlp_assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5suI3fCFjhO",
        "colab_type": "text"
      },
      "source": [
        "# NLP Assignment 2 (Bengio and other Neural Language Models)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD4GX_ezyPag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "# %tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "# from google.colab import drive, files \n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "import os, pickle\n",
        "import numpy as np\n",
        "import math\n",
        "import typing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYLEc_SQLTmc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnA8lII6Al51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "blaine_data_path = '/Users/blaine/Google Drive File Stream/My Drive/Winter20/nlp/nlp_group2/data'\n",
        "data_path = 'drive/My Drive/Winter20/nlp/nlp_group2/data'\n",
        "grant_data_path = 'drive/My Drive/nlp_group2/data'\n",
        "sundar_data_path = 'drive/My Drive/nlp_group2/data'\n",
        "z_data_path = 'drive/My Drive/nlp_group2/data'\n",
        "sundar_local_path = '~/Workspaces/Q2/NLP/data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hux8jIA0OWWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = blaine_data_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X8tKzUSzAlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(os.listdir(data_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWiLJQNrE72M",
        "colab_type": "text"
      },
      "source": [
        "## Task 1\n",
        "Split train corpus with `batch_size=30` and `window=5` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6iLwqmo_Do1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data\n",
        "int_tagged_train = pickle.load(open(os.path.join(data_path, 'group2.int_tagged_train.p'), 'rb'))\n",
        "tagged_train = pickle.load(open(os.path.join(data_path, 'group2.tagged_train.p'), 'rb'))\n",
        "vocab_dict = pickle.load(open(os.path.join(data_path, 'group2.vocab_dict.p'), 'rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pw_br8mAJ58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(int_tagged_train[:10], '\\n', tagged_train[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFbxb_nIAQHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# batch the train integer representations\n",
        "def gen_batches(context_size, batch_size, data):\n",
        "  num_data = len(data)\n",
        "\n",
        "  # removing remainder tokens\n",
        "  remainder = num_data % 30\n",
        "  data = data[:num_data - remainder]\n",
        "  num_data = len(data)\n",
        "\n",
        "  batches = np.array_split(data, math.floor(num_data)/batch_size)\n",
        "  return batches\n",
        "\n",
        "batches = gen_batches(5, 30, tagged_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg3b1XELNCYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_seq(batch, window, seq_idx):\n",
        "  input_tokens = batch[seq_idx:seq_idx+window]\n",
        "  target_token = batch[seq_idx+window]\n",
        "\n",
        "  print(\"input : \", input_tokens)\n",
        "  print(\"target: [\", target_token, \"]\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkBM381LNChw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('--- batch 01 ---')\n",
        "print_seq(batches[0], window, 0)\n",
        "print_seq(batches[0], window, 1)\n",
        "print_seq(batches[0], window, 2)\n",
        "\n",
        "print('-- batch 02 --')\n",
        "print_seq(batches[1], window, 0)\n",
        "print_seq(batches[1], window, 1)\n",
        "print_seq(batches[1], window, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6gNu8xBSizG",
        "colab_type": "text"
      },
      "source": [
        "## Task 2: Bengio Style Feedforward network language model\n",
        "- TensorFlow version: `2.1.0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWCFC4p1RMPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BengioParams():\n",
        "  context_window = 5\n",
        "  batch_size = 30\n",
        "  \n",
        "  hidden_units = 50\n",
        "  embeddings_space = 60\n",
        "  num_epochs = 20\n",
        "\n",
        "  learning_rate = 0.5\n",
        "\n",
        "  gpu_mem = 0.25\n",
        "  \n",
        "  tf_precision = tf.float32\n",
        "  np_precision = np.float32\n",
        "\n",
        "  init_scale = 0.5\n",
        "  max_grad = 10.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj6d3vk0U0lz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class BengioModel():\n",
        "  \"\"\"\n",
        "  Class implements Bengio NN model with Tensorflow accoring to the function:\n",
        "    y = b + Ux + tanh(d + Hx)\n",
        "  \n",
        "  and \n",
        "    cost = softmax_cross_entropy?\n",
        "\n",
        "  NOTE: dimensions are not correct yet! need clarification \n",
        "  (may need to transpose)\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, params=BengioParams()):\n",
        "    self.x = tf.compat.v1.placeholder(\n",
        "        params.tf_precision, \n",
        "        shape=[params.context_window, 1],\n",
        "        name=\"x\"\n",
        "    )\n",
        "\n",
        "    self.y = tf.compat.v1.placeholder(\n",
        "        params.tf_precision,\n",
        "        shape=[1],\n",
        "        name=\"y\"\n",
        "    )\n",
        "\n",
        "    self.W = tf.compat.v1.get_variable(\n",
        "        name=\"W\",\n",
        "        shape=[params.context_window, 1],\n",
        "        dtype=params.tf_precision\n",
        "    )\n",
        "    \n",
        "    self.H = tf.compat.v1.get_variable(\n",
        "        name=\"H\",\n",
        "        shape=[params.context_window, 1],\n",
        "        dtype=params.tf_precision\n",
        "    )\n",
        "\n",
        "    self.U = tf.compat.v1.get_variable(\n",
        "        name=\"U\",\n",
        "        shape=[params.context_window, 1],\n",
        "        dtype=params.tf_precision\n",
        "    )\n",
        "\n",
        "    self.b = tf.compat.v1.get_variable(\n",
        "        name=\"b\",\n",
        "        shape=[1],\n",
        "        dtype=params.tf_precision\n",
        "    )\n",
        "\n",
        "    self.d = tf.compat.v1.get_variable(\n",
        "        name=\"d\",\n",
        "        shape=[1],\n",
        "        dtype=params.tf_precision\n",
        "    )\n",
        "\n",
        "    self.a1 = tf.compat.v1.tanh(\n",
        "        self.d + tf.matmul(self.x, self.H)\n",
        "    )\n",
        "\n",
        "    self.y_hat =  self.b + tf.matmul(self.W, self.x) + self.a1\n",
        "\n",
        "    self.cost = tf.nn.softmax_cross_entropy_with_logits(\n",
        "        self.y,\n",
        "        self.y_hat,\n",
        "        name='cross_entropy_coss_fn'\n",
        "    )\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiI-h9TscByK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}