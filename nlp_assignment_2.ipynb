{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_assignment_2.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blainerothrock/nlp-group-2/blob/master/nlp_assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5suI3fCFjhO",
        "colab_type": "text"
      },
      "source": [
        "# NLP Assignment 2 (Bengio and other Neural Language Models)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XD4GX_ezyPag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "print(tf.__version__)\n",
        "\n",
        "from google.colab import drive, files \n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, pickle\n",
        "import numpy as np\n",
        "import math\n",
        "import typing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYLEc_SQLTmc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.listdir()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnA8lII6Al51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "blaine_data_path = '/Users/blaine/Google Drive File Stream/My Drive/Winter20/nlp/nlp_group2/data'\n",
        "data_path = 'drive/My Drive/Winter20/nlp/nlp_group2/data'\n",
        "grant_data_path = 'drive/My Drive/nlp_group2/data'\n",
        "sundar_data_path = 'drive/My Drive/nlp_group2/data'\n",
        "z_data_path = 'drive/My Drive/nlp_group2/data'\n",
        "sundar_local_path = '~/Workspaces/Q2/NLP/data'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hux8jIA0OWWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = data_path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X8tKzUSzAlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(os.listdir(data_path))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWiLJQNrE72M",
        "colab_type": "text"
      },
      "source": [
        "## Task 1\n",
        "Split train corpus with `batch_size=30` and `window=5` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6iLwqmo_Do1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load data\n",
        "int_train = pickle.load(open(os.path.join(data_path, 'group2.int_train.p'), 'rb'))\n",
        "train = pickle.load(open(os.path.join(data_path, 'group2.train.p'), 'rb'))\n",
        "vocab_dict = pickle.load(open(os.path.join(data_path, 'group2.vocab_dict.p'), 'rb'))\n",
        "int_train = [vocab_dict[w] for w in train]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pw_br8mAJ58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(int_tagged_train[:10], '\\n', tagged_train[:10])\n",
        "\n",
        "print(\"vocab len: %i\" % len(vocab_dict))\n",
        "print(\"int rep: %s\" % len(int_train))\n",
        "print(\"train token: %s\" % len(train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Q27oXDpa70T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_ids = tf.constant(int_train)\n",
        "embeddings = tf.Variable(tf.random_uniform([len(vocab_dict), 60]))\n",
        "embed = tf.nn.embedding_lookup(embeddings, word_ids)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    embeddings = sess.run(embed)\n",
        "\n",
        "embeddings.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFbxb_nIAQHn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# batch the train integer representations\n",
        "def gen_batches(context_size, num_batches, data):\n",
        "  num_data = len(data)\n",
        "\n",
        "  # removing remainder tokens\n",
        "  remainder = num_data % math.floor(num_data/num_batches)\n",
        "  print(remainder)\n",
        "  data = data[:num_data - remainder]\n",
        "  num_data = len(data)\n",
        "\n",
        "  # batches = np.array_split(data, math.floor(num_data)/batch_size)\n",
        "  batches = np.split(np.array(data),num_batches,axis=0)\n",
        "  return batches\n",
        "\n",
        "batches_words = gen_batches(5, 30, train)\n",
        "batches_embeddings = gen_batches(5, 30, embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mg3b1XELNCYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_seq(batch, window, seq_idx):\n",
        "  input_tokens = batch[seq_idx:seq_idx+window]\n",
        "  target_token = batch[seq_idx+window]\n",
        "\n",
        "  print(\"input : \", input_tokens)\n",
        "  print(\"target: [\", target_token, \"]\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkBM381LNChw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('--- batch 01 ---')\n",
        "print_seq(batches_words[0], 5, 0)\n",
        "print_seq(batches_words[0], 5, 1)\n",
        "print_seq(batches_words[0], 5, 2)\n",
        "\n",
        "print('-- batch 02 --')\n",
        "print_seq(batches_words[1], 5, 0)\n",
        "print_seq(batches_words[1], 5, 1)\n",
        "print_seq(batches_words[1], 5, 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6gNu8xBSizG",
        "colab_type": "text"
      },
      "source": [
        "## Task 2: Bengio Style Feedforward network language model\n",
        "- TensorFlow version: `2.1.0`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWCFC4p1RMPg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BengioParams():\n",
        "  context_window = 5\n",
        "  num_batches = 30\n",
        "\n",
        "  vocab_len = len(vocab_dict)\n",
        "  \n",
        "  hidden_units = 50\n",
        "  embeddings_dim = 60\n",
        "  num_epochs = 20\n",
        "\n",
        "  learning_rate = 0.5\n",
        "\n",
        "  gpu_mem = 0.25\n",
        "  \n",
        "  tf_precision = tf.float32\n",
        "  np_precision = np.float32\n",
        "\n",
        "  init_scale = 0.5\n",
        "  max_grad = 10.0\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cj6d3vk0U0lz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BengioModel():\n",
        "  \"\"\"\n",
        "  Class implements Bengio NN model with Tensorflow accoring to the function:\n",
        "    y = b + Wx + Utanh(d + Hx)\n",
        "  \n",
        "  and \n",
        "    cost = softmax_cross_entropy?\n",
        "\n",
        "  NOTE: dimensions are not correct yet! need clarification \n",
        "  (may need to transpose)\n",
        "\n",
        "  NOTE: Y = (30, |v|)\n",
        "        X = (30, 300) -> window_size * embedding_size -> 5*60 = 300\n",
        "        W = (300, |v|)\n",
        "        b = (1, |v|)\n",
        "        U = (50, |v|)\n",
        "        d = (1, 50)\n",
        "        H = (300, 50)\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, params=BengioParams()):\n",
        "\n",
        "    self.Y = tf.placeholder(\n",
        "        params.tf_precision,\n",
        "        shape=[params.num_batches, params.vocab_len],\n",
        "        name=\"Y\"\n",
        "    )\n",
        "    \n",
        "    self.X = tf.placeholder(\n",
        "        params.tf_precision, \n",
        "        shape=[params.num_batches, params.context_window * params.embeddings_dim],\n",
        "        name=\"X\"\n",
        "    )\n",
        "\n",
        "    \n",
        "    self.W = tf.get_variable(\n",
        "        name=\"W\",\n",
        "        shape=[params.context_window * params.embeddings_dim, params.vocab_len],\n",
        "        dtype=params.tf_precision\n",
        "    )\n",
        "    \n",
        "    self.H = tf.get_variable(\n",
        "        name=\"H\",\n",
        "        shape=[params.context_window * params.embeddings_dim, params.hidden_units],\n",
        "        dtype=params.tf_precision\n",
        "    )\n",
        "\n",
        "    self.U = tf.get_variable(\n",
        "        name=\"U\",\n",
        "        shape=[params.hidden_units, params.vocab_len],\n",
        "        dtype=params.tf_precision\n",
        "    )\n",
        "\n",
        "    self.b = tf.get_variable(\n",
        "        name=\"b\",\n",
        "        shape=[1, params.vocab_len],\n",
        "        dtype=params.tf_precision\n",
        "    )\n",
        "\n",
        "    self.d = tf.get_variable(\n",
        "        name=\"d\",\n",
        "        shape=[1, params.hidden_units],\n",
        "        dtype=params.tf_precision\n",
        "    )\n",
        "\n",
        "    self.a1 = tf.tanh(\n",
        "        self.d + tf.matmul(self.X, self.H)\n",
        "    )\n",
        "\n",
        "    self.y_hat =  self.b + tf.matmul(tf.transpose(self.W), tf.transpose(self.X)) + tf.matmul(tf.transpose(U), self.a1)\n",
        "\n",
        "    self.cost = tf.nn.softmax_cross_entropy_with_logits(\n",
        "        self.Y,\n",
        "        self.y_hat,\n",
        "        name='cross_entropy_coss_fn'\n",
        "    )\n",
        "\n",
        "    self.optimizer = tf.train.GradientDescentOptimizer(params.learning_rate).minimize(self.cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiI-h9TscByK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run():\n",
        "\n",
        "  params = BengioParams()\n",
        "\n",
        "  with tf.Session() as sess:\n",
        "\n",
        "    initializer = tf.random_uniform_initializer(-params.init_scale,params.init_scale)\n",
        "    with tf.variable_scope(\"BengioModel\", reuse=tf.AUTO_REUSE, initializer=initializer):\n",
        "      model = BengioModel(params=params)\n",
        "      for batch in batch_embeddings:\n",
        "        batch_x = []\n",
        "        batch_y = []\n",
        "        for win_idx in range(len(batch) - params.context_window - 1):\n",
        "          batch_x.append(batch[win_idx:win_idx+params.context_window])\n",
        "          batch_y.append(batch[win_idx+params.context_window])\n",
        "        \n",
        "        session.run(model.optimizer, feed={ x:batch_x, y: batch_y })"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWBxECjWWXn4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7owo5_W9Wb7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}